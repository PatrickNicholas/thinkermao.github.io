<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Write Ahead Log 杂谈]]></title>
    <url>%2F2018%2F08%2F04%2Fwrite-ahead-log%2F</url>
    <content type="text"><![CDATA[预写式日志（Write Ahead Log, WAL）主要用于实现存储系统中的原子性和持久性。预写式日志要求存储系统的修改操作在提交前都要先写入日志（Log）中。在硬盘数据不损坏的情况下，预写式日志允许存储系统在崩溃后能够在日志的指导下恢复到崩溃前的状态，避免数据丢失。 预写式日志并不是实现原子性和持久性的唯一办法，影页替换（Shadow Paging）是另一种实现方式，区别是预写式日志允许数据库进行原地更新（in-place），影页替换则不行。 预写式日志是一种套路，并不仅限于传统数据库中，在需要原子性和持久性的系统中经常见到它的身影。关系数据库的实现里，预写式日志常会被实现为重做（Redo Log）和撤销（Undo Log）两部分。LevelDB 中的日志模块就是预写式日志的简单应用，而最佳实践参考 ARIES algorithm。 Linux 文件系统里也有预写式日志的身影，不过叫做 Journaling。Journaling 提供了文件系统原子写入的可能，减轻存储系统实现难度。Journaling 在存储设备上开辟一段空间，用于记录文件操作，写操作先写入日志，然后复制数据到具体文件空间中，更新文件元信息，确保写入操作完成后再删除日志。Journaling 会在系统挂载文件系统时检查是否有未完成的日志，对其进行重做；系统卸载文件系统时，会将积压的日志写入。如果日志本身就不完整，直接丢弃更改。Journaling 每次操作需要将数据写两次，一种优化方式是先将数据写入对应位置，日志里只记录操作元信息，数据写入成功后再写日志。 预写式日志还应用在使用复制状态机（Replicated State Machine, RSM）进行协作的分布式系统中，如 Raft 算法为了保证安全性要求节点在将日志完整写入硬盘后才能回复该消息。 预写式日志在存储系统中扮演着举足轻重的地位，从文件系统，到分布式系统。不过在新的硬件环境下，出现了另一种与预写式日志相对的叫 Write-Behind Logging 的日志系统。WBL 在事务提交的时候，直接把藏页写入 NVRAM 中，等脏页刷盘后，再去更新日志。关于 WBL 的具体实现方式，参考论文：Write-Behind Logging]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Storage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft-实现指北-领导选举]]></title>
    <url>%2F2018%2F01%2F07%2FRaft-%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97-%E9%A2%86%E5%AF%BC%E9%80%89%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。在选举上，Raft 算法使用一个随机计时器来选举领导者，这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。[1] Raft 把时间分割任意长度的任期（term），并使用连续整数标记，每个任期都从一次选举开始。每次选举有一个或多个候选人参选，如果一个候选人赢得选举，其就会在该任期充当领导人的职责。某些情况下会出现选票瓜分的现象，那么该任期无法选出领导人，所以进入下一期选举，其中 Raft 通过随机计时来保证选举成功。[1] 设计实现领导人选举之前，先看到上一节提到的纯函数式的状态机，将 Raft 实现成为一个无副作用的纯函数状态机。Raft 算法可以看作一个角色状态机，通过其他节点传递的消息、计时器、客户端的提交请求和快照等输入消息，从一个状态转移到另一个状态、或修改部分内部状态并返回一个发送给外部的信息。 1(state, message) -&gt; state machine -&gt; message state machine 是一个纯函数式的状态机，负责处理消息，并将改动写入到 state 里，然后返回给外部的消息。 根据 Raft 论文，一个 state 几部分组成： 状态 所有服务器上持久存在的 currentTerm 服务器最后一次知道的任期号（初始化为 0，持续递增） votedFor 在当前获得选票的候选人的 Id log[] 日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号 状态 所有服务器上经常变的 commitIndex 已知的最大的已经被提交的日志条目的索引值 lastApplied 最后被应用到状态机的日志条目索引值（初始化为 0，持续递增） 状态 在领导人里经常改变的 （选举后重新初始化） nextIndex[] 对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一） matchIndex[] 对于每一个服务器，已经复制给他的日志的最高索引值 实现大体是类似的，不过以后需要加入流量控制、成员加入退出等，所以将 state 中保存的其他服务器的信息抽象一下： 12345type node struct &#123; id uint64 nextIdx uint64 matched uint64&#125; id 表示其他服务器在 Raft 中的唯一 ID，nextIdx 与 matched 分别是 nextIndex 数组和 matchIndex 数据中第 id 个元素。 Raft 通过超时来驱动心跳和选举，一共由两种超时：1、心跳超时，领导人定期给跟随者发送心跳信息宣布自己的领导权；2、选举超时，超时时间是随机选择的。 整个 state 如下： 12345678910111213141516type core struct &#123; id uint64 leaderId uint64 state StateRole term uint64 vote uint64 log *LogHolder nodes []node timeElapsed int randomizedElectionTimtout int electionTimeout int heartbeatTimeout int&#125; id 是 Raft weiyiqueding d term 和 vote 分别是 currentTerm 和 voteFor 的实现，而日志由应用负责持久化。lastApplied 和 commitIndex 由 log 负责管理。nodes 表示该 Raft 集群的其他服务器的状态。timeElapsed 表示从时间累积，randomizedElectionTimeout 表示随机生成的选举超时阈值，每次转为跟随者、候选人状态时都会改变。heartbeatTimeout 表示领导人两次心跳的间隔。electionTimeout 用来表示领导人选举超时基准，其用于计算randomizedElectionTimeout，使用公式：$electionTimeout + rand() \% electionTimeout$ 计算得到。另外还有 leaderId 和 state 状态，leaderId 表示当前领导人的 ID，state 则是 Raft 目前所处的角色。 此外，还需要设计消息结构作为外部应用、服务器和 Raft 状态机进行数据交换。 12345678910type Message struct &#123; From uint64 To uint64 MsgType MessageType Term uint64 Index uint64 LogIndex uint64 LogTerm uint64 Reject uint64 &#125; 该结构不仅仅用于发起请求，也用于状态机返回数据，所以需要 Reject 字段表示拒绝请求，比如拒绝给某个候选人投票。 最后，状态机需要返回消息给消息发送者，由于希望将 Raft 设计为一个纯函数式状态机，消息的接受发送交给了应用处理，所以还得提供一个 Application 接口，供 Raft 和应用交互。 123type Application interface &#123; send(msg *raftpd.Message)&#125; 当应用接收到消息后，将其输入到 Raft 状态机，处理完后，调用 send 发送回复消息，并保存信息到机中。整个状态机由消息驱动，所以 Raft 接口如下： 1234type Raft interface &#123; Step(msg *raftpd.Message) Periodic(millsSinceLastPeriod int)&#125; 当应用接受到外部传递的消息后，调用 Step 驱动状态机改变状态。Raft 中通过超时进行心跳或选举，外部应用需要通过某个固定的定时源隔一段时间调用 Periodic 驱动状态机进行心跳、选举等。 选举过程 系统进行初始化时，每个节点都处于跟随者状态，由于没有领导人定期广播心跳，所以一段时间后部分跟随者成为候选人并进行下一届选举。 当某个候选人获得了超过半数的投票后，成为领导人，并向所有节点广播自己成功的信息。当候选人接收到其他候选人成为领导人的信息后，一届只能选出一个领导人（选举安全特性），该候选人退回到跟随者的状态，并投票给该领导人。 如果到了下一个选举超时，仍然没有候选人成为领导人，就会跳过这一届，开始下一届的领导人选举。 PreVote由于选举安全特性的限制，成员会忽略已经过期的信息时，并返回自己所在的任期，用于发送者更新自己。由于这一特性的存在，在一个存在网络延迟的网络中，某个节点由于延迟进入了选举，而实际上大多数节点都能接收到领导人的心跳，也会进入选举。Raft 原论文 9.6 节中提出了 Prevote 算法：在选举前可以选询问其他节点是否愿意参与选举，如果节点能够感知到领导人的心跳，那么它就不会参与选举，否则参与选举。只有过半的节点参与选举，才能开始下一届领导人选举。 领导人选举实现加入了 PreVote 算法后，Raft 的状态变为 4 个：领导人、跟随者，候选人，预候选人。此时的外部事件为：选举、心跳超时；以及： MsgPreVoteRequest MsgPreVoteResponse MsgVoteRequest MsgVoteResponse MsgAppendRequest MsgAppendRequest 这种消息类型发生在某个节点成竞选成功后向其他节点宣示领导权，在选举过程中也由该种类型在节点间传递。比如 PreVote 阶段正常的跟随者能够接收到领导人的心跳；又或者新晋领导人首次对外宣誓领导权。 123456789101112131415func (c *core) Periodic(millsSinceLastPeriod int) &#123; c.timeElapsed += millsSinceLastPeriod log.Debugf("%d periodic %d, time elapsed %d", c.id, millsSinceLastPeriod, c.timeElapsed) if c.state.IsLeader() &#123; if c.heartbeatTick &lt;= c.timeElapsed &#123; c.broadcastAppend() c.timeElapsed = 0 &#125; &#125; else if c.randomizedElectionTick &lt;= c.timeElapsed &#123; if len(c.nodes) &gt; 1 &#123; c.campaign(campaignPreCandidate) &#125; &#125;&#125; 每次应用程序调用 Periodic 时，Raft 判断是否为 leader，是判断 timeElapsed 是否超过 heartbeatTick，然后向其他节点发送追加日志（心跳）信息，并清空 timElapsed；如果不是领导人，且已经超过随机生成的选举超时，那么状态转移到预候选人同时开始 PreVote 阶段。 除此之外，PreVote 算法还需要记录其他节点对某次预选举请求的响应状态，所以在 node 结构中添加字段标记： 123456789101112type voteState intconst ( voteNone voteState = iota voteReject voteGranted)type node struct &#123; ... vote voteState&#125; 状态间转换继续之前需要看看 Raft 状态机的状态转换是如何实现的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func (c *core) resetRandomizedElectionTimeout() &#123; c.randomizedElectionTick = c.electionTick + rand.Intn(c.electionTick)&#125;func (c *core) reset(term uint64) &#123; if c.term != term &#123; c.term = term c.vote = InvalidId &#125; c.leaderId = InvalidId c.timeElapsed = 0 c.resetRandomizedElectionTimeout()&#125;func (c *core) becomeFollower(term, leaderId uint64) &#123; c.reset(term) c.leaderId = leaderId c.state = FOLLOWER c.vote = leaderId log.Infof("%v become follower at %d", c.id, c.term)&#125;func (c *core) becomeLeader() &#123; utils.Assert(c.state == CANDIDATE, "invalid translation [%v =&gt; Leader]", c.state) c.reset(c.term) c.leaderId = c.id c.state = LEADER c.vote = c.id log.Infof("%v become leader at %d", c.id, c.term)&#125;func (c *core) becomeCandidate() &#123; utils.Assert(c.state != LEADER, "invalid translation [Leader =&gt; Candidate]") c.reset(c.term + 1) c.vote = c.id c.state = CANDIDATE for i := 0; i &lt; len(c.nodes); i++ &#123; node := &amp;c.nodes[i] node.resetVoteState() &#125; log.Infof("%v become candidate at %d", c.id, c.term)&#125;func (c *core) becomePreCandidate() &#123; c.reset(c.term) c.state = PRE_CANDIDATE for i := 0; i &lt; len(c.nodes); i++ &#123; node := &amp;c.nodes[i] node.resetVoteState() &#125; // Becoming a pre-candidate changes our state, // but doesn't change anything else. In particular it does not increase // currentTerm or change votedFor. log.Infof("%x became pre-candidate at term %d", c.id, c.term)&#125; 首先看到 reset，它是负责在 Raft 状态转换过程中重置部分状态。reset 中第一步是根据任期是否改变决定重置 vote 和 term 信息；除此之外还重置了 leaderId 以及超时相关的两个属性: timeElapsed 和 randomizedElectionTimeout。 进入预选举的节点在被大多数节点拒绝后会回退到跟随者的状态，因此在 becomePreCandidate 中除了重置基础状态外，仅仅修改了 state 属性和重置其他节点的投票情况。特别需要注意的是不能修改 currentTerm 和 votedFor。 如果预选举的节点获得了半数的节点参选支持，就会进入候选人状态，因此任期加一，同时给自己投票。 此外，当领导者和跟随者在发送心跳或接收到领导人的通知后，都需要重置 timeElappsed，因此将 becomeLeader 和 becomeFollower 设计为重入只会影响到 timeElapsed 和 randomizedElectinTimeout 属性。 PreCampaign竞选时首先调用 campaign 给其他节点发送 MsgPreVoteRequest 请求。 1234567891011121314151617181920212223242526func (c *core) campaign(ct campaignState) &#123; utils.Assert(c.state != LEADER, "invalid translation [Leader =&gt; PreCandidate/Candidate]") msg := raftpd.Message&#123;&#125; msg.LogIndex = c.log.lastIndex() msg.LogTerm = c.log.lastTerm() if ct == campaignPreCandidate &#123; msg.Term = c.term + 1 msg.MsgType = raftpd.MsgPreVoteRequest c.becomePreCandidate() &#125; else &#123; msg.Term = c.term msg.MsgType = raftpd.MsgVoteRequest c.becomeCandidate() &#125; for i := 0; i &lt; len(c.nodes); i++ &#123; node := &amp;c.nodes[i] msg.To = node.id log.Infof("%x [term: %d, index: %d] send %v request to %x at term %d", c.id, c.log.lastTerm(), c.log.lastIndex(), msg.MsgType, msg.To, c.term) c.send(&amp;msg) &#125;&#125; PreVote 要求某个节点只有在长时间未和领导人交换心跳时才参与选举。同时参与选举要求候选人的日志必须是最新的（领导人完全特性）。所以在接收到其他节点发送的 MsgPreVoteRequest 时，1、如果在一个选举超时内（注意：electionTimeout）有和领导交换过一次心跳；2、或者候选人的任期号小于自身的任期号；3、或者候选人的日志不是最新的都拒绝参加选举。否则回复参加选举。 123456789101112131415161718func (c *core) handlePreVote(msg *raftpd.Message) &#123; reply := raftpd.Message&#123;&#125; reply.To = msg.From reply.MsgType = raftpd.MsgPreVoteResponse // Reply false if last AppendEntries call was received less than election timeout ago. // Reply false if term &lt; currentTerm. // Reply false if candidate's log isn't at least as up­to­date as receiver's log. if (c.leaderId != InvalidId &amp;&amp; c.timeElapsed &lt; c.electionTick) || (msg.Term &lt; c.term) || !c.log.IsUpToDate(msg.LogIndex, msg.LogTerm) &#123; reply.Reject = false &#125; else &#123; reply.Reject = true &#125; c.send(&amp;reply)&#125; 注意：实际上在处理远程信息时，如果接收到了过期信息，会直接丢弃（后面有讲），不会进入 handlePreVote 函数，所以上面第二点实际上永远为假。 预候选人接收到其他节点回复的信息时: 1234567891011121314151617181920212223242526272829func (c *core) handleVoteResponse(msg *raftpd.Message) &#123; if msg.Reject &#123; log.Infof("%x received %v rejection from %x at term %d", c.id, msg.MsgType, msg.From, c.term) &#125; else &#123; log.Infof("%x received %v from %x at term %s", c.id, msg.MsgType, msg.From, msg.Term) &#125; node := c.getNodeById(msg.From) node.updateVoteState(msg.Reject) count := c.voteStateCount(voteGranted) if count &gt;= c.quorum() &#123; if msg.MsgType == raftpd.MsgVoteResponse &#123; c.becomeLeader() c.broadcastVictory() &#125; else &#123; c.campaign(campaignCandidate) &#125; return &#125; // return to follower state if it receives vote denial from a majority count = c.voteStateCount(voteReject) if count &gt;= c.quorum() &#123; c.becomeFollower(msg.Term, InvalidId) &#125;&#125; 更新某个 node 对此次请求的投票情况，并判断支持者和反对者人数，如果支持者人数过半，那么调用 campaign(campaignCandidate) 进入候选人状态。如果反对者人数过半，那么节点会回退到跟随者的状态。 Campaign在候选人一方，选举过程使用了相同的函数，不同的是跟随者对候选人的处理。只有当候选人未投票或者上一次投给了该候选人，候选人才能获得跟随者的选票。 123456789101112131415func (c *core) handleVote(msg *raftpd.Message) &#123; reply := raftpd.Message&#123;&#125; reply.To = msg.From reply.MsgType = raftpd.MsgVoteResponse // no vote or vote for candidate, and log is at least as up-to-date as receiver's. if c.vote == InvalidId || c.vote == msg.From || c.log.IsUpToDate(msg.LogIndex, msg.LogTerm) &#123; reply.Reject = false &#125; else &#123; reply.Reject = true &#125; c.send(&amp;reply)&#125; 处理过时消息根据 Raft 论文中将 term 用作逻辑时间，判断过期的消息。在论文图 2 中提到如果接收到来自高任期的消息，应该回退到跟随者状态；接收到过时消息，直接忽略。所以代码可以写为： 12345if msg.Term &lt; c.term &#123; c.reject(msg)&#125; if msg.Term &gt; c.term &#123; c.becomeFollower()&#125; 实际上可能某个节点成为候选人后，又重新连接到网络中。此时发起投票会导致其他节点增大任期，因此对投票相关的消息做特殊处理。 1234567891011121314151617181920func (c *core) Step(msg *raftpd.Message) &#123; if msg.Term &lt; c.term &#123; c.reject(msg) &#125; else if msg.Term &gt; c.term &#123; if msg.MsgType == raftpd.MsgPreVoteRequest &#123; &#125; else if msg.MsgType == raftpd.MsgPreVoteResponse &amp;&amp; msg.Reject &#123; &#125; else &#123; c.becomeFollower(msg.Term, leaderId) &#125; &#125; switch msg.MsgType &#123; case raftpd.MsgPreVoteRequest: c.handlePreVote(msg) case raftpd.MsgVoteRequest: c.handleVote(msg) default: c.dispatch(msg) &#125;&#125; Raft 算法虽然更易于理解，但是实现并不简单。就以上述代码为例，Raft 如果没有 PreVote 机制，那么重新上线的候选人会通过 c.reject(msg) 强制让候选人参与选举。加入 PreVote 机制也不能完全避免这种情况。如果一个节点成为了候选人，此时领导人重新上线，那么候选人仍然会强制发起一次选举[3]。 References 寻找一种易于理解的一致性算法（扩展版） Etcd-raft-core 阅读 Morning Paper, MongoDB 对 Raft 算法的 4 个改动]]></content>
      <categories>
        <category>Destribution</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>Consensus</tag>
        <tag>Practice</tag>
        <tag>Destribution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft 实现指北-日志模块]]></title>
    <url>%2F2018%2F01%2F02%2FRaft-%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[在真正开始设计之前，需要考虑好 Raft 框架的搭建。如下图所示，一个服务器由三部分组成：共识算法、状态机以及日志系统。共识算法控制多副本之间日志的同步、广播。Raft 算法主要的工作是管理日志复制，所以在 Raft 应该有一个可操作的日志模块。 Write Ahead Log在设计日志模块之前，需要先说说预写式日志（Write Ahead Log, WAL）。预写式日志通常出现在存储系统中，以保证数据的持久性[1]。WAL 的中心思想是对数据文件进行修改前，需要保证操作日志已经同步到稳定存储介质中。如果在进行操作时出现了错误导致程序崩溃，重启的程序可以通过读取日志重建原有状态。 Raft 算法中也需要 WAL 配合工作，比如领导人得知某条日志已经有超过半数的人响应，便将其应用到状态机并将其应用结果返回给客户端。状态机将数据保存在内存中，等待系统写入磁盘。此时如果发生错误，客户端的操作日志丢失，而它又接收到了应用成功的消息，便出现了不一致。 日志模块123struct LogHolder &#123; vector&lt;Entry&gt; entries;&#125; 日志的存储结构可以简单如上设计，Entry 表示一套操作日志记录。所有已经通过 WAL 持久化的操作日志保存在 Raft 的 LogHolder 中做缓存。IO 操作非常耗时，在实际的项目中每次操作先进行 IO 操作，效率不高。通常考虑 Batch 操作，将结构修改为： 1234struct LogHolder &#123; vector&lt;Entry&gt; entries; size_t stabled_to;&#125; 这样操作日志和已经持久化的日志保存在一起，并通过 stable_to 区分开。这样将多个日志 Entry 一起写入 WAL，Batch 的方法可以提升系统整体的吞吐量，不过对于单条数据，会有部分延迟，与提升比起来是非常值得的。 当某条日志被成功复制到集群中过半数的节点中时，Raft 变认为这条日志可以被应用到状态机中，并标记这部分日志为提交状态。提交的日志采用追加的方式，那么原有数据将一直占用存储空间，而对于系统而言，已经被应用了的日志是无用的，所以 Raft 也提出了日志压缩思想。和存储系统中的日志压缩思路一致，都是通过选取某个时间点的日志创建状态机的快照，将时间点之前的日志全部丢弃。[2] 这里将上述的思想也设计到日志系统中： 1234567891011// +--------------+--------------+-------------+-------------+// | wait compact | wait apply | wait commit | wait stable |// +--------------+--------------+-------------+-------------+// ^ offset ^ Applied ^ committed ^ stabled ^ laststruct LogHolder &#123; vector&lt;Entry&gt; entries; size_t offset; size_t last_applied; size_t last_committed; size_t last_stabled;&#125; offset 表示日志压缩后日志系统里存储的第一条日志在整个日志中的偏移。整个模块需要保证 $0 \le offset \le last\_applied \lt last\_committed \lt entreis.size()$。需要注意，last_stabled 和 last_committed 之前不一定存在着先后顺序，比如一个出现了网络隔离的节点在一段时间后上线，领导者将将其日志复制给该节点并告知其已经全部提交了，那么就会出现日志属于已经提交的状态，但是还未持久化。 在 Raft 论文中提到，在生成日志快照时，需要保存快照最后一条日志的 index 和 term 作为元信息。也有很多访问该元信息的需求，因此可以在 entries 中保留一个空白（dummy）日志作为快照元信息，那么 offset 完全可以被该日志项替代。 整个 LogHolder 只负责维护日志在内存中的缓存，提供日志追加、应用、提交、持久化以及压缩的基本功能，至于具体的操作实际由使用者负责管理。 API 设计API 设计是一个模块好用与否的关键，良好的 API 设计可以减少内部设计的暴露，减少模块间的耦合，同时提供最大程度的灵活性。这里希望 API 设计简单易用，接口数量少，粒度适中。 1234567891011type LogHolder interface &#123; compactTo(to, term uint64) commitTo(uint64) applyEntries() []Entry stableEntries() []Entry term(uint64) uint64 isUpToDate(idx, term uint64) bool tryAppend(idx, term, commitIdx uint64, entries []Entry) (uint64, bool) append(entries []Entry) uint64 slice(lo, hi uint64) []Entry&#125; compactTo: 当应用生成了快照后，需要对冗余的日志进行压缩； commitTo: 日志复制到集群中半数节点中或跟随者接收到领导人提交日志的命令时调用，修改 last_commit 属性； stableEntries: 读取待持久化的日志，并将这部分日志标记为已经持久化； applyEntries: 读取待应用到状态机的日志，同时将其日志标记为已经应用； term: 返回某个日志提交到集群中的 term； isUpToDate: 用于判断候选人是否拥有最新的日志； tryAppend: 跟随者添加日志，会将冲突的日志丢弃； append: 领导添加日志，只有追加功能； slice: 分片 compactTo，commitTo 负责修改其只修改日志模块属性信息。compactTo 对日志进行压缩，其可用范围为 $[offset, last\_applied]$，范围内的数据均已经应用到状态机中。实际上在跟随者从网络隔离中恢复或新加入集群时，领导人会选择发送日志来加速跟随者的同步，此时快照并没有落到可用范围内，或者日志与快照的元信息冲突（跟随者在一个少数派的网络中增加了很多日志），因此需要对整个日志系统进行重建。commitTo 只需要对 to 范围进行验证，修改 last_commit 即可。 stableEntries 和 applyEntries 不需要任何参数，根据属性设置对应的 slice，并返回需要持久化、应用的日志队列。 isUpToDate 比较给出的日志项和日志模块谁更新。根据 Raft 论文中给出了谁比较新的定义：如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新；如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。 tryAppend 是用于提交领导人复制给候选人的日志，由于网络分化或者节点的加入退出，获选人的日志可能落后、冲突于领导人提供的日志，日志模块需要对待追加的日志进行检查，并找出冲突项目并替换。 实现compactTo 设计如下： 123456789101112131415161718func (holder *LogHolder) CompactTo(to, term uint64) &#123; if holder.Term(to) != term || to &lt;= holder.offset() || to &gt; holder.lastApplied &#123; // log entry conflict with exists, or less than offset, or great than applied // so need to rebuild log entries := make([]raftpd.Entry, 1) entries[0].Index = to entries[0].Term = term holder.entries = entries holder.lastApplied = to holder.commitIndex = to holder.lastStabled = to &#125; else &#123; offset := holder.offset() utils.Assert(offset &lt;= to, "%d compact idx: %d less than first index: %d", holder.id, to, offset) holder.entries = drain(holder.entries, int(to-offset)) &#125;&#125; 首先检查是否存在冲突、或者没有在范围之内，都不存在才对日志队列进行压缩；否则重建日志模块，清空日志队列。因为使用了 dummy 日志项的缘故，这里也要把快照元信息作为一个 dummy log 保存。 和 compactTo 比起来，commitTo 的实现就容易得多。commitTo 需要保证状态机安全性和领导人完全性[2]，不能减少 commit_index；同时也要保证容错，即在服务器宕机恢复后数据具有一致性，每个可提交的日志需要已经持久化到本地。commitTo 需要保证数据范围在 $[commit_index, last\_stabled]$ 之间。 1234567891011121314func (holder *LogHolder) CommitTo(to uint64) &#123; if holder.commitIndex &gt;= to &#123; /* never decrease commit */ return &#125; else if holder.lastStabled &lt; to &#123; /* cannot commit unstable log entry */ to = utils.MinUint64(to, holder.lastStabled) &#125; utils.Assert(holder.lastIndex() &gt;= to, "%d toCommit %d is out of range [last index: %d]", holder.id, to, holder.lastIndex()) holder.commitIndex = to&#125; stableEntries 和 applyEntries 需要返回待持久化或待应用的日志，同时会修改属性，将这已返回的日志标记为已持久化或已经应用。term 的实现比较直观，isUpToDate 的实现按照论文给出的定义即可。 123func (holder *LogHolder) IsUpToDate(idx, term uint64) bool &#123; return term &gt; holder.lastTerm() || (term == holder.lastTerm() &amp;&amp; idx &gt;= holder.lastIndex())&#125; append 由领导人负责调用，由领导人只附加原则决定其只追加新日志到模块中。因为 Raft 的日志具有连续性，追加时要保证第一条追加的日志要紧接着日志模块的最后一条日志。tryAppend 由跟随者调用，正常情况下领导人发送的日志可以直接追加到跟随者的日志模块中。跟随者可能是新加入集群，并通过快照已经恢复到了快照所处的状态，此时也可以直接追加到日志模块里。当跟随者出现网络隔离导致日志远低于领导人复制来的第一条日志项（重新选举时），或日志项与领导人提供的存在冲突。如果第一条日志存在冲突，那么需要提醒领导人发送合适的日志；如果仅仅部分日志存在冲突，跟随者需要丢弃冲突日志，然后将领导人提供的日志追加到日志模块中（根据日志匹配原则），此时需要保证不能抛弃任何已经提交的日志（状态机安全性和领导人完全性）。 tryAppend 的第一步是找出第一个与现有日志存在冲突的日志索引，然后根据冲突索引丢弃存在冲突的日志，并返回。tryAppend 的返回值表示是否成功的将日志追加到系统中。Raft 论文 5.3 节提出了一个优化方式，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化，这里可以使用算法给出的一种优化方式：当附加日志 RPC 的请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。因此在拒绝该追加请求时，还给领导人返回提示索引。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func (holder *LogHolder) getHintIndex(prevIdx, prevTerm uint64) uint64 &#123; utils.Assert(prevIdx != InvalidIndex &amp;&amp; prevTerm != InvalidTerm, "%d get hint index with invalid idx or Term", holder.id) idx := prevIdx term := holder.Term(idx) for idx &gt; InvalidIndex &#123; if holder.Term(idx) != term &#123; return utils.MaxUint64(holder.commitIndex, idx) &#125; idx-- &#125; return holder.commitIndex&#125;// findConflict return the first index which Entries[i].Term is not equal// to holder.Term(Entries[i].Index), if all Term with same index are equals,// return zero.func (holder *LogHolder) findConflict(entries []raftpd.Entry) uint64 &#123; for i := 0; i &lt; len(entries); i++ &#123; entry := &amp;entries[i] if holder.Term(entry.Index) != entry.Term &#123; if entry.Index &lt;= holder.lastIndex() &#123; log.Infof("%d found conflict at index %d, "+ "[existing Term: %d, conflicting Term: %d]", holder.id, entry.Index, holder.Term(entry.Index), entry.Term) &#125; return entry.Index &#125; &#125; return 0&#125;func (holder *LogHolder) TryAppend(prevIdx, prevTerm, leaderCommittedIdx uint64, entries []raftpd.Entry) (uint64, bool) &#123; lastIdxOfEntries := prevIdx + (uint64)(len(entries)) if holder.Term(prevIdx) == prevTerm &#123; conflictIdx := holder.findConflict(entries) if conflictIdx == 0 &#123; /* success, no conflict */ &#125; else if conflictIdx &lt;= holder.commitIndex &#123; log.Panicf("%d entry %d conflict with committed entry %d", holder.id, conflictIdx, holder.commitIndex) &#125; else &#123; offset := prevIdx + 1 holder.Append(entries[conflictIdx-offset:]) &#125; return lastIdxOfEntries, true &#125; else &#123; utils.Assert(prevIdx &gt; holder.commitIndex, "%d entry %d [Term: %d] conflict with committed entry Term: %d", holder.id, prevIdx, prevTerm, holder.Term(prevIdx)) return holder.getHintIndex(prevIdx, prevTerm), false &#125;&#125; done至此，日志模块的实现就结束了。日志模块是整个 Raft 算法的基础，这里将日志模块剥离出来，并将提供一些原子方法。每个方法只干一件事，从而使分析方法正确性的分析更容易；每个方法都可以看作是纯函数，所以输入一定，输出则一定。实际上分布式程序的调试是一个非常困难的方式： 你的并发模型往往会成为你代码库中的病毒。你希望有细粒度的并发控制，好吧，你得到了，代码里到处都是。因此是并发导致了不确定性，而不确定性造成了麻烦。因此必须得把并发给踢出去。可是你又不能抛弃并发，你需要它。那么，你一定要禁止把并发和你的分布式状态机结合在一起。换句话说，你的分布式状态机必须成为纯函数式的。没有IO操作，没有并发，什么都没有。[3] 好的办法是将其抽象成纯函数式的，通过消息进行驱动，这样能够对程序拥有控制力，出现问题是可以完美重现，也能够跟踪定位到问题所在。从 Raft 算法的角度看，在上面的实现里，日志模块只是一个黑匣子，每个操作好比一个按钮，如果得到的不是想要的结果，那肯定是输入有问题（前提是黑匣子实现正确）。因此上面的代码很好的解开了算法和日志模块的耦合，隔离了双方的错误干扰。 References 预写式日志 寻找一种易于理解的一致性算法（扩展版） 分布式系统编程，你到哪一级了？]]></content>
      <categories>
        <category>Destribution</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>Consensus</tag>
        <tag>Practice</tag>
        <tag>Destribution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft 实现指北-开篇]]></title>
    <url>%2F2018%2F01%2F01%2FRaft-%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97-%E5%BC%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Raft 是一种解决分布式共识问题的算法。何为分布式共识问题？在此之前，还得说说分布式系统中的基础模型。基础模型是对分布式算法的一个定性的评估（分类）标准，它说明了算法的作用范围，可解决什么问题。 基础模型基础模型也可以称为算法的属性，这里主要关心两个部分：定时模型（Timing Model）、失效模式（Failure Model）、失效检测器（Failure Detectors）[1]。 定时模型是研究分布式系统的网络传输时延特性，分布式系统通过消息传递来进行通信，根据消息在网络中传递时间是否有上界，可以将消息系统分类为：同步模型（Synchronous Model）和异步模型（Asynchronous Model）[2]。在同步模型中，消息传递时间是已知的，每个进程的速度也是确定的，即每个进程执行一个算法步骤耗时是确定的。在异步模型中，每个组件自行决定算法步骤的执行顺序，每一步的耗时也没有保证[1]。注意，这里的同步和异步要与编程中出现的同步异步加以区分。 失效模式是对分布式系统中节点失效种类的假设。最基础的是崩溃-结束（crash-stop）失效模式，节点一直正常运行，直至崩溃，节点崩溃后不会恢复。相较于崩溃-结束失效模式，另一种崩溃-恢复（crash-recovery）失效模式更为常见，即节点崩溃后，会被恢复。值得一提的是崩溃-恢复模式中，一个节点恢复时，并不等同于没崩溃的原始节点（比如 Raft 算法动态调整系群组关系，某个节点被另一个新加入节点顶替）。一种更复杂的失效模式叫做拜占庭失效模式或者任意失效模式（Byzantine or arbitrary failures mode）：进程有可能向同伴发送错误的信息；进程可能是冒充的；应答给其他进程的数据是正确的，但是篡改了本地数据库的内容，等等[2]。设计分布式系统时，失效模式必须考虑进去，通常来说，我们并不需要考虑拜占庭失效模式。 上述两种属性能够描述分布式系统所处的问题，另外还有部分属性用于对系统工作方式进行分类，失效检测器便是这样的一种属性。失效检测器是对报告系统状态的抽象，即检测节点是否已经崩溃（或者怀疑是否崩溃）。失效检测器是在异步系统中解决共识问题的关键。在著名的FLP论文中指出，在异步的分布式系统中，如果进程有可能失效，那么就不可能达成共识。要达成共识，就必须为系统引入一个能够规避上述问题的失效检测器[1]。 分布式共识问题分布式共识问题，简单说，就是在一个或多个进程提议了一个值应当是什么后，使系统中所有进程对这个值达成一致意见。为了达到共识，每个进程都提出自己的提议（propose），最终通过共识算法，所有正确运行的进程决定（decide）相同的值[2]。 在同步、可靠的系统中，想要多个节点达成一致比较容易。实际的分布式场景多为异步模型，FLP不可能性说明：没有任何算法可以在存在任何故障的异步系统中确保达到共识，绕过不可能性结论的办法是考虑部分同步系统，利用故障屏蔽、故障检测器或随机化手段避开异步系统模型[2]。 分布式问题最常见的应用场景是多副本状态机（Replicated state machine）。多副本状态机是指多台机器具有完全相同的状态，并且运行有完全相同的确定性状态机[2]。多副本状态机主要用于解决分布式系统中的容错问题，因为副本冗余了状态机，只要保证大多数副本存活且一致，就能向外部提供服务。多副本状态机的实现思想：状态机的每个副本上都保存有完全相同的操作日志，保证所有副本状态机按照相同的顺序执行操作，这样由于状态机是确定性的，则一定会得到相同的状态[2]。具体的实现方式主要分为两种[3]： 日志复制：由 primary 机接受操作日志，并广播给 backup 机，backup 机需要跟 primary 机的操作日志保持一致； 状态重演：操作日志由多个副本共享，每个副本通过重新执行操作日志从放状态； Raft 算法有三种非常具有代表性的分布式共识算法：分别是 Viewstamped Replication 、Raft 和大名鼎鼎的 Paxos 算法，前两个工作本身就是基于多副本状态机的场景完成的，而 Paxos 算法是作为独立的分布式共识算法提出，并给出了使用该算法实现多副本状态机的范例[2]。 Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性[4]。 与其他共识算法相比，Raft 算法有三个特点[4]： 强领导者：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。 领导选举：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。 成员关系调整：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。 虽然这篇文章标题有“Raft 实现”关键字，但并不会讲 Raft 算法的原理，这只是 Raft 的功能实现介绍，所以我建议在继续阅读之前，先学习一下 Raft 算法：寻找一种易于理解的一致性算法（扩展版）。 挖坑一个基础的 Raft 功能只需要实现选举和日志复制，但这远远不够。想要应用到实际的工程中，还需要实现日至压缩、成员关系调整，才算完整的 Raft 实现。这里给出个 Raft 功能清单，实际上也是本系列文章希望实现的功能： leader election prevote log replication log compaction &amp; snapshot linearizable read(read index &amp; lease) membership change leadership transfer 拥有上述功能可以算上一个工业级的 Raft 实现，不过在实际应用中，还会有许多工业上的优化技巧比如 Batch 和 Pipeline，具体有哪些可以优化的，放到以后的章节详述。 这是我在学习 Raft 算法，并以之为基础实现分布式系统过程中的学习总结。在接下来的几篇文章中，将按照上述清单依次谈谈对应的实现方法和优化原理。实现方法参考优秀的开源实现：etcd/raft 以及其各语言移植版本。 Reference WHAT WE TALK ABOUT WHEN WE TALK ABOUT DISTRIBUTED SYSTEMS 分布式共识(Consensus)：Viewstamped Replication、Raft以及Paxos The design of a practical system for Fault-Tolerant Virtual Machines 寻找一种易于理解的一致性算法（扩展版） 分布式系统编程，你到哪一级了？]]></content>
      <categories>
        <category>Destribution</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>Consensus</tag>
        <tag>Practice</tag>
        <tag>Destribution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 事务隔离级别的使用]]></title>
    <url>%2F2017%2F12%2F07%2FMysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近在项目中遇到一个问题，在 Mysql 的 Repeatable Read 隔离级别下，出现了数据丢失更新。一开始怀疑的是事务失效，被排查后否定。最后定位到 Mysql 事务的使用问题上。我们的 Sql 场景类似于： 12SELECT number FROM A WHERE ID = 1;UPDATE A SET NUMBER = number + 1 WHERE ID = 1; 事务回顾事务有四种特性（ACID）： 原子性 隔离性 一致性 持久性 在执行事务时可能出现以下问题： 丢失更新： 第一类丢失更新：事务失败回滚时将其他事务已经提交的数据覆盖 第二类丢失更新：事务提交时，覆盖了其他事务的提交（类似 += ，是不可重复读的特例） 脏读：事务读取了其他事务还未提交的内容 不可重复读：一个事务中多次读取同一个内容，结果不一致 幻读：一个事务中两次查询，但第二次查询比第一次查询多了或少了几行或几列数据 为了解决上述问题，数据库系统提供了四种事务隔离级别供用户选择： Read Uncommitted 读未提交：不允许第一类更新丢失。允许脏读，不隔离事务。 Read Committed 读已提交：不允许脏读，允许不可重复读。 Repeatable Read 可重复读：不允许不可重复读。但可能出现幻读。 Serializable 串行化：所有的增删改查串行执行。 在传统的事务隔离级别的实现中，可重复读已经能够避免了两类丢失更新，对于绝大多数的事务，只需要将隔离级别设置为可重复读。 Snapshot isolation &amp; MVCC需要明确的是，以上的ACID和隔离级别定义是在SQL规范层面的定义，不同数据库的实现方式和使用方式并不相同。上面的隔离级别标准是SQL92 基于读写锁的实现方式制定的规范。 为了克服并发问题，各个数据库厂商都引入了 MVCC （多版本并发控制）来提高并发度。所以实际上的事务实现与规范定义的出现了细微的差别，而这细微的差别，就是本文出现的原因。（下文主要以 Mysql innoDB 存储引擎的 MVCC 实现为主，InnoDB 中的 MVCC 为表添加了隐藏的列，打上版本号，来提供多版本功能）。 所以在 MVCC 中，SELECT 语句执行时，会执行快照读取（称为快照读，也称为一致性读）。如果数据被锁，直接读取 undo log 来读取其被锁前的副本。在 Read Commit 隔离级别中，快照读总是读取对应行的最新版本；如果该行被锁住，则会读取最近一次的快照。在 Repeatable Read 隔离级别中，快照读总是读取事务开始时的数据版本。 这种方式极大的提升了并发读取的效率，本质也非常类似乐观锁。所以这种方式实现的隔离级别与规范定义存在一定差异，在 Repeatable Read 中，这种差异导致了 innoDB 第二类更新丢失的出现。因此，使用 MVCC 实现的隔离级别也被称为快照隔离级别。 SI 隔离与规范的 RR 隔离级别的区别在于读取 SI 的 SELECT 语句为快照读，而传统的 SELECT 语句则为当前读（加读锁:locking read, LR）。 在 InnoDB 中，update, delete 执行的是加锁读，想要将 SELECT 语句也设置为加锁读，需要在语句后加上 FOR UPDATE, LOCK IN SHARE MODE。具体的加锁方式取决于用户使用的是那种查询计划： unique index with a unique search condition a range-type search condition 对于第一种方式，InnoDB 只对其所在的索引进行加锁，不影响其他内容。对于第二种方式，InnoDB 通过使用间隙锁（gap locks)或者 next-key locks 来实现。因为这种加锁落实到区间上，所以也有可能锁住不必要的内容。因此 InnoDB 也号称在 RR 级别上实现了 Serializable 隔离级别。 next-key locks 能排除大多数的幻读现象，只会存在 write skew style 的幻读。 回到题目最开始的问题上，因为这种不规范的事务实现，导致了在高并发情况下会存在第二类丢失更新问题。只需要在 SELECT 后面加上 FOR UPDATE 就能避免出现的问题。 References 事务并发的问题以及其解决方案 事务隔离级别与 Mysql 中事务的使用 Innodb中的事务隔离级别和锁的关系 Consistent Nonlocking Reads innodb-transaction-isolation-levels]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人站点：Mysql 5.6 内存占用配置]]></title>
    <url>%2F2017%2F09%2F07%2F%E4%B8%AA%E4%BA%BA%E7%AB%99%E7%82%B9%EF%BC%9AMysql-5-6-%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[前两天刚把服务器部署上，今天就出现了异常。在 App 上看是服务器直接宕机。原本以为仅仅是服务端挂了，在服务器上使用 ps aux | grep java 发现进程还在，只是不服务了。打开 log 发现 Java run out of memory，导致无法创建新的线程。 使用 top -o %MEM 查看，java 占用近 200M，mysql 占用近 500 M。因为是个人用的小服务器，只有 1G 内存，吃紧得很。既然 mysql 占用了最多的内存，就让它吐出一点好了。 一开始猜测是 InnoDB 缓冲区过大，不过在 /etc/mysql/my.cnf 中发现配置的缓存已经非常小了。后来在网上发现是因为 Mysql 5.6 版本默认 GA 配置过大，导致初始需要近 400M 空间。通过下面配置，直接讲内存降到 100M 以下： 123performance_schema_max_table_instances=400table_definition_cache=400table_open_cache=256 参数意义： performance_schema_max_table_instances The maximum number of instrumented table objects 检测的表对象的最大数目。 table_definition_cache The number of table definitions (from .frm files) that can be stored in the definition cache. If you use a large number of tables, you can create a large table definition cache to speed up opening of tables. The table definition cache takes less space and does not use file descriptors, unlike the normal table cache. The minimum and default values are both 400. 缓存 frm 文件 table_open_cacheThe number of open tables for all threads. Increasing this value increases the number of file descriptors that mysqld requires. table_open_cache 指的是缓存数据文件的描述符(Linux/Unix)相关信息 在 5.6 中的默认配置： 123performance_schema_max_table_instances 12500table_definition_cache 1400table_open_cache 2000 References: 解决 Mysql 内存占用巨大问题 MySQL 5.6内存占用过高解决方案 linux 下mysql内存占用过高]]></content>
      <categories>
        <category>Linux 服务器</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSKS-(三)、设计模式]]></title>
    <url>%2F2017%2F08%2F26%2FCSKS-%E4%B8%89-%E3%80%81%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[面对对象原则 单一职责：不要存在多于一个导致类变更的原因；通俗的说，即一个类只负责一项职责； 里氏替换：所有引用基类的地方必须能透明地使用其子类的对象；通俗的来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能； 依赖倒置：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象； 接口隔离：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上； 迪米特法则：一个对象应该对其他对象保持最少的了解； 开闭原则：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭； 23种设计模式References 设计模式大总汇 单例模式：确保整个程序中只有一个实例，并自行实例化以向整个体统提供实例 工厂方法模式：将实例的创建延迟到子类 抽象工厂模式：为创建一组相互依赖的对象提供一个接口，并将创建过程延迟到子类 建造者模式：将一个复杂对象的创建和表示分离开来，使得同一个创建过程可以得到不同的表示 原型模式： 迭代器模式：在不暴露内部实现的情况下，使客户可以遍历容器内部对象 责任联模式：将对象连成一条链，并沿着这条链传递该请求，直到有对象处理该请求位置，解决了发送方和接收方的耦合 桥梁模式：将抽象和实现解耦，使两者可以独立变化 适配器模式：将一个对象的接口转换成另一个对象期待的接口，从而使原本不匹配的对象能在一起工作 中介者模式：将一系列对象的交互封装起来，使其耦合松散，而且可以独立变化 观察者模式：定义一种1-N的关系，使得当一个对象更新时，所有依赖它的对象都能收到通知并响应 命令模式：将客户参数化，使得客户请求可以记录、排队，并能实现撤销，恢复等功能 亨元模式：使用共享对象可以有效的支持大量细粒度的对象 状态模式：当一个对象状态改变时改变其行为，使得对象看起来像是改变了类 解释器模式：定义一组语言及其解释器 访问者模式：定义一组接口，从而是现在不改变数据结构自身的情况下添加职责 装饰器模式：动态的为一个对象添加一些额外的职责，比生成子类要简单 代理模式：提供一种代理以控制对对象的访问 策略模式：定义并封装一组可以互换的算法 模板方法模式：定义一个算法的骨架，将一些具体步骤延迟到子类。使得子类可以不改变算法结构即重定义算法特定步骤 组合模式： 门面模式： 备忘录模式： 单例模式单例模式重点在两个方面： 系统只有一个实例； 自行实例化并向整个系统提供这个实例； 单例模式的实现上有两个重要的因素： 线程安全； 延迟加载； 延迟加载技术可以解耦依赖链与初始化顺序。如果单例在程序执行前就进行初始化，某一个单例的初始化过程中，又引用到了另一个单例，便出现了加载顺序的决议问题。而使用延迟加载技术将这种依赖过程与初始化顺序进行了自动决议。 1234567void instance() &#123; static Singleston * sing = NULL; if (sing == NULL) &#123; sing = new Singleston; &#125; return sing;&#125; 线程安全方面则根据语言不同而有所差异，以 C++ 为例，C++11 标准规定了局部静态变量初始化的线程安全特性，所以写起来非常方便： 1234void instance() &#123; static Class ins; return ins;&#125; 按照这种写法不仅线程安全，同时还解决了依赖问题。如果不想用这种办法，也可以使用标准库提供的：call_once() 函数。 Java 在方面就要麻烦得多，我个人比较偏爱的是 DCL 这种方式： 1234567891011public class Singleston &#123; private static volatile Singleston instance; public static getInstance() &#123; if (instance == null) synchronized(Singleston.class) &#123; if (instance == null) instance = new Singleston; &#125; return instance; &#125; &#125; Java 版本的 DCL 需要注意使用 volatile 修饰，从 1.5 版本开始这种写法已经不存在问题了。 建造者模式建造者模式用于将一个复杂对象的建造过程和表示过程分开。这种比较适合一旦创建好后不会怎么更改的对象。在 Android 中的 AlertDialg 就使用这种方式： 1234567891011121314151617181920protected void dialog() &#123; new Builder(this) .setMessage("are you sure?") .setTitle("tips") .setPositiveButtion("yes", new OnClickListener() &#123; @Override public void onClick(DialogInterface dialog, int which) &#123; dialog.dismiss(); Main.this.finish(); &#125; &#125;) .setNegativeButton("No", new OnClickListener() &#123; @Override public void onClick(DialogInterface dialog, int which) &#123; dialog.dismiss(); &#125; &#125;) .create() .show();&#125; 无独有偶，在 Java 著名网络库 Netty 中，创建 Channel 也是使用建造者模式： 123456789101112Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; // ... &#125; &#125;); ChannelFuture f = b.connect(host, port).sync(); 迭代器模式容器需要提供用户一个访问机制，而又不暴露内部细节，这种方法就叫迭代器模式。C++ 和 Java 中均有迭代器模式的影子： 123456789101112// C++vector&lt;int&gt; arrays;// ...auto it = arrays.begin();// JavaArrayList&lt;Integer&gt; arrays = new ArrayList&lt;Integer&gt;();// ...Iterator&lt;Integer&gt; it = arrays.iterator();while (it.hasNext()) &#123; ...&#125; 责任链模式如其名，整个处理过程就像链一样，一级一级传递下去，从而接触了发送方和接收方的耦合。责任链模式常见于各种事件处理机制，比如 Android 的事件处理机制、Win32 中的消息机制。责任链模式的显著特点是如果一个事件（消息）在当前处理逻辑中不处理，就将其传递给下一级处理逻辑。 123456void slove(Message msg, Handler handle) &#123; switch (msg) &#123; case xxx: ...; break; default: handle.slove(msg); &#125;&#125; 桥梁模式将抽象和实现解耦的就是桥梁模式。通常在设计时，不要传播设计，而桥梁模式正好可以处理。比如一开始只有一台实验仪器，所以用单例模式来表示，某一天实验室又购进了一台新的仪器，那么之前所有引用单例的代码都要修改。而设计时如果将获取设备接口和单例分开，就没有这么多麻烦了： 12345678910public class Device &#123; private class SingleDevice &#123; // singleston &#125; public static Device getByRandom() &#123; return SingleDevice.getInstance(); &#125;&#125; 桥梁模式的另一个常见用途在 C++ 中，常用于实现减少 C++ 头文件编译负担： 123456789101112131415161718192021// a.h 中class A &#123; class AImpl;public: void do();private: std::shared_ptr&lt;AImpl&gt; impl;&#125;;// A.cpp 中class A::AImpl &#123;public: void do() &#123; ... &#125;&#125;;void A::do() &#123; impl-&gt;do();&#125; 适配器模式适配器模式可以使两个不兼容的接口一起工作，有 Andoird 开发经验的一定对 Adaptor 非常熟悉，这里不细讲。 中介者模式中介者模式把两个独立对象的一系列操作封装起来，把这两个对象之间的联系解耦，这样两个对象不依赖对方，可以独立变化。 观察者模式解耦操作最好的还属观察者模式。观察者模式重新定义了对象之间的依赖关系，将原有的监听操作转变为通知操作。 关于使用观察者模式，比较典型的例子是控件事件的监听–在指定控件上绑定一个回调函数，事件发生的时候，控件负责调用该函数通知用户。在 Java 中大名鼎鼎的响应式库 RxJava 就是以观察者模式为基础，还解决了长期以来困扰的 Callback hell 问题。Vue.js 中实现数据绑定也是以观察者模式为基础的。 命令模式命令模式最重要的一点就是将客户端的请求参数化，从而实现请求排队、记录回滚等。在游戏中，命令模式可以将用户对角色控制的输入进行参数化，实现死亡回放等。在服务器开发中，将客户端的请求参数化，并放入请求队列，实现流量控制。 状态模式说到命令模式不得不提状态模式，以任务操纵为例，人在地面上可以进行跳跃，而在跳跃的过程中则不可以。那么对于相同的命令，在不同的状态下有不同的响应，这就是状态模式。状态模式可以在改变对象状态的同时改变对象的行为。 享元模式游戏中地图大量元素存在重复的情况，大量创建相同的对象非常浪费内存，此时可以创建几个单例，让地图引用具体的单例，这就是享元模式。 解释器模式现在很多游戏的基本框架由 C/C++ 来写，具体业务逻辑则交给 lua 之类的脚本处理。如果是自己设计的脚本，那么就需要写出对应的解释器： 123456789class Expr &#123;public: Value execute();private: char c; Expr * left, * right;&#125;;// 解释器模式 访问者模式一开始我们只提供了游戏脚本解释器的解释功能，某次调试的时候希望将具体的抽象语法书打印出来，所以在每个元素类中添加了打印支持： 12345678910111213class Expr &#123;public: Value execute(); Value dump() &#123; left-&gt;dump(); cout &lt;&lt; c ; right-&gt;dump(); &#125;private: char c; Expr * left, * right;&#125;; 每当出现一个新的需求时，都要对原有的数据结构进行修改。而访问者模式为我们提供了遍历，可以在不修改数据结构的同时增加数据结构上的操作。 1234567891011121314151617181920212223242526272829class Visitor &#123;public: virtual void visit(Expr *ptr); virtual void visit(Value *ptr);&#125;;class Visitable &#123;public: virtual void accept(Visitor *visitor);&#125;;//...class Expr : public Visitable &#123;public: void accept(Visitor *visitor) &#123; visitor-&gt;visit(this); &#125;&#125;;class Dump : public Visitor &#123;public: void visit(Value * v); void visit(Expr * e) &#123; e-&gt;left-&gt;accept(this); cout &lt;&lt; e-&gt;c; e-&gt;right-&gt;accept(this); &#125;&#125;; 装饰器模式装饰器模式可以在不继承对象的同时给对象增加操作。Python 中有一个装饰器的概念，比如我们要给原来的函数添加上调用记录到日志的功能： 123456789def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper@logdef do(): pass 与之类似的还有 Java 提供的注解功能，这里不展开。 代理模式说到代理，常见有 VPN、HTTP Proxy ，代理模式用于控制对对象的访问。比如实现一个 RPC 功能，在客户端定义一个接口，由代理服务生成接口对应的实例。客户在调用接口时，代理服务监测并将请求转发给服务器，等到服务端计算完成并返回时，代理服务把结果返回给客户端。从客户端的角度上，这个过程和调用一个耗时的函数没有区别。]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CSKS-(二)、数据库系统]]></title>
    <url>%2F2017%2F08%2F26%2FCSKS-%E4%BA%8C-%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[数据库基础现在主流的数据库系统主要是关系数据库。关系数据库使用集合代数等概念和方法来处理数据库中的数据，同时数据组织成描述性的表格。关系数据库通常由三级模式两层映像组成。在具体设计数据库的时候，通常使用范式来对数据库进行约束设计。 近些年 NoSQL（非关系型数据库）应用也比较多，主要以 Key-Value 类数据库为主，比如 Redis。 理论基础References 关系代数 数据库底层结构 - B 树 SQL 语言SQL 语言共分为四大类： 数据查询语言 DQL 数据操纵语言 DML 数据定义语言 DDL 数据控制语言 DCL 数据查询语言DQL数据查询语言 DQL 基本结构是由 SELECT 子句，FROM 子句，WHERE 子句组成的查询块： 123SELECT &lt;字段名表&gt;FROM &lt;表或视图名&gt;WHERE &lt;查询条件&gt; 数据操纵语言DML主要有三种形式： 插入：INSERT 更新：UPDATE 删除：DELETE 数据定义语言 DDL数据定义语言 DDL 用来创建数据库中的各种对象—–表、视图、索引、同义词、聚簇等如： 123CREATE TABLE/VIEW/INDEX/SYN/CLUSTERALTERDROP DDL 操作是隐性提交的！不能 rollback。 数据控制语言 DCL数据控制语言 DCL 用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等。如： GRANT：授权 ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点。 COMMIT [WORK]：提交 回滚—ROLLBACK 回滚命令使数据库状态回到上次最后提交的状态。其格式为: 1SQL&gt; ROLLBACK; References DQL、DDL、DML、DCL SQL语言入门 drop、truncate和delete的区别 数据库中视图的作用 数据库范式数据库范式是指数据库中数据满足的某种约束，用来指导数据库设计。随意设计的数据库可能存在数据冗余、插入异常、更新异常、删除异常等。数据库范式用于减少或消除上述异常。 数据库范式分为：1NF,2NF,3NF,BCNF,4NF,5NF。通常设计时只需要考虑到 BCNF。符合高一级的范式，必定符合低一级范式。 1NF1NF的定义为：符合1NF的关系中的每个属性都不可再分。实际上，1NF 是所有关系型数据库的最基本要求，你在关系型数据库管理系统（RDBMS），例如 SQL Server，Oracle，MySQL 中创建数据表的时候，如果数据表的设计不符合这个最基本的要求，那么操作一定是不能成功的。也就是说，只要在 RDBMS 中已经存在的数据表，一定是符合 1NF 的。 函数依赖函数依赖指出了一张表中属性之间的函数关系：将属性分为 X,Y 两组，对于任意的 X 满足 X 相同时 Y 一定相同，即 X 值确定的情况下，Y 的值也能确定，此时称为 X → Y。从“函数依赖”这个概念展开，还有两个概念： 完全函数依赖：在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X’ → Y 不成立，那么我们称 Y 对于 X 完全函数依赖，记作 X F→ Y。 部分函数依赖假：如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，记作 X P→ Y， 码设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K（这个“完全”不要漏了），那么我们称 K 为候选码，简称为码。在实际中我们通常可以理解为：假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为主码）。 在任意一个码中的属性称为主属性，与之对应的就是非主属性。 2NF2NF的定义为：非主属性不部分地依赖于码。第二范式要求数据具有唯一性。以学生、学校、学校地址(st,sc,addr)为例，其中学生、学校为主属性，学校地址只依赖于学校，不满足第二范式。如果新办了座学校，校内还没有学生上课，那么就无法插入数据（插入异常）；如果学校地址改变了，需要对每一条数据中的学校地址都进行更新，非常麻烦（更新异常）。 2NF3NF的定义为：非主属性不传递地依赖于码。第三范式要求任何非主属性不能由其他属性派生出来。 BCNFBCNF的定义为：主属性既不部分地依赖于码，也不传递地依赖于码。BCNF 要求主属性之间满足唯一且不能由其他属性派生出来。 关于范式的详解可以参考：数据库第一二三范式到底在说什么？。 数据库完整性约束关系完整性是为保证数据库中数据的正确性和相容性，对关系模型提出的某种约束条件或规则。完整性通常包括域完整性，实体完整性、参照完整性和用户定义完整性，其中域完整性，实体完整性和参照完整性，是关系模型必须满足的完整性约束条件。 域完整性约束：域完整性是保证数据库字段取值的合理性。属性值应是域中的值，这是关系模式规定了的。除此之外，一个属性能否为 NULL，这是由语义决定的，也是域完整性约束的主要内容。域完整性约束是最简单、最基本的约束。在当今的关系 DBMS 中，一般都有域完整性约束检查功能。包括检查（CHECK）、默认值（DEFAULT）、不为空（NOT NULL）等。 实体完整性实体完整性是指关系的主关键字不能重复也不能取“空值”。一个关系对应现实世界中一个实体集。现实世界中的实体是可以相互区分、识别的，也即它们应具有某种惟一性标识。在关系模式中，以主关键字作为惟一性标识，而主关键字中的属性(称为主属性)不能取空值，否则，表明关系模式中存在着不可标识的实体(因空值是“不确定”的)，这与现实世界的实际情况相矛盾，这样的实体就不是一个完整实体。按实体完整性规则要求，主属性不得取空值，如主关键字是多个属性的组合，则所有主属性均不得取空值。 参照完整性参照完整性是定义建立关系之间联系的主关键字与外部关键字引用的约束条件。关系数据库中通常都包含多个存在相互联系的关系，关系与关系之间的联系是通过公共属性来实现的。所谓公共属性，它是一个关系 R (称为被参照关系或目标关系)的主关键字，同时又是另一关系 K (称为参照关系)的外部关键字。如果参照关系 K 中外部关键字的取值，要么与被参照关系 R 中某元组主关键字的值相同，要么取空值，那么，在这两个关系间建立关联的主关键字和外部关键字引用，符合参照完整性规则要求。如果参照关系 K 的外部关键字也是其主关键字，根据实体完整性要求，主关键字不得取空值，因此，参照关系 K 外部关键字的取值实际上只能取相应被参照关系 R 中已经存在的主关键字值。 用户定义完整性实体完整性和参照完整性适用于任何关系型数据库系统，它主要是针对关系的主关键字和外部关键字取值必须有效而做出的约束。用户定义完整性则是根据应用环境的要求和实际的需要，对某一具体应用所涉及的数据提出约束性条件。这一约束机制一般不应由应用程序提供，而应有由关系模型提供定义并检验，用户定义完整性主要包括字段有效性约束和记录有效性。 数据库事务数据库事务(Database Transaction) ，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。通过将一组相关操作组合为一个要么全部成功要么全部失败的单元，可以简化错误恢复并使应用程序更加可靠。一个逻辑工作单元要成为事务，必须满足所谓的ACID（原子性、一致性、隔离性和持久性）属性。 事务的 ACIDAtomicity原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 Consistency一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。换句话说就是：事务开始和结束之间的中间状态不会被其他事务看到。 Isolation隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 隔离性主要涉及到事务的并发控制，根据不同的并发控制策略，可能出现脏读、不可重复读、幻读。 脏读脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户 A 向用户 B 转账 $100$ 元，对应 SQL 命令如下: 12update account set money=money+100 where name=’B’; (此时A通知B)update account set money=money-100 where name=’A’; 当只执行第一条 SQL 时，A 通知 B 查看账户，B 发现确实钱已到账（此时即发生了脏读），而之后无论第二条 SQL 是否执行，只要该事务不提交，则所有操作都将回滚，那么当 B 以后再次查看账户时就会发现钱其实并没有转。 不可重复读不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。不可重复读就是一个事务范围内多次查询结果不同。例如事务 T1 读取了某一数据，而事务 T2 立马修改了这个数据并且提交事务给数据库，事务 T1 再次读取该数据就得到了不同的结果，发送了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 虚读(幻读)幻读是事务非独立执行时发生的一种现象。例如事务 T1 对一个表中所有的行的某个数据项做了从 $1$ 修改为 $2$ 的操作，这时事务 T2 又对这个表中插入了一行数据项，而这个数据项的数值还是为 $1$ 并且提交给数据库。而操作事务 T1 的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务 T2 中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 Durability持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 事务的 4 种隔离级别 隔离级别 脏读 不可重复读 幻读 Read uncommitted × × × Read committed ✓ × × Repetable read ✓ ✓ × Serializable ✓ ✓ ✓ 四种隔离级别，重高到低有： Serializable 串行化 Repeatable read 可重复读 Read committed 读已提交 Read uncommitted 读未提交 Serializable 采用的是范围锁 RangeS、RangeS_S 模式，锁定检索范围为只读，这样就避免了幻影读问题。Repeatable read 读取数据时加共享锁，写数据时加排他锁，都是事务提交才释放锁。读取时候不允许其他事物修改该数据，不管数据在事务过程中读取多少次，数据都是一致的，避免了不可重复读问题。Read committed 修改时加排他锁，直到事务提交后才释放，读取时加共享锁，读取完释放。事务1读取数据时加上共享锁后（这样在事务1读取数据的过程中，其他事务就不会修改该数据），不允许任何事物操作该数据，只能读取，之后1如果有更新操作，那么会转换为排他锁，其他事务更无权参与进来读写，这样就防止了脏读问题。Read uncommitted 相当于不加锁。 在 MySQL 数据库中默认的隔离级别为 Repeatable read (可重复读)。 事务的提交和回滚在数据库的插入、删除和修改操作时，只有当事务在提交到数据库时才算完成。在事务提交前，只有操作数据库的这个人才能有权看到所做的事情，别人只有在最后提交完成后才可以看到。 提交数据有三种类型：显式提交、隐式提交及自动提交。下面分别说明这三种类型。 显式提交用 COMMIT 命令直接完成的提交为显式提交。其格式为： 1SQL&gt; COMMIT; 隐式提交用 SQL 命令间接完成的提交为隐式提交。这些命令是： 1ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME 自动提交若把 AUTOCOMMIT 设置为 ON ，则在插入、修改、删除语句执行后，系统将自动进行提交，这就是自动提交。其格式为： 1SQL&gt; SET AUTOCOMMIT ON; 有时执行 SQL 语句会出现异常，又或提交事务失败，总之事务没有成功完成。这种情况下，需要把事务前面执行了的语句回滚，才能保证事务的 ACID。 如果出现了异常导致数据库没有执行到 COMMIT，用户需要手动执行 ROLLBACK 回滚刚才的操作。 undo、redo 与检查点数据库刚提交的事务通常存放在缓冲区中，等到缓冲区满或者其他需要写入硬盘的时候，才写入硬盘。数据库通常用日志文件记录操作，undo 日志记录某数据被修改前的值，可以用来在事务失败时进行 rollback；redo 日志记录某数据块被修改后的值，可以用来恢复未写入。 数据库先将操作写入日志文件，然后把数据写入缓冲区。等到时机合适时才将数据持久化到硬盘上。这种顺序保证了数据库故障时恢复最后修改的操作，也可以用于 rollback。当进行恢复操作时，对未提交的操作执行 undo，对提交了的执行 redo。 在持久化时，会记录 checkpoint 发生的”时刻“。在故障回复时候，只需要 redo/undo最近的一次 checkpoint 之后的操作。 References 关于spring手动进行事务提交以及回滚的问题 对mysql事务提交、回滚的错误理解 理解数据库中的undo日志、redo日志、检查点 数据库索引数据库索引是对数据库中一个或多个值进行排序的结构，用于加速数据查询等。数据库索引类似与书籍附录的名词索引，在不用扫描整个数据库表的情况下，允许程序快速找到表中的数据。 索引加快了数据查找速度，提高系统性能。而维护索引需要使用额外的物理空间，同时插入、更新、删除时也需要对索引进行维护。 从底层的视角来看，索引通常以 B+ 树为数据结构。B+ 树是多路搜索树，所以能保证索引的查找速度。对于高纬度如 GIS 数据索引，可以考虑使用 R 树作为数据结构。 从物理空间的角度来看，索引通常分为聚簇索引和非聚簇索引。聚簇索引是指表中的数据存储顺序和索引的顺序一致；非聚簇索引正好相反。因此，聚簇索引一张表只能有一个。非聚簇索引又通常被成为辅助索引。 在实际的程序逻辑中，有主键索引、唯一索引和普通索引。主键索引要求内容不能为空值，唯一索引要求数据不能重复。自然的，主键索引是唯一索引的特殊情况，其要求能唯一确定具体表项。一般情况下，DBMS 会在主键上建立聚簇索引，比如 Mysql 的 Innodb。如果索引不止建立在一列上，就称之为联合索引（与之对应的成为单列索引），一般情况下，联合索引使用时通常按照最左前缀原则匹配。 References Mysql 索引背后的数据结构和算法原理 Mysql 之辅助索引 最左前缀原理与相关优化 MySQL索引原理及慢查询优化 Mysql 索引优化 索引效率优化 慢查询 mysql的最佳索引攻略 Mysql 性能调优三部曲（慢查询、Explain 和 Profile） 锁与并发控制锁从功能角度来看： 共享锁：允许多个读，不允许写； 排他锁：只允许一个读写； 意向锁 共享锁、排他锁通常有具体作用范围：表、页、行。有时需要给整个表加锁，加锁前需要检查有无事务对某一行加了锁，如果一行一行检测，效率是不可接受的。这种情况下，DBMS 要求事务在某子节点加上读、写锁时，要持有父节点的意向锁；后面加锁的事务只需要检查父节点的意向锁就能得知。 从范围角度来看： 行级锁：表示只针对当前操作的行进行加锁 表级锁：表示对当前操作的整张表加锁 页级锁：介于行级锁和表级锁之间 下面看看 Mysql 中的行级锁、表级锁及页级锁。 类别 开销 速度 冲突率 粒度 并发度 行级锁 最大 最慢 低 最小 最高 表级锁 小 快 最高 最大 最低 页级锁 一般 一般 一般 一般 一般 References Mysql 共享锁、排他锁和意向锁 MySQL中的行级锁,表级锁,页级锁 两阶段锁协议整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁。在加锁阶段，事务只能加锁，也可以操作数据，但不能解锁，直到事务释放第一个锁，就进入解锁阶段，此过程中事务只能解锁，也可以操作数据，不能再加锁。两阶段锁协议使得事务具有较高的并发度，因为解锁不必发生在事务结尾。它的不足是没有解决死锁的问题，因为它在加锁阶段没有顺序要求。如两个事务分别申请了A, B锁，接着又申请对方的锁，此时进入死锁状态。 并发控制数据库管理系统（DBMS）中的并发控制的任务是： 确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性； 统一性以及数据库的统一性； 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段： 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作； 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性； 无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。所以，不要把乐观并发控制和悲观并发控制狭义的理解为 DBMS 中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在 DBMS 中，悲观锁正是利用数据库本身提供的锁机制来实现的。 在 Mysql 中，悲观锁通过 select for update 实现，乐观锁则在表中加上 version 字段实现。 具体关于加锁时机可以参考深入详解乐观锁和悲观锁、乐观锁、悲观锁。 事务隔离级别和乐观锁、悲观锁的关系：事务隔离级别是并发控制的整体解决方案，其实际上是综合利用各种类型的锁和行版本控制，来解决并发问题。锁是数据库并发控制的内部机制，是基础。对用户来说，只有当事务隔离级别无法解决一些并发问题和需求时，才有必要在语句中手动设置锁。 数据库扩展随着业务规模的不断扩大，需要选择合适的方案去应对数据规模的增长，以应对逐渐增长的访问压力和数据量。 关于数据库的扩展主要包括：主从复制、读写分离、数据库分库与分表。 References MySQL 读写分离 高性能 Mysql 主从架构的复制原理及配置详解 Mysql 主从复制原理和配置 Mysql 主从复制(Binary log) 数据库分库分表策略的具体实现方案 大众点评订单系统分库分表实践 唯品会订单分库分表的实践总结已经关键步骤 分库分表的几种常见形式以及可能遇到的难 MysqlReferences MySQL数据库的各种存储引擎详解 MySQL中的存储引擎讲解（InnoDB,MyISAM,Memory等各存储引擎对比） Redis &amp; Memcached]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CSKS-(一)、数据结构和算法]]></title>
    <url>%2F2017%2F08%2F26%2FCSKS-%E4%B8%80-%E3%80%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[算法复杂度算法的时间复杂度反映了程序执行时间随输入规模增长而增长的量级，算法的空间复杂度反映了程序执行时消耗的空间随输入规模增长而增长的规模；时间复杂度和空间复杂度在很大程度上能很好反映出算法的优劣。 在数学上有三个记号用于刻画算法复杂度: 大 $O$ 记号：表示函数数量级上的上界 大 $Ω$ 记号：与大 $O$ 记号相反，表示函数数量级上的下界 大 $Θ$ 记号：表示函数数量级上的一个确界 通常情况下主要考虑的是算法的最坏情况，即大 $O$ 记号。 数学定义下面给出三个记号的数学定义： 若存在常量 $c$ 和函数 $f(n)$，对于任意的 $n \gg 2$，均有 $T(n) \le c \times f(n)$ 成立，则表示 $f(n)$ 给出了 $T(n)$ 增长的一个渐进上界，记作 $T(n) = O(f(n))$。 若存在常量 $c$ 和函数 $g(n)$，对于任意的 $n \gg 2$，均有 $T(n) \ge c \times g(n)$ 成立，则表示 $g(n)$ 给出了 $T(n)$ 增长的一个渐进下界，记作 $T(n) = \Omega(g(n))$。 若存在常量 $c1$、$c2$ 和函数 $h(n)$，对于任意的 $n \gg 2$，均有 $c1 \times h(n) \le T(n) \le c2 \times h(n)$ 成立，则表示 $h(n)$ 给出了 $T(n)$ 增长的一个渐进下界，记作 $T(n) = Θ(h(n))$。 P 问题和 NP 问题一般地，$O(log_2n)$、$O(n)$、$O(n \times log_{2}n)$、$O(n^2)$、$O(n^3)$ 称为多项式复杂度；$O(2^n)$、$O(n!)$ 称为指数复杂度。 计算机科学家普遍认为前者（即多项式时间复杂度的算法）是有效算法，把这类问题称为 P（Polynomial，多项式）类问题，而把后者（即指数时间复杂度的算法）称为 NP（Non-Deterministic Polynomial，非确定多项式）问题。 多项式复杂度用于求解问题的代价是可接受的。很多问题没有多项式时间的解，比如大数分解、Hamilton 回路。虽然这些问题没有多项式时间内的解，但是可以在多项式时间内验证某个猜想是否正确。 References 数据结构与算法的分析-渐进复杂度（三个记号） 算法的时间复杂度和空间复杂度-总结 数据结构数组、链表、栈、队列等是数据结构中最常用的，且实现比较简单。 References 数组、链表、栈、队列、二叉树 数组、链表、栈、队列和STL 并查集并查集这个数据结构主要用于判断两个元素是否为同一个集合元素。这里以 p[i] 表示 i 元素所在集合，开始时每个元素各占一个集合；union(i, j) 操作将原有两个集合 i、j 合并为一个集合。 1234567891011121314151617void init() &#123; for (int i = 0; i &lt; n; ++i) p[i] = i; for (int i = 0; i &lt; n; ++i) weight[i] = 1;&#125;int find(int i) &#123; while (i != p[i]) i = p[i]; return i;&#125;void union(int x, int y) &#123; int i = find(x); int j = find(y); if (i == j) return; if (weight[i] &lt; weight[j]) &#123; p[i] = j; weight[j] += weight[i]; &#125; else &#123; p[j] = i; weight[i] += weight[j]; &#125;&#125; init() 用于初始化并查集 find() 用于找到当前元素所在的集合 union() 用于将两个元素的集合合并起来 因为使用类似与子节点指向父节点的原理，如果合并中一直加到某个节点最下方，将导致链变长。因此使用 weight 记录集合权重，每次将权重小的集合加到权重大的集合后，加快了 find 的速度。 优先队列优先队列内部由堆构成，堆类似二叉树，其中子节点均小于父节点。只要保证每次插入、删除数据时保持堆原有的性质，那么可以在 $O(1)$ 的时间复杂度内得到最小（最大）值。 References 优先队列原理与实现 树二叉树 二叉树是指最多有两个孩子节点的树。在计算机科学中，二叉树有几个重要的性质： 二叉树第 $i$ 层最多有 $2^{i-1}$ 个节点，其中 $i \ge 1$ 二叉树深度为 $k$，那么最多有 $2^k-1$ 个节点，其中 $k \ge 1$ $n_0$ 表示度为 $0$ 的节点，$n_2$ 表示度为 $2$ 的节点，那么有 $n_0=n_2+1$ 在完全二叉树中，具有 $n$ 个节点的二叉树深度为 $\lfloor log_2(n + 1) \rfloor + 1$ 第一个可以不用证明。以 $l_i$ 表示第 $i$ 层有最多有多少个节点，那么第二条结论等于 $total=l_1+l_2+\cdots+l_k=1+2+\cdots+2^{i-1}=2^i-1$。 第三个性质需要用到其他两个公式： $n=n_0+n_1+n_2$ $n$ 表示总节点个数，$n_1$ 表示度为 $1$ 的节点的个数 $n-1=2n_2+n_1$ 这个公式是边的数量的恒等式 两式相减可以得到第三条公式。 完全二叉树最后一层长度为 $1 \to 2^{i-1}$ 之间，因为 $2^i-1=n$，所以成立。 References 二叉树的5个重要性质 二叉树 二叉查找树假设有这样一颗二叉树，其节点值保存一个数据，而左节点的值均小于等于当前结点，右节点所有值均大于等于当前节点，那么这棵树就叫做二叉查找树。 在查找时，类似与二分查找，先判断是否等于当前值，然后根据大小在左右两侧进行查找。当然，因为没有其余限制，极端情况下二叉查找树会形成一条链，此时查找时间便降到 $O(n)$。所以实际使用中会对二叉查找树进行旋转操作，进行旋转的二叉查找树被成为平衡二叉树。比起普通二叉树，平衡二叉树在实现上复杂得多。 References 二叉查找树 AVL 树AVL 树是一种平衡二叉查找树，也被称为高度平衡树。它的特点是任何两个节点的高度差最大为 $1$。 如果树有 $n$ 个节点，AVL 树的增删查改操作复杂度为 $log(n)$，如果插入、删除操作导致 AVL 树中某个节点不再满足上述性质，那么平衡状态就被破坏。所以要对其进行旋转操作，保证其平衡性。 AVL 树只有四种可能出现的不平衡状态，与之对应的，就是 $4$ 种旋转操作。 References AVL树 AVL树详解 另一种二叉查找树是伸展树，伸展树有一个特点：当某个节点被访问时，伸展树会通过旋转操作使得该节点成为树根。所以再次访问这个节点时，能够迅速访问到这个节点。更多伸展树相关的请看伸展树。 红黑树References 平衡查找树之2-3树 平衡查找树之红黑树 红黑树详解 Tire 树References Tire 树 B 树References 算法数据结构(一)-B树 B、B+、B* 树 从 B、B+、B* 树谈到 R 树 区间信息维护与查询有时会需要在区间上进行操作，比如区间最值、区间和等。 树状数组树状数组提供了一种查询和维护区间和的方式。 low_bit进一步将树状数组前，得讲讲 low_bit，low_bit 用于求出数值二进制表示中的最后一个 $1$ 所表示的数值。 123int low_bit(int c) &#123; return c &amp; (c ^ (c - 1));&#125; 从二进制的角度可以清晰地观察到原理： 以 15(1110) 为例，15-1(1101)，15^(15-1)(0011)，所以low_bit(15)(0010) 树状数组用 $c[i]$ 记录 $a[i-low_bit(i)+1]+…+a[i]$ 的信息。那么想要前 $i$ 个数据的和就可以用下面的代码: 12345678int sum(int i) &#123; int ret = 0; while (i &gt; 0) &#123; ret += c[i]; i -= low_bit(i); &#125; return ret;&#125; 可以看到前 $i$ 个数据和为 $a[1]+a[2]+…+a[i]$，将其划分为两部分 $a[1]+a[2]+…+a[i-low_bit(i)]$ 和 $a[i-low_bit(i)+1]+…+a[i]$，后一部分等价于 $c[i]$。现在就将求和转换为求前 $i-low_bit(i)$ 项加上 $c[i]$ 的和。递归地运用，就能得到具体值。 树状数组同时还允许修改操作： 123456void add(int i, int d) &#123; while (i &lt;= length) &#123; c[i] += d; i += low_bit(i); &#125;&#125; 这里算法将等价于执行a[i] += d，其中length为数据长度最大值。当修改了元素值后，树状数组维护的信息也应修改。因为 $c[i]$ 等于 $a[i-low_bit(i)+1]+…+a[i]$，而 $c[i+low_bit(i)]$ 的区间范围为：$[i+low_bit(i)-low_bit(i+low_bit(i))+1, i+low_bit(i)]$，其中 $low_bit(i+low_bit(i))$ 显然等于 $low_bit(i) &lt;&lt; 1$，所以等价于 $[i-low_bit(i)+1, i+low_bit(i)] &gt; [i-low_bit(i)+1, i]$。要保证树状数组信息正确，必须在修改 $c[i]$ 后同时修改 $c[i+low_bit(i)]$ 所在值。 有了两个操作后，就能完成区间查询操作，比如查询[3,5]的和，可以使用 $sum(5)-sum(2)$。 当然，树状数组需要进行初始化，如何初始化？使用add(i, a[i])。可以简单得出树状数组初始化操作耗时 $O(n \times log_2n)$，查询操作耗时 $O(log_2n)$。 线段树树状数组适合查询区间值。其主要思想是在数据集上维护一颗二叉树，二叉树叶子节点对应一个具体数据，而父节点表示左右节点对应的集合。 123[1,4][1,2][3,4][1][2][3][4] 如上所示，最下方为其数据集，而上方为对应的父节点。现在用每个父节点维护其子节点对应区间的信息（最大值、最小值、求和）。那么如果要查询某个区间内容比如 [1,3]，可以将集合分为 [1,2][3] 两部分，因此每次查询会停留在区间被完全覆盖的节点上，从而实现快速查询。 同树状数组一致，当更新某个数据时，同样需要更新其上方包含该区间的节点的信息。线段树还可以对一个区间进行快速操作，比如整个区间加上某个值。实现方式很简单，在每个节点处加上一个额外的信息，在进行操作时，如果区间完整覆盖了当前区间，那么就把操作添加到当前额外信息上。当然，后续查询中如果查到的区间小于该节点的区间怎么办？那就需要把额外信息往下传递。 Sparse Table如果仅仅需要查询区间最值，且初始化后数据不会改变，那么使用 sparse table 是不错的选择。 sparse table 的思路是使用函数 $f(i, j)$ 表示从 $i$ 开始长度为 $2^j$ 的一段元素中的最小值（最大值）。显然有 $f(i, j)=min(f(i, j-1), f(i+2^{j-1}, j-1))$ 成立。观察到总共有 $n$ 个数据，而每个数据表示长度最多为 $log(n)$，所以总共初始化耗时 $O(n \times log_2(n))$。 1234567void init(int *a, int n) &#123; for (int i = 0; i &lt; n; ++i) d[i][0] = a[i]; for (int j = 1; (1 &lt;&lt; j) &lt;= n; ++j) &#123; for (int i = 0; i + (1 &lt;&lt; j) - 1 &lt; n; ++i) d[i][j] = min(d[i][j-1], d[i+(1&lt;&lt;(j-1))][j-1]); &#125;&#125; 当构造好了 table 后如何查询呢？比方说想要找到区间 $[L, R]$ 的最值，这时需要找到一个区间满足$2^k \le R-L+1$，其中 $k$ 为满足前面不等式的最大整数，那么就可以通过区间 $[L, L+2^k]$ 和 $[R-2^k+1, R]$ 的最值进行比较得到（即 $f(L, k)$ 和 $f(R-z^k+1, k)$，因为求最值，所以区间重叠不影响结果）。 12345int query(int l, int r) &#123; int k = 0; while (1 &lt;&lt; (k+1) &lt;= r-l+1) k++; return min(d[l][k], d[r-(1&lt;&lt;k)+1][k])&#125; 完成预处理后，查询操作可以在常量时间内完成。 排序算法这里列出了常见的十大排序算法 算法 空间 稳定 时间复杂度 空间复杂度 冒泡排序 in stable $O(n^2)$ - 插入排序 in stable $O(n^2)$ - 选择排序 in unstable $O(n^2)$ $O(1)$ 归并排序 out stable $O(nlog(n))$ $O(n)$ 快速排序 in unstable $O(n^2)$ - 堆排序 in unstable $O(nlog(n))$ - 计数排序 out stable $O(n+k)$ - 桶排序 out stable $O(n^2)$ - 基数排序 out stable $O((n+k)d)$ - 希尔排序 - - - - 解释： stable：表示排序前后值相同的元素相对位置不变 unstable：与上面相反 In-place：表示排序算法可以在原有数据空间上执行 Out-place：表示排序算法需要额外的空间来执行 冒泡排序冒泡排序是通过两两交换，像水中的泡泡一样，小的先冒出来，大的后冒出来。具体实现为：从第一个到最后一个扫描，每次按一定顺序排列相邻的两个元素；执行一次后，找到一个最大元素，将查找范围减一后重复执行上一部；执行多次后，达到有序。 123456for (int i = length-1; i &gt; 0; i--) &#123; for (int j = 0; j &lt; i; j++) &#123; if (a[j] &gt; a[j+1]) swap(a, j, j + 1); &#125;&#125; 插入排序插入排序将数据分为前后两个部分： 按照某种顺序有序部分 无序部分 每次将无序部分的第一个数据与有序部分进行比较并交换，这样朝着开始方向移动，直到找到第一个大于或小于该数据的值。 插入排序比较适合用于“少量元素的数组”。其实插入排序的复杂度和逆序对的个数一样，当数组倒序时，逆序对的个数为 $\frac{n(n-1)}{2}$，因此插入排序复杂度为 $O(n^2)$。 1234for (int i = 0; i &lt; length; ++i) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j--) swap(a, j, j-1);&#125; 插入排序的速度直接是逆序对的个数，而冒泡排序中执行“交换“的次数是逆序对的个数，因此冒泡排序执行的时间至少是逆序对的个数，因此插入排序的执行时间至少比冒泡排序快。 选择排序每次找一个最小值。具体实现为每次在未排序数据中找到一个最值，并加到以排序数据首部或尾部。 12345678for (int i = length - 1; i &gt;= 0; i--) &#123; int idx = i; for (int j = 0; j &lt; i; j++) &#123; if (a[idx] &lt; a[j]) idx = j; &#125; swap(a, i, idx);&#125; 归并排序运用分治法思想解决排序问题。实现中将原有数据分为两个部分，递归调用自己，最后得到了两份有序的数据，然后将两份有序数据合并。 12345678910111213141516171819// [l, r)void sort(int *a, int *tmp, int l, int r) &#123; if (l &gt;= r-1) return; int mid = l + (r - l) / 2; sort(a, tmp, l, mid); sort(a, tmp, mid, r); int i = l, j = mid, k = 0; for (int k = 0; k &lt; r - l; k++) &#123; if (i &lt; mid) tmp[k++] = a[i++]; else if (j &gt; hi) tmp[k++] = a[j++]; else if (a[i] &gt; a[j]) tmp[k++] = a[j++]; else tmp[k++] = a[i++]; &#125; for (int k = 0; k &lt; r - l; k++) a[l + k] = tmp[k];&#125; 归并排序是 out-place sort，与快速排序相比，需要很多额外空间；通常情况下，归并和快排渐进复杂度一致，不过归并排序系数大于快排，所以通常认为归并排序慢于快排。 插入排序适合对小数组进行排序，所以可以使用插入排序对归并排序进行改进。以数组长度为 $k$ 时采用插入排序，则渐进复杂度为 $O(nk+nlog(n/k))$，如果保证 $k=log(n)$，那么有 $O(nlog(n))$。 快速排序快速排序的思想也是分治法。具体做法是选择一个元素作为 pivot，并用 pivot 将数据分为大于 pivot 和小于 pivot 的两部分。然后分别对这两部分递归调用自己，此时得到的数据便是有序的。 在数组已经有序时，快排的时间复杂度为 $O(n^2)$。通常使用随机化（shuffle array 或者 randomized select pivot）来改进，使得期望运行时间为 $O(nlog(n))$。 当输入数组的所有元素都一样时，不管是快速排序还是随机化快速排序的复杂度都为 $O(n^2)$，使用三向切分技术可以使这种情况下的复杂度为 $O(n)$。 12345678910111213141516171819202122// [l, r)int partition(int *a, int l, int r) &#123; int lt = l, gt = r; int pivot = a[l]; while (true) &#123; while (a[++lt] &lt; pivot) if (lt &gt;= r) break; while (pivot &lt; a[--gt]) if (gt &lt;= l) break; if (lt &gt;= gt) break; swap(a, lt, gt); &#125; swap(a, gt, l); return gt;&#125;// [l, r)void sort(int *a, int l, int r) &#123; if (l &gt;= r-1) return; int part = partition(a, l, r); sort(a, l, part); sort(a, part + 1, r);&#125; 在算法一书中还介绍了一种快排的优化算法：三向切分。其核心思想是将原有的分成两部分转换为分成三部分：小于、等于、大于。具体实现需要依赖于下面的数据（以递增排序为例）： lt 表示当前不小于 pivot 的第一个元素 i 表示未排序的第一个元素 gt 表示大于 pivot 的第一个元素 根据上面的，分析过程中数据布局如下： 1[l 小于pivot |lt 等于pivot |i 未排序 |gt 大于pivot r) 此时选中第一个i进行操作： 如果 $a[i] == pivot$ 则 $i=i+1$ 如果 $a[i] &gt; pivot$ 则交换 $a[–gt]$ 和 $a[i]$ 如果 $a[i] &lt; pivot$则交换 $a[i++]$ 和 $a[lt++]$ 每次操作完成后，仍然保持了原有的数据格式。重复该过程直到$i==gt$ 则表示 partition 操作完成，现在只需要对 $[l, lt)$ 和 $[gt, r)$ 部分进行排序即可。 1234567891011121314void sort(int *a, int l, int r) &#123; if (l &gt;= r-1) return; int lt = l, i = l+1, gt = r; int pivot = a[l]; while (i &lt; gt) &#123; int cmp = a[i] - pivot; if (cmp &gt; 0) swap(a, --gt, i); else if (cmp &lt; 0) swap(a, i++, lt++); else i++; &#125; sort(a, l, lt); sort(a, gt, r);&#125; 堆排序运用了最小堆、最大堆这个数据结构，而堆还能用于构建优先队列。 References 堆与堆排序 计数排序计数排序有很大的局限性，其要求数据范围比较小，能枚举。具体实现思路是将其按照数据数据大小，直接分配一个固定位置。 一般情况下计数排序复杂度为 $O(n+k)$，当$k=O(n)$时，计数排序时间为$O(n)$，其中 $k$ 表示数据范围，$n$ 表示数据长度。 12345678void sort(int *a, int n, int k) &#123; int b[n+1], c[k+1]; for (int i = 0; i &lt;= k; ++i) c[i] = 0; for (int i = 1; i &lt;= n; ++i) c[a[i-1]]++; for (int i = 1; i &lt;= k; ++i) c[i] += c[i-1]; for (int i = n; i &gt; 0; --i) b[c[a[i-1]]--] = a[i-1]; for (int i = 0; i &lt; n; ++i) a[i] = b[i+1];&#125; 桶排序 算法：将元素按照范围依次分散到多个桶中，此时桶的范围是有序的。再对每个桶进行排序，最后得到的数据就是有序的。 当分布不均匀时，全部元素都分到一个桶中，则 $O(n^2)$，当然也可以将插入排序换成堆排序、快速排序等，这样最坏情况就是 $O(nlog(n))$。 1234567891011void sort(int *a, int n) &#123; int *b[10] = &#123; 0 &#125;; int l[10] = &#123;0&#125;; for (int i = 0; i &lt; n; ++i) &#123; int idx = a[i] % 10; 将a[i]插入到b[idx]中 l[idx]++; &#125; for (int i = 0; i &lt; 10; ++i) otherSort(b[i], l[i]);&#125; 桶排序的缺点是： 首先是空间复杂度比较高，需要的额外开销大。排序有两个数组的空间开销，一个存放待排序数组，一个就是所谓的桶，比如待排序值是从 $0$ 到 $m-1$，那就需要 $m$ 个桶，这个桶数组就要至少 $m$ 个空间。 其次待排序的元素都要在一定的范围内等等。 基数排序这里假定每位的排序是计数排序。而计数排序是稳定的，所以对部分有序的数据排序，得到的结果仍然满足部分有序。话句话说，如果第 $k+1$ 位有序，对第 $k$ 位进行计数排序后，得到的结果仍然在 $k+1$ 位有序。将原有数据每一位依次排序，最后得到的结果能保证有序。 计数排序复杂度为 $O((n+k)d)$。 $d$ 表示位数 $k$ 表示数据范围 $n$ 表示长度 当 $d$ 为常数、$k=O(n)$时，效率为$O(n)$。 123456// 其中counter用于对第i位排序void sort(int *a, int d, int n) &#123; for (int i = 1; i &lt;= d; ++i) &#123; counter_sort(a, i, n); &#125;&#125; 希尔排序希尔排序是利用插入排序在有序时速度快的特点。以 $k$ 为间隔对数据进行排序，直到 $k=1$。 1234567891011void sort(int *a, int n) &#123; int k = 0; while (k &lt; n/3) k = k*3 + 1; while (k &gt;= 1) &#123; for (int i = k; i &lt; N; ++i) &#123; for (int j = i; j &gt;= k &amp;&amp; a[j] &lt; a[j-k]; j -= k) swap(a, j, j-k); &#125; k /= 3; &#125;&#125; 查找查找算法二分查找对于有序且可以随机访问的数据，要判断数据中是否含有某个值，可以使用 $O(log(n))$ 的二分查找。 对于一个给定的区间 $[l, r)$，我们判断 $mid=\frac{l+r}{2}$ 是否为目标值，是表示找到，否则没有找到。没有找到时，判断值和 $val[mid]$ 和目标值的大小，如果目标值小于中间值，则实际值应该能在左边区间 $[l, mid)$ 中找到，否则应该在 $[mid + 1, r)$ 中查找。 1234567891011// [l, r)int search(int *a, int n, int val) &#123; int l = 0, r = n; while (l &lt; r) &#123; int mid = l + (r-l)/2; if (a[mid] &lt; val) r = mid; else if (a[mid] &gt; val) l = mid + 1; else return mid; &#125; return -1;&#125; 三分查找二分查找适用于单调函数中逼近求解某点的值。如果遇到凸性或凹形函数时，可以用三分查找求那个凸点或凹点。 假设我们要找一个凸点，给了区间 $[l, r]$ 和函数 $f(x)$，下面找出中点 $mid=(l+r)/2$，以及 $[mid,r]$ 的中点 $mmid=(mid+r)/2$。通过比较 $f(mid)$ 与 $f(mmid)$ 的大小来缩小范围，当最后 $L=R-1$ 时，再比较下这两个点的值，我们就找到了答案。 当 $f(mid) &gt; f(mmid)$ 的时候，我们可以断定 $mmid$ 一定在最值点的右边。假设 $mmid$ 在最值点的左边，则 $mid$ 也一定在最值点的左边，又由 $f(mid) &gt; f(mmid)$ 可推出 $mmid &lt; mid$，与已知矛盾，故假设不成立。所以，此时可以将 $R = mmid$ 来缩小范围。 当 $f(mid) &lt; f(mmid)$ 的时候，我们可以断定 $mid$ 一定在最值点的左边。反证法：假设 $mid$ 在最值点的右边，则 $mmid$ 也一定在最值点的右边，又由 $f(mid) &lt; f(mmid)$ 可推出 $mid &gt; mmid$，与已知矛盾，故假设不成立。同理，此时可以将 $L = mid$ 来缩小范围。 1234567891011int search(int l, int r) &#123; //找凸点 while (l &lt; r-1) &#123; int mid = (l+r)/2; int mmid = (mid+r)/2; if (f(mid) &gt; f(mmid)) r = mmid; else l = mid; &#125; return f(l) &gt; f(r) ? l : r; &#125; 树树已经在前面数据结构-树中介绍了。 Hash散列表散列表类似于数组的使用方式，通过 key 找到对应的 value。使用散列查找算法分为两步： 用散列函数将 key 映射到数组的索引上 处理索引（hash）冲突 散列函数选取非常重要，因为好的散列函数能够将数据均匀的分布在数组上。这里重点看冲突的处理，冲突处理主要有两种方式： 链地址法 线性探测法（开放地址法） 在散列表使用中，由于冲突的存在，散列表除了要保存value外，也要保存key。查找时，需要对 key 进行比对，成功时才是真正定位到了具体数据上。 链地址法将数组看作一个个桶，具体的数据通过链表链接到桶后。java 中的 HashMap 便是使用的链地址法。而线性探测法是发生冲突时重新选择一个新的 hash 值作为索引，直到找到空位为止。 当散列表中存储数据到达一定限制后，就要调整散列表大小。比如线性探测法中，如果 存储键的数目N=数组大小M，那么永远也找到一个新的空位存放当前元素。这里需要介绍负载因子（load factor），表示散列表空间使用率。在 HashMap 中的负载因子默认为 0.75，桶的大小M*loadFactor 得到容量调整的 阈值(threshold)。所以当 键的数量N大于桶大小M*0.75 后， HashMap 会调整容量大小。具体调整多少呢？在 Java 中默认是两倍，因为散列表桶大小默认是16，而 HashMap 又使用 hash 值模上桶大小比如 key.hashcode() &amp; (length - 1) 作为桶索引。（只有在 length 为2的倍数时，&amp; 结果和 % 结果一致，如果将容量扩充为其他数量而非2的倍数，那么 &amp; 得到的索引值可能就不是均匀的分布在数组上了）。 References 为什么求模运算要用素数（质数）—— 哈希表设计 Hash时取模为什么要模质数 字符串Hash的原理与应用 HashMap 的实现原理 HashMap 转红黑树 Hash 树在 Hash 表中通常使用素数作为模运算的因子，对于一个 Hash 值，如果素数为 $x$，那么能将 Hash 值域分为 $x$ 块。再这个基础上，再做一次取模，如果用素数 $y$ 且 $y \ne x$，那么就将值域分为了 $x \times y$ 块。依次类推，形成一颗树状的表，称为 Hash 树。 References 简单理解 Hash 树 HASH树 图图由顶点(vertex, node)和边(edge)组成。假设定点集合为 V，边集合为 E，那么图可以表示为 G(V, E)，连接两点 u 和 v 的边用 e(u, v) 表示。图分为有向图和无向图，分别表示边是否有指向性。实际应用中，还会给边赋予各种各样的属性。比较具有代表性的有权值(cost)，此时称图为带权图。 图的术语对于无向图，两个定点之间如果有边连接，那么就认为两点相邻。相邻定点的序列称为路径。起点和终点重合时，路径被称为圈。任意两个点都存在路径的叫做连通图。定点的边数叫做这个顶点的度。我们称没有圈的连通图为树，没有圈的非连通图为森林。对于树，边数正好等于顶点数减一，这是一个等价条件。 对于有向图，起点为顶点 V 的边为 V 的边集。边集数目等于定点出度，重点为定点V的边的数目等于定点的入度。如果有向图没有圈，那么该图称为DAG(Directed Acyclic Graph)。 图的割点、桥与双连通分支 图的表示方法图常见的表示方法有两种： 邻接矩阵； 邻接表。 两种方法各有优缺点，适合不同的算法。接下来，记顶点和边的集合为 V 和 E ，|V| 和 |E| 分别表示顶点和边的个数，另外，将顶点编号为 $0 \cdots |V|-1$。 邻接矩阵使用 $|V| \times |V|$ 的二维数组来表示图，其中 $g[i][j]$ 表示顶点 $i$ 和顶点 $j$ 的关系，比如是否连接，或者边的权值。需要注意的是，如果图存在重边或者自环，如果使用的是无权图，那么用 $g[i][j]$ 表示边数即可，对于带权图则无法表示。同时，对于稀疏图，会存在这大量浪费空间的情况，比如表示一颗树，只需要记录 $|V|-1$ 条边，而实际上花费了 $|V|*|V|$ 的空间。 使用邻接表则完美解决上述情况，邻接表将边保存到对应的顶点处，向链表一样，指向其他顶点。使用邻接表只需要花费 $O(|V|+|E|)$的空间。 1234567891011// 邻接表表示struct vertex &#123; vector&lt;vertex*&gt; edge; //顶点属性&#125;;vertex G[Nodes];// orstruct edge &#123; int from, to, cost;&#125;;vector&lt;edge&gt; G[Nodes]; 拓扑排序References 等价、偏序、全序 拓扑排序详解 联通分量强连通分量References 有向圖強連通分量的Tarjan算法 求强连通分量-Kosaraju算法 双联通分量References Tarjan算法之-割、桥 Tarjan算法之-双联通分量 最近公共祖先References 离线-Tarjan-LCA 在线-Sparse Table-LCA 在线-倍增法-LCA 2-SATReferences 2-sat 讲解 最短路径所谓最短路径，是指给定两个顶点，找到以这两个顶点为起点和重点的路径中，边权值最小的路径。而单源最短路径则是固定一个顶点，求该点到其他所有定点的最短路的问题。 单元最短路径的算法有两种：1、Bellman-ford；2、Dijkstra 。 Bellman-ford记从顶点 $s$ 出发，到顶点 $i$ 的最短距离为 $d[i]$，那么有：$d[i]=min(d[j]+weight(j, i)|e(j,i) \in E)$ 成立。 1234567891011121314151617181920struct edge &#123; int from; int to; int cost; &#125;;edge es[MAX_E];int d[MAX_V];int V, E;void bellman_ford(int s) &#123; for (int i = 0; i &lt; V; ++i) d[i] = INF; d[s] = 0; while (true) &#123; bool update = false; for (int i = 0; i &lt; E; ++i) &#123; edge e = es[i]; if (d[e.from] != INF &amp;&amp; d[e.to] &gt; d[e.from] + e.cost) &#123; d[e.to] = d[e.from] + e.cost; update = true; &#125; &#125; if (!update) break; &#125;&#125; 上面的方法就叫做 Bellman-ford 算法，如果图中不存在从点 $s$ 可达的负圈，那么路径一定不会经过任一点两次，所以最外层循环最多执行 $|V|-1$ 次。所以总的时间复杂度为 $|V| \times |E|$。如果存在负圈，那么 $|V|$ 次一定还会更新 $d$ 的值，所以可以用此判断是否有负圈。 Dijkstra如果图中不存在负权边，那么可以用 Dijkstra 算法来求单源最短路径。在 Bellman-ford 算法中，如果 $d[j]$ 不是点 $j$ 到起点的最短路径，那么 $d[i]=d[j]+cost(j,i)$ 自然得到的也不是最短路径。而 Dijsktra 算法正好解决了这个问题，它将顶点分为两部分，一部分已经找到了最短距离，另一部分没找到。每次计算时，在还不是最短距离的集合中找到最短的那条，加到已经找到的集合中去。 那么如何更新距离呢？实际上只需要找到未使用过的顶点中的某个 $j$，和已经最短的顶点 $i$，保证 $d[i]+cost(i, j)=d[j]$ 比其余顶点都短，那么得到的 $d[j]$ 就是 $s$ 到 $j$ 的最短路径。 12345678910111213141516171819202122232425struct edge &#123; int to, cost; &#125;;typedef pair&lt;int, int&gt; P;int V, E;vector&lt;edge&gt; G[MAX_V];int d[MAX_V];void dijkstra(int s) &#123; priority_queue&lt;P, vector&lt;P&gt;, greater&lt;P&gt;&gt; que; fill(d, d+V, INF); d[s] = 0; que.push(P(0, s)); while (!que.empty()) &#123; P p = que.top(); que.pop(); int v = p.second; for (int i = 0; i &lt; G[v].size(); ++i) &#123; edge e = G[v][i]; if (d[e.to] &gt; d[v] + e.cost) &#123; d[e.to] = d[v] + e.cost; que.push(P(d[e.to], e.to)); &#125; &#125; &#125;&#125; 上面的算法在每次循环中，找出已经找到最短路径中距离 $s$ 点最短的点，然后更新与该点相邻的点的距离。这个算法的复杂度是 $O(|E| \times log(|V|))$。 Floyd-Warshall求解所有两点间的最短路的问题叫做任意两点间的最短路问题。Floyd-Warshall 算法可以在 $|V| \times |V| \times |V|$ 的时间里求得所有点的最短路径长度，同 Bellman-Ford 算法一样，可以处理负边的情况。该算法主要利用公式：$d[i][j]=min(d[i][j], d[i][k]+d[k][j])$ 的不断更新来实现。 12345678int d[MAX_V][MAX_V];int V;void warshall_floyd() &#123; for (int k = 0; k &lt; V; ++k) for (int i = 0; i &lt; V; ++i) for (int j = 0; j &lt; V; ++j) d[i][j] = min(d[i][j], d[i][k]+d[k][j]);&#125; 最小生成树给定一个图，在图上找到一棵树，那么这棵树被称为生成树。如果树的边权是所有树中最短的，这棵树被称为最短生成树。最小生成树求解有两种算法。 PrimPrim 算法和 Dijkstra 算法类似，均是从一个顶点出发，不断地添加边的算法。具体思路是假设一颗只包含一个顶点 $v$ 的树 $T$，然后贪心地选取 $T$ 和其他顶点之间相连的权值最小的边，并把它加到 $T$ 中。不断的进行该操作，直到所有节点均在 $T$ 中。其复杂度为 $O(V*V)$： 12345678910111213141516171819202122232425int cost[MAX_V][MAX_V];int mincost[MAX_V];bool used[MAX_V];int V;int prim() &#123; for (int i = 0; i &lt; V; ++i) &#123; mincost[i] = INF; used[i] = false; &#125; mincost[0] = 0; int res = 0; while (true) &#123; int v = -1; for (int u = 0; u &lt; V; u++) &#123; if (!used[u] &amp;&amp; (v == -1 || mincost[u] &lt; mincost[v])) v = u; &#125; if (v == -1) break; used[v] = true; res += mincost[v]; for (int u = 0; u &lt; V; u++) &#123; mincost[u] = min(mincost[u], cost[v][u]); &#125; &#125; return res;&#125; KruskalKruskal 算法是按照边的权值的顺序从小到大看一遍。Kruskal 在边的排序上最花时间，算法复杂度为 $O(|E| \times log(|E|))$。Kruskal 使用并查集，每次找到未使用的最小的边时，首先判断是否在一个集合。在一个集合就啥也不做，否则就把两者所在的集合合并。 12345678910111213141516171819202122struct edge &#123; int u, v, cost; &#125;;bool comp(const edge &amp;e1, const edge &amp;e2) &#123; return e1.cost &lt; e2.cost;&#125;edge es[MAX_E];int V, E;int kruskal() &#123; sort(es, es + E, comp); init_union_find(V); int res = 0; for (int i = 0; i &lt; E; i++) &#123; edge e = es[i]; if (!same(e.u, e.v)) &#123; unite(e.u, e.v); res += e.cost; &#125; &#125; return res;&#125; 二分图匹配References 二分图的最大匹配、完美匹配和匈牙利算法 二分图最佳匹配 网络流References Ford-Fulkerson 网络流详解 数学最大公约数求解最大公约数问题可以使用辗转相除法。辗转相除法实际上由一个等价公式推出：$gcd(a, b)=gcd(b, a \mod b)$，代码如下： 1234int gcd(int a, int b) &#123; if (b == 0) return a; return gcd(b, a % b);&#125; 最小公倍数最大公约数与最小公倍数在数学上存在联系：$lcm(a, b) = \dfrac{a \times b}{gcd(a, b)}$ 。只要计算出 $gcd(a, b)$，通过上式可计算 $lcm(a, b)$。 素数判断恰好有两个约数的整数被称为素数。如果 $d$ 是数 $n$ 的约数，那么 $\dfrac{n}{d}$ 也是 $n$ 的约数。因此只需要检查 $2 \to \sqrt{n}$ 范围内的整数就够了。 123456bool is_prime(int n) &#123; for (int i = 2; i * i &lt;= n; ++i) &#123; if (n % i == 0) return false; &#125; return true;&#125; 这个算法适合查询一次，如果查询多次，有另一种办法。埃氏筛法可以枚举 $n$ 以内的素数，其主要思路是将 $2 \to n$范围内的数据都写下来。其中最小的数字是 $2$，然后将所有 $2$ 的倍数全部删去。依次类推，将剩余的最小数字 $m$ 的倍数全部删去，最后得到的便是 $2 \to n$ 内所有的素数。 123456789101112int sieve(int n) &#123; int p = 0; for (int i = 0; i &lt;= n; ++i) is_prime[i] = true; is_prime[0] = is_prime[1] = false; for (int i = 0; i &lt;= n; ++i) &#123; if (is_prime[i]) &#123; prime[p++] = i; for (int j = 2 * i; j &lt;= n; j += i) is_prime[j] = false; &#125; &#125; return p;&#125; 快速幂快速幂实际上应用了二进制优化的思想。对于 $k^m$ 有 $k^{1+2+\cdots+i=m}=k^1 \times k^2 \times \cdots \times k^i$。 123456789int pow(int x, unsigned int m) &#123; int res = 1; while (m &gt; 0) &#123; if (m &amp; 1) res *= x; x = x * x; m &gt;&gt;= 1; &#125; return res;&#125; OthersReferences 数论四大定理 扩展欧几里得算法 关于取模运算和求逆元]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Computer Science Knowledge System]]></title>
    <url>%2F2017%2F06%2F13%2FComputer-Science-Knowledge-System%2F</url>
    <content type="text"><![CDATA[数据结构与算法CSKS-(一)、数据结构和算法 数据库CSKS-(二)、数据库系统 操作系统操作系统是管理和控制计算机硬件与软件资源的计算机程序，功能包括管理计算机系统的硬件、软件及数据资源，控制程序运行，改善人机界面，为其它应用软件提供支持，让计算机系统所有资源最大限度地发挥作用，提供各种形式的用户界面，使用户有一个好的工作环境，为其它软件的开发提供必要的服务和相应的接口等。 操作系统主要有五大功能：处理机管理（CPU）、进程管理、内存管理、设备管理和文件系统管理。 调度进程时用户提交给操作系统运行的最小单元。在学术上，进程是具有一定功能的程序关于某个数据集合上的一次运行活动，是系统进行资源调度和分配的一个独立单位。除了进程，操作系统还提供了更小粒度的调度对象-线程。线程是进程的实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。一个进程可以有多个线程，多个线程也可以并发执行。 一般情况下，系统按照以下流程创建一个进程： 分配、初始化 PCB 初始化机器寄存器 拷贝、初始化内存页表 从硬盘加载程序代码到内存 将进程加入就绪队列 进程调度时，选择该进程并切换到用户态开始执行进程 系统通过快速切换进程，让每一个进程都有一定的时间片来响应用户提交的请求；在用户的视角，好像每个进程都在同时执行一样。系统切换进程的方法叫做进程调度算法，基本的调度算法有：先来先服务、时间片轮转、短作业优先、优先级调度以及多级反馈队列调度。 除了进程切换，操作系统还负责管理进程的虚拟内存。一般情况下，系统会在硬盘上开辟一个空间作为交换区，用于在物理内存不足时选择性地交换部分虚拟页，以开辟出足够的物理空间。用于选择交换的页面的算法称为页面置换算法。基本的页面置换算法有：FIFO、第二次机会、时钟轮转、LRU 和 NRU。 References 操作系统常用调度算法-cnblogs 操作系统核心原理-3.进程原理（上）：进程概要 操作系统核心原理-3.进程原理（中）：进程调度 虚拟内存详解-cnblogs 操作系统学习-内存管理 操作系统学习-虚拟内存 通信线程之间共享内存，但拥有各自不同的运行栈；进程之间则相互隔离。线程之间并发需要解决的是线程同步问题，进程之间则是通信问题。 线程之间同步由四种基本操作提供： 原子操作 互斥量 信号量 条件变量 在以上四种基本操作的基础上，形成了高级通信工具。如：阻塞队列，共享内存等。 一般情况下，原子变量用于构造乐观锁，比如 spinlock 。其他情况下使用条件变量和互斥量结合起来足够完成任务，同时还不容易出错。如果使用信号量，需要在自己的程序里也维护计数值，而信号量本身也需要维护计数值，需要用户自己进行维护。 与信号量相比，互斥量增减了所有权的概念；锁住的互斥量只能由上锁的线程解开。信号量则没有这些限制。条件变量与信号量相比，没有了数量限制，资源数量隐含在程序的逻辑中。 信号量与另外两者的区别主要在于“同步”一词，同步可以看作两部分：一部分是等待数据的“事件”或者“通知”；另一部分是保护数据的“临界区”。信号量直接满足这两个功能，互斥锁与信号量各满足一部分。在 do one thing and do it best 的指导下，更建议使用后两者。linux 内核曾将信号量作为同步原语，后来将之换为了互斥锁，需要“通知”的场景则换成了条件变量，不仅代码变简单了，速度也上去了。 进程之间通信常用的方式有： 管道 共享内存 信号 消息队列 socket RPC(Remote Process Call) 其中管道、信号、共享内存和消息队列只能运行在一台机器上，而 socket 和 RPC 则提供了远程支持。当然，也有在 socket 或 RPC 基础上实现消息队列的。一般需要实现进程间通信，可以直接考虑 socket 或 RPC，毕竟以后的业务场景有可能扩展到多机。 References 操作系统核心原理-3.进程原理（下）：进程通信 死锁在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。 死锁产生的四个条件（有一个条件不成立，则不会产生死锁） 互斥条件：一个资源一次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放 不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 只要上述一个条件不成立，就不会产生死锁，所以解决死锁的基本方法有：：预防死锁、避免死锁、检测死锁、解除死锁。其常用策略为：鸵鸟策略、预防策略、避免策略、检测与解除死锁。 LinuxReferences Linux man 第十二章、學習 Shell Scripts 计算机网络计算机网网络总结 从 URL 到页面的过程// TODO: 分层与协议TCPTCP 是面向连接的、可靠的流式通信传输协议；UDP 是无连接的、不可靠的通信协议。 Nagle 算法糊涂窗口综合症和 Nagle 算法Nagle &amp; Delayed ACKDelayed ACKLinux TCP 编程 拥塞控制流量控制滑动窗口 UDP可靠 UDP 传输 HTTPHTTP（超文本传输协议，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW 文件都必须遵守这个标准。设计HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。是用于从 WWW 服务器传输超文本到本地浏览器的传输协议。默认使用 80 端口，HTTP 客户端发起一个请求，建立一个到服务器指定端口（默认是 80 端口）的 TCP 连接。 HTTP 连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。HTTP/1.0 是第一个在通讯中指定版本号的 HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。HTTP/1.1 是当前版本，持久连接被默认采用，并能很好地配合代理服务器工作，还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。 HTTP／2.0 在 HTTP 1.x 的基础上，大幅度的提高了 web 性能，减少了网络延迟。HTTP1.0 和 1.1 在之后很长的一段时间内会一直并存，这是由于网络基础设施更新缓慢所决定的。 关于更多 HTTP 协议的基础信息，可以看HTTP基础、HTTP 请求方法和幂等性探究、理解 HTTP 幂等性。 HTTP 以 TCP 作为传输协议，自然要面临链接管理的问题，HTTP连接管理、谈谈 HTTP 连接管理。 另外，随着网络访问量的提升，性能瓶颈问题开始出现。HTTP 对于这部分问题的解决办法是：对固定的资源进行缓存。HTTP 缓存通常分为：强制缓存、对比缓存。关于 HTTP 缓存的具体内容参考：HTTP缓存机制。 最后，关于 HTTP 协议中常见的两种攻击方式：用大白话谈谈XSS与CSRF。 References HTTP 2.0 资料汇总 SSL/TLSSSL/TLS 原理详解。 IO 模型// TODO: 分布式CAP 理论和 BASE 理论References CAP 理论 CAP 理论和最终一致性 最终一致性实现方式 CAP 理论和 BASE 理论 一致性 HashReferences 每天进步一点点——五分钟理解一致性哈希算法(consistent hashing) 一致性Hash算法原理 一致性Hash算法Java实现 设计模式CSKS-(三)、设计模式 语言C++References C++11 标准基本数据类型 类型转换References C++11 四种类型转换 C++笔记 · C++类型转换 最佳实践References Accustoming Yourself to C++ Constructors,Destructors,and Assignment Operators Resource management Designs &amp; Implements Exception-safe code C++对象线程安全 C++ 疑难解答References 取余和取模 带符号整数的除法和余数 C++并发编程那些事 深入理解右值引用-move语义和完美转发 C++完全总结 Java类加载原理Java和其他语言不同的是，Java是运行于Java虚拟机(JVM)。这就意味着编译后的代码是以一种和平台无关的格式保存的，而不是某种特定的机器上运行的格式。这种格式和传统的可执行代码格式有很多重要的区别。具体来说，不同于C或者Ｃ++程序，Java程序不是一个独立的可执行文件，而是由很多分开的类文件组成，每个类文件对应一个Java类。另外，这些类文件并不是马上加载到内存，而是当程序需要的时候才加载。类加载器就是Java虚拟机中用来把类加载到内存的工具。 Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该元信息对象可以获知Class的结构信息：如构造函数，属性和方法等，Java允许用户借由这个Class相关的元信息对象间接调用Class对象的功能。虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 工作机制类装载器就是寻找类的字节码文件，并构造出类在JVM内部表示的对象组件。在Java中，类装载器把一个类装入JVM中，要经过以下步骤： 装载：查找和导入Class文件； 链接：把类的二进制数据合并到JRE中； 校验：检查载入Class文件数据的正确性； 准备：给类的静态变量分配存储空间； 解析：将符号引用转成直接引用； 初始化：对类的静态变量，静态代码块执行初始化操作 类初始化时机 遇到 new、getstatic、putstatic 或 invokestatic 这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用 new 关键字实例化对象的时候，读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 只有上述四种情况会触发初始化，也称为对一个类进行主动引用，除此以外，所有其他方式都不会触发初始化，称为被动引用。 数据类型Java 中数据类型分为两种：基本数据类型，引用数据类型。 基础数据类型基础数据类型由数值型、字符型和布尔型组成，其中数值型有： byte short int long float double 字符型：char 可以表示任意有 unicode 编码的值，2字节长度。布尔型 boolean 表示逻辑运算类型。 char 本质上是 UTF-16 定常编码，换而言之，char 中只能存放 UTF-16 编码下只占2字节长度的字符。 自动类型转换自动类型转换，也称隐式类型转换，是指不需要书写代码，由系统自动完成的类型转换。由于实际开发中这样的类型转换很多，所以 Java 语言在设计时，没有为该操作设计语法，而是由 JVM 自动完成。 转换规则：从存储范围小的类型到存储范围大的类型。具体规则为：byte→short(char)→int→long→float→double 也就是说 byte 类型的变量可以自动转换为 short 类型，示例代码： 12byte b = 10;short sh = b; 这里在赋值时，JVM 首先将 b 的值转换为 short 类型，然后再赋值给 sh。在类型转换时可以跳跃。示例代码： 12byte b1 = 100;int n = b1; 类型转换中可能存在着坑： 123short a = 0;a = a + 1; // errora += 1; 执行 +1 时，a 被转换为整形，然后做加法，赋值给 a 时类型不一致，需要强制类型转换；而 += 则由编译器内部实现 +1 逻辑。 注意问题:在整数之间进行类型转换时，数值不发生改变，而将整数类型，特别是比较大的整数类型转换成小数类型时，由于存储方式不同，有可能存在数据精度的损失。 强制类型转换强制类型转换，也称显式类型转换，是指必须书写代码才能完成的类型转换。该类类型转换很可能存在精度的损失，所以必须书写相应的代码，并且能够忍受该种损失时才进行该类型的转换。 转换规则:从存储范围大的类型到存储范围小的类型。具体规则为：double→float→long→int→short(char)→byte语法格式为：(转换到的类型)需要转换的值 示例代码： 12double d = 3.10;int n = (int)d; 这里将 double 类型的变量 d 强制转换成 int 类型，然后赋值给变量 n。需要说明的是小数强制转换为整数，采用的是去 1 法，也就是无条件的舍弃小数点的所有数字，则以上转换出的结果是 3。整数强制转换为整数时取数字的低位，例如 int 类型的变量转换为 byte 类型时，则只去 int 类型的低 8 位(也就是最后一个字节)的值。示例代码： 1234int n = 123;byte b = (byte)n;int m = 1234;byte b1 = (byte)m; 则 b 的值还是 123，而 b1 的值为 -46。b1 的计算方法如下：m 的值转换为二进制是 10011010010，取该数字低 8 位的值作为 b1 的值，则 b1 的二进制值是 11010010，按照机器数的规定，最高位是符号位，1 代表负数，在计算机中负数存储的是补码，则该负数的原码是 10101110，该值就是十进制的 -46。 注意问题:强制类型转换通常都会存储精度的损失，所以使用时需要谨慎。 引用数据类型引用数据类型有三大类： 接口 对象 数组 引用数据类型也存在着自动转换和强制类型转换，自动转换负责将子类对象转换成父类对象，强制转换则将父类对象转换成子类对象。 Objectjava.lang 包在使用的时候无需显示导入，编译时由编译器自动导入。Object 类是类层次结构的根，Java 中所有的类从根本上都继承自这个类。Object 类是 Java 中唯一没有父类的类。其他所有的类，包括标准容器类，比如数组，都继承了 Object 类中的方法。 Object 类中有如下方法： clone()clone 方法创建并返回对象的一份拷贝，其原型如下： 1protected Object clone() throws CloneNotSupportedException 这个方法有两点比较特殊的： 使用这个方法的类必须实现 java.lang.Cloneable 接口，否则会抛出 CloneNotSupportedException 异常。Cloneable 接口中不包含任何方法，所以实现它时只要在类声明中加上 implements 语句即可； 这个方法是 protected 修饰的，覆写 clone() 方法的时候需要写成 public，才能让类外部的代码调用； equals(Object obj)equals 方法等价于 == 运算符，用于判断两个对象是否指向同一个对象。 在 Java 中，== 运算符默认使用引用语义，即比较两个对象是否引用同一对象；C/C++ 相反，默认使用值语义，比较内部数据是否相同。 Object 类中的 equals() 方法如下： 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 即 Object 类中的 equals() 方法等价于 ==，只有当继承 Object 的类覆写（override）了 equals() 方法之后，继承类实现了用 equals() 方法比较两个对象是否相等，才可以说 equals() 方法与 == 不同。比如 String 类覆写了 equals() 方法，实现了值语义。 equals() 方法需要具有如下特点： 自反性：任何非空引用 x，x.equals(x)返回为 true; 对称性：任何非空引用 x 和 y，x.equals(y) 返回 true 当且仅当 y.equals(x) 返回 true; 传递性：任何非空引用 x 和 y，如果 x.equals(y) 返回 true，并且 y.equals(z) 返回 true，那么 x.equals(z) 返回 true。 一致性：两个非空引用 x 和 y，x.equals(y) 的多次调用应该保持一致的结果，（前提条件是在多次比较之间没有修改 x 和 y 用于比较的相关信息）。 约定：对于任何非空引用 x，x.equals(null) 应该返回为 false。 并且覆写 equals() 方法时，应该同时覆写 hashCode() 方法，反之亦然。 前面三个特点属于等价关系需要满足的条件，所以对于任何非空引用，equals() 方法定义了该引用上的等价关系。 hashCode()hashCode() 返回当前对象的 hash code，原型如下： 1int hashCode() 这个方法返回一个整型值（hash code value），如果两个对象被 equals() 方法判断为相等，那么它们就应该拥有同样的hash code。 Object 类的 hashCode() 方法为不同的对象返回不同的值，Object 类的 hashCode 值表示的是对象的地址。 hashCode 方法需要满足一定条件： 一致性：hashCode() 方法多次执行结果应该相同（未修改时）； 当你覆写了 equals() 方法之后，必须也覆写 hashCode() 方法，反之亦然； 如果 equals() 判断两个对象不相等，那么它们的 hashCode() 方法就应该返回不同的值（未强制要求）； 两个对象用 equals() 方法比较返回 false，它们的 hashCode 可以相同也可以不同。 toString()toString() 方法返回对象的 String 表示。当打印引用，如调用 System.out.println() 时，会自动调用对象的 toString() 方法，打印出引用所指的对象的 toString() 方法的返回值，因为每个类都直接或间接地继承自 Object，因此每个类都有 toString() 方法。 Object 类中的 toString() 方法定义如下： 123public String toString() &#123; return getClass().getName() + "@" + Integer.toHexString(hashCode());&#125; finalize()References Java finalize() 方法详解 getClass()References Java getClass() 方法详解 OthersReferences Java Object wait()、notify()、notifyAll() 泛型References Java 泛型基础 Java 泛型 &lt;? super T&gt; 中 super 怎么 理解？与 extends 有何不同？ Java 泛型进阶 浅谈 Java 泛型 Array数组比较特殊，其有一个 length 成员，表示数组长度。 References Java 数组操作 Java Arrays 详解 StringReferences String 类常用方法详解 String 类详解 String StringBuffer StringBuilder 详解 CollectionCollection是Java中的集合类的一个抽象接口，在其上有更具体的接口实现：Set和List。 References Java Collection 详解 SetSet中方法与Collection一致。 HashSet：内部数据结构是哈希表，是不同步的。Set集合中元素都必须是唯一的，HashSet作为其子类也需保证元素的唯一性。 判断元素唯一性的方式： 通过存储对象（元素）的hashCode和equals方法来完成对象唯一性的。 如果对象的hashCode值不同，那么不用调用equals方法就会将对象直接存储到集合中； 如果对象的hashCode值相同，那么需调用equals方法判断返回值是否为true， 若为false, 则视为不同元素，就会直接存储； 若为true， 则视为相同元素，不会存储。 PS：如果要使用HashSet集合存储元素，该元素的类必须覆盖hashCode方法和equals方法。一般情况下，如果定义的类会产生很多对象，通常都需要覆盖equals，hashCode方法。建立对象判断是否相同的依据。 TreeSet：保证元素唯一性的同时可以对内部元素进行排序，是不同步的。 判断元素唯一性的方式： 根据比较方法的返回结果是否为0，如果为0视为相同元素，不存；如果非0视为不同元素，则存。 TreeSet对元素的排序有两种方式： 方式一：使元素（对象）对应的类实现Comparable接口，覆盖compareTo方法。这样元素自身具有比较功能。 方式二：使TreeSet集合自身具有比较功能，定义一个类实现Comparable接口覆盖其compareTo方法。（相当于自定义了一个比较器）将该类对象作为参数传递给TreeSet集合的构造函数。（TreeSet(Comparator&lt;? super E&gt; c)） MapMap保存具有映射关系的数据，因此Map集合里保存着两组值，一组值用来保存Map里的key,一组用来保存Map里的value,key和value可以是任何引用类型的数据。 Map里的key不允许重复，value可以重复。key和value之间存在单向的一对一的关系，通过指定的key，总能找到唯一的、确定的value。 HashMap与HashTableHashMap与HashTable都是Map的典型实现类，他们之间的关系类似于ArrayList和Vector：HashTable是一个古老的Map实现类，在JDK1.0时就出现了。主要区别： HashTable是一个线程安全的Map实现，但是HashMap是线程不安全的实现，HashMap的性能要比HashTable高一些，尽量避免使用HashTable,多个线程访问一个Map对象又要保证线程安全时，可以使用Collections中的方法把HashMap变成线程安全的。 HashTable不允许使用null作为key和value,如果试图把null加入HashTable中，将会引发空指针异常。 TreeMapTreeMap是Map的子接口SortedMap的的实现类，与TreeSet类似的是TreeMap也是基于红黑树对TreeMap中所有的key进行排序，从而保证key-value处于有序状态，TreeMap也有两种排序方式： 自然排序：TreeMap的所有key必须实现Comparable接口，而且所有key应该是同一类的对象，否则会抛出ClassCastException. 定制排序：创建TreeMap时，传入一个Comparator对象，该对象负责对TreeMap中所有的key进行排序。由于TreeMap支持内部排序，所以通常要比HashMap和HashTable慢。 QueueQueue模拟了队列这种数据结构，队列通常是“先进先出”的数据结构，通常不允许随机访问队列中的元素。 Queue常用的实现类：LinkedList和PriorityQueue。 LinkedListLinkedList它不仅实现了List接口还实现了Dueue接口(双端队列，既具有队列的特征，也具有栈的特征)，Dueue接口是Queue的子接口。 PriorityQueuePriorityQueue保存队列元素的的顺序并不是按照加入队列的顺序，而是按照队列元素大小进行重新排序。所以当调用peek和poll方法来取队列中的元素的时候，并不是先取出来队列中最小的元素。从这个意义上来看，PriorityQueue已经违反了队列的基本规则。PriorityQueue不允许插入null元素。 ConcurrentReferences Java 并发工具包 java.util.concurrent 用户指南 PythonReferences Python3 教程 系统设计References 系统设计入门 OthersMarkdownReferences Markdown-语法手册 Markdown-书写风格指南 LatexReferences Latex 数学公式 需要补充分布式架构：（了解原理就行，如果真的有实践经验更好）CAP原理和BASE理论。Nosql与KV存储（redis，hbase，mongodb，memcached等）服务化理论（包括服务发现、治理等，zookeeper、etcd、springcloud微服务、）负载均衡（原理、cdn、一致性hash）RPC框架（包括整体的一些框架理论，通信的netty，序列化协议thrift，protobuff等）消息队列（原理、kafka，activeMQ，rocketMQ）分布式存储系统（GFS、HDFS、fastDFS）、存储模型（skipList、LSM等）分布式事务、分布式锁等 大数据与数据分析：hadoop生态圈(hive、hbase、hdfs、zookeeper、storm、kafka)spark体系语言：python、R、scala搜索引擎与技术机器学习算法：模型和算法很多。其他工具的理论和使用：这个更多了，问的多的比如git、docker、maven/gradle、Jenkins等等 常见面试题整理–数据库篇常见面试题整理–操作系统篇Java 面试题全集-上Java 面试题全集-下常见面试题整理 Python 概念篇常见面试题整理 Python 代码篇常见面试题整理–计算机网络篇计算机网络基础面试题]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 85 Maximal Rectangle]]></title>
    <url>%2F2017%2F06%2F12%2FLeetCode-85-Maximal-Rectangle%2F</url>
    <content type="text"><![CDATA[85. Maximal Rectangle 首先看题意，题目需要求出由0和1组成的2Dmatrix中，全由1组成的矩形最大面积为多少。比如下面的矩形： 12341 0 1 0 01 0 1 1 11 1 1 1 11 0 0 1 0 最大面积为 6。 在做这提前，需要看看前一题：84. Largest Rectangle in Histogram。这道题目是求出柱状图中可以摆放下的最大矩形。 如何求解？仔细观察可以发现，像 576 这样的数据，可以看作中间高，两边低。而具体面积则由数据个数 * 选取区间中最矮的高度决定。所以完全可以把这几个变为：555、7和66这样的形式，然后再从中选出最大的。 所以这道题的简单解法是从头到尾扫一次，每次遇到递减时，将多出的部分计算后给扔掉，那么扔掉后的数据则仍然是递增的。比如576，当扫描到6时，计算得7，并将7改为6，得到566继续计算。这样，得到了中间去掉部分能组成的最大面积，和最后剩下的递增数组进行比较。对于单调递增的数据，也好算，减少宽度，增加高度就能算出来。所以代码部分如下： 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; stack&lt;int&gt; stack; int max_ = 0; for (auto i : heights) &#123; if (stack.empty()) stack.push(i); else &#123; int l = stack.top(); if (l &lt;= i) &#123; stack.push(i); &#125; else &#123; int count = 1; while (!stack.empty() &amp;&amp; stack.top() &gt; i) &#123; int t = stack.top(); stack.pop(); if (t * count &gt; max_) &#123; max_ = t * count; &#125; count++; &#125; for (int j = 0; j &lt; count; j++) &#123; stack.push(i); &#125; &#125; &#125; &#125; if (!stack.empty()) &#123; int count = stack.size(); for (int i = 1; i &lt;= count; ++i) &#123; int t = stack.top(); stack.pop(); if (t * i &gt; max_) max_ = t * i; &#125; &#125; return max_; &#125;&#125;; 现在回到计算matrix中的矩形问题上来。用一行将矩形分割成两半，上面部分和下面部分。遮住下面部分，那么看到的就是一个Histogram，则可以使用上面一题的解法来做。将行往下挪，如果出现了(1/0/1)这样的列数据，不再是一个Histogram，那么可以认为0以上部分全为0，得到Histogram。所以题目答案为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123;public: int maximalRectangle(vector&lt;vector&lt;char&gt;&gt;&amp; matrix) &#123; if (matrix.empty() || matrix[0].empty()) return 0; int max = 0; vector&lt;int&gt; heights(matrix[0].size(), 0); for (int i = 0; i &lt; matrix.size(); ++i) &#123; for (int j = 0; j &lt; matrix[0].size(); ++j) &#123; heights[j] = (matrix[i][j] == &apos;0&apos;) ? 0 : heights[j] + 1; &#125; max = std::max(largestRectangleArea(heights), max); &#125; return max; &#125; int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; stack&lt;int&gt; stack; int max_ = 0; for (auto i : heights) &#123; if (stack.empty()) stack.push(i); else &#123; int l = stack.top(); if (l &lt;= i) &#123; stack.push(i); &#125; else &#123; int count = 1; while (!stack.empty() &amp;&amp; stack.top() &gt; i) &#123; int t = stack.top(); stack.pop(); if (t * count &gt; max_) &#123; max_ = t * count; &#125; count++; &#125; for (int j = 0; j &lt; count; j++) &#123; stack.push(i); &#125; &#125; &#125; &#125; if (!stack.empty()) &#123; int count = stack.size(); for (int i = 1; i &lt;= count; ++i) &#123; int t = stack.top(); stack.pop(); if (t * i &gt; max_) max_ = t * i; &#125; &#125; return max_; &#125;&#125;;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SO_REUSEADDR & SO_REUSEPORT 异同]]></title>
    <url>%2F2017%2F06%2F04%2FSO-REUSEADDR-SO-REUSEPORT-%E5%BC%82%E5%90%8C%2F</url>
    <content type="text"><![CDATA[2018-1-15 日更新：这里贴上 man 7 socket 中对 SO_REUSEADDR 和 SO_REUSEPORT 的说明，大有裨益。 SO_REUSEADDR Indicates that the rules used in validating addresses supplied in a bind(2) call should allowreuse of local addresses. For AF_INET sockets this means that a socket may bind, except whenthere is an active listening socket bound to the address. When the listening socket is boundto INADDR_ANY with a specific port then it is not possible to bind to this port for any localaddress. Argument is an integer boolean flag. SO_REUSEPORT (since Linux 3.9) Permits multiple AF_INET or AF_INET6 sockets to be bound to an identical socket address. Thisoption must be set on each socket (including the first socket) prior to calling bind(2) on thesocket. To prevent port hijacking, all of the processes binding to the same address must havethe same effective UID. This option can be employed with both TCP and UDP sockets. For TCP sockets, this option allows accept(2) load distribution in a multi-threaded server tobe improved by using a distinct listener socket for each thread. This provides improved loaddistribution as compared to traditional techniques such using a single accept(2)ing thread thatdistributes connections, or having multiple threads that compete to accept(2) from the samesocket. For UDP sockets, the use of this option can provide better distribution of incoming datagramsto multiple processes (or threads) as compared to the traditional technique of having multipleprocesses compete to receive datagrams on the same socket. 写在前面，本文转载自网络：http://blog.chinaunix.net/uid-28587158-id-4006500.html ，请保留出处。 文章内容来源于stackoverflow上的回答，写的很详细http://stackoverflow.com/questions/14388706/socket-options-so-reuseaddr-and-so-reuseport-how-do-they-differ-do-they-mean-t 虽然不同的系统上socket的实现方式有一些差异，但都来源于对BSD socket的实现，因此在讨论其它系统之前了解BSD socket的实现是非常有益的。首先我们需要了解一些基本知识，一个TCP/UDP连接是被一个五元组确定的： 1&#123;&lt;protocol&gt;, &lt;src addr&gt;, &lt;src port&gt;, &lt;dest addr&gt;, &lt;dest port&gt;&#125; 因此，任何两个连接都不可能拥有相同的五元组，否则系统将无法区别这两个连接。 当使用socket()函数创建套接字的时候，我们就指定了该套接字使用的protocol(协议)，bind()函数设置了源地址和源端口号，而目的地址和目的端口号则由connect()函数设定。尽管允许对UDP进行”连接”（在某些情况下这对应用程序的设计非常有帮助）但由于UDP是一个无连接协议，UDP套接字仍然可以不经连接就使用。”未连接”的UDP套接字在数据被第一次发送之前并不会绑定，只有在发送的时候被系统自动绑定，因此未绑定的UDP套接字也就无法收到（回复）数据。未绑定的TCP也一样，它将在连接的时候自动绑定。 如果你明确绑定一个socket，把它绑定到端口0是可行的，它意味着”any port”(“任意端口”)。由于一个套接字无法真正的被绑定到系统上的所有端口，那么在这种情况下系统将不得不选择一个具体的端口号（指的是”any port”）。源地址使用类似的通配符，也就是”any address” （IPv4中的0.0.0.0和IPv6中的::）。和端口不同的是，一个套接字可以被绑定到任意地址(any address)，这里指的是本地网络接口的所有地址。由于socket无法在连接的时候同时绑定到所有源IP地址，因此当接下来有一个连接过来的时候，系统将不得不挑选一个源IP地址。考虑到目的地址和路由表中的路由信息，系统将会选择一个合适的源地址，并将任意地址替换为一个选定的地址作为源地址。 默认情况下，任意两个socket都无法绑定到相同的源IP地址和源端口(即源地址和源端口号均相同)。只要源端口号不相同，那么源地址实际上没什么关系。将socketA绑定到地址A和端口X （A:X)，socketB绑定到地址B和端口Y (B:Y)，只要X != Y，那么这种绑定都是可行的。然而当X == Y的时候只要A != B，这种绑定方式也仍然可行，比如：一个FTP server的socketA绑定为192.168.0.1:21而属于另一个FTP server的socketB绑定为 10.0.0.1:21，这两个绑定都将成功。记住：一个socket可能绑定到本地”any address”。例如一个socket绑定为 0.0.0.0:21，那么它同时绑定了所有的本地地址，在这种情况下，不论其它的socket选择什么特定的IP地址，它们都无法绑定到21端口，因为0.0.0.0和所有的本地地址都会冲突。 上面说的对所有主流操作系统都是一样的。当涉及到地址重用的时候，OS之间的差异就显现出来了，正如之前所说的那样，其它的实现方案都来源于BSD的实现，因此我们首先从BSD说起。 BSDSO_REUSEADDR如果在绑定一个socket之前设置了SO_REUSEADDR，除非两个socket绑定的源地址和端口号都一样，那么这两个绑定都是可行的。也许你会疑惑这跟之前的有什么不一样？关键是SO_REUSEADDR改变了在处理源地址冲突时对通配地址(“any ip address”)的处理方式。 当没有设置SO_REUSEADDR的时候，socketA先绑定到0.0.0.0:21，然后socketB绑定到192.168.0.1:21的时候将会失败(EADDRINUSE错误)，因为0.0.0.0意味着”任意本地IP地址”，也就是”所有本地IP地址“，因此包括192.168.0.1在内的所有IP地址都被认为是已经使用了。但是在设置SO_REUSEADDR之后socketB的绑定将会成功，因为0.0.0.0和192.168.0.1事实上不是同一个IP地址，一个是代表所有地址的通配地址，另一个是一个具体的地址。注意上面的表述对于socketA和socketB的绑定顺序是无关的，没有设置SO_REUSEADDR，它们将失败，设置了SO_REUSEADDR，它将成功。 下面给出了一个表格列出了所有的可能组合： 12345678910SO_REUSEADDR socketA socketB Result--------------------------------------------------------------------- ON/OFF 192.168.0.1:21 192.168.0.1:21 Error (EADDRINUSE) ON/OFF 192.168.0.1:21 10.0.0.1:21 OK ON/OFF 10.0.0.1:21 192.168.0.1:21 OK OFF 0.0.0.0:21 192.168.1.0:21 Error (EADDRINUSE) OFF 192.168.1.0:21 0.0.0.0:21 Error (EADDRINUSE) ON 0.0.0.0:21 192.168.1.0:21 OK ON 192.168.1.0:21 0.0.0.0:21 OK ON/OFF 0.0.0.0:21 0.0.0.0:21 Error (EADDRINUSE) 上面的表格假定socketA已经成功绑定，然后创建socketB绑定给定地址在是否设置SO_REUSEADDR的情况下的结果。Result代表socketB的绑定行为是否会成功。如果第一列是ON/OFF，那么SO_REUSEADDR的值将是无关紧要的。 现在我们知道SO_REUSEADDR对通配地址有影响，但这不是它唯一影响到的方面。还有一个众所周知的影响同时也是大多数人在服务器程序上使用SO_REUSEADDR的首要原因。为了了解其它SO_REUSEADDR重要的使用方式，我们需要深入了解TCP协议的工作方式。 一个socket有一个发送缓冲区，当调用send()函数成功后，这并不意味着所有数据都真正被发送出去了，它只意味着数据都被送到了发送缓冲区中。对于UDP socket来说，如果不是立刻发送的话，数据通常也会很快的发送出去，但对于TCP socket，在数据加入到缓冲区和真正被发送出去之间的时延会相当长。这就导致当我们close一个TCP socket的时候，可能在发送缓冲区中保存着等待发送的数据(由于send()成功返回，因此你也许认为数据已经被发送了)。如果TCP的实现是立刻关闭socket，那么所有这些数据都会丢失而你的程序根本不可能知道。TCP被称为可靠协议，像这种丢失数据的方式就不那么可靠了。这也是为什么当我们close一个TCP socket的时候，如果它仍然有数据等待发送，那么该socket会进入TIME_WAIT状态。这种状态将持续到数据被全部发送或者发生超时。 在内核彻底关闭socket之前等待的总时间(不管是否有数据在发送缓冲区中等待发送)叫做Linger Time。Linger Time在大部分系统上都是一个全局性的配置项而且在默认情况下时间相当长(在大部分系统上是两分钟)。当然对于每个socket我们也可以使用socket选项SO_LINGER进行配置，可以将等待时间设置的更长一点儿或更短一点儿甚至禁用它。禁用Linger Time绝对是一个坏主意，虽然优雅的关闭socket是一个稍微复杂的过程并且涉及到来回的发送数据包(以及在数据包丢失后重发它们)，并且这个过程还受到Linger Time的限制。如果禁用Linger Time，socket可能丢失的不仅仅是待发送的数据，而且还会粗暴的关闭socket，在绝大部分情况下，都不应该这样使用。如何优雅的关闭TCP连接的细节不在这里进行讨论，如果你想了解更多，我建议你阅读：http://www.freesoft.org/CIE/Course/Section4/11.html。而且如果你用SO_LINGER禁用了Linger Time,而你的程序在显式的关闭socket之前就终止的话，BSD(其它的系统也有可能)仍然会等待，而不管已经禁用了它。这种情况的一个例子就是你的程序调用了exit()(在小的服务器程序很常见)或者进程被信号杀死(也有可能是进程访问了非法内存而终止)。这样的话，不管在什么情况下，你都无法对某一个socket禁用linger了。 问题在于，系统是怎样看待TIME_WAIT状态的？如果SO_REUSEADDR还没有设置，一个处在TIME_WAIT的socket仍然被认为绑定在源地址和端口，任何其它的试图在同样的地址和端口上绑定一个socket行为都会失败直到原来的socket真正的关闭了，这通常需要等待Linger Time的时长。所以不要指望在一个socket关闭后立刻将源地址和端口绑定到新的socket上，在绝大部分情况下，这种行为都会失败。然而，在设置了SO_REUSEADDR之后试图这样绑定(绑定相同的地址和端口)仅仅只会被忽略，而且你可以将相同的地址绑定到不同的socket上。注意当一个socket处于TIME_WAIT状态，而你试图将它绑定到相同的地址和端口，这会导致未预料的结果，因为处于TIME_WAIT状态的socket仍在”工作”，幸运的是这种情况极少发生。 对于SO_REUSEADDR你需要知道的最后一点是只有在你想绑定的socket开启了地址重用(address reuse)之后上面的才会生效，不过这并不需要检查之前已经绑定或处于TIME_WAIT的socket在它们绑定的时候是否也设置这个选项。也就是说，绑定的成功与否只会检查当前bind的socket是否开启了这个标志，不会查看其它的socket。 SO_REUSEPORTSO_REUSEPORT的含义与绝大部分人对SO_REUSEADDR的理解一样。基本上说来，SO_REUSEPORT允许你将多个socket绑定到相同的地址和端口只要它们在绑定之前都设置了SO_REUSEPORT。如果第一个绑定某个地址和端口的socket没有设置SO_REUSEPORT，那么其他的socket无论有没有设置SO_REUSEPORT都无法绑定到该地址和端口直到第一个socket释放了绑定。 SO_REUSEPORT并不表示SO_REUSEADDR。这意味着如果一个socket在绑定时没有设置SO_REUSEPORT，那么同预期的一样，其它的socket对相同地址和端口的绑定会失败，但是如果绑定相同地址和端口的socket正处在TIME_WAIT状态，新的绑定也会失败。当有个socket绑定后处在TIME_WAIT状态(释放时)时，为了使得其它socket绑定相同地址和端口能够成功，需要设置SO_REUSEADDR或者在这两个socket上都设置SO_REUSEPORT。当然，在socket上同时设置SO_REUSEPORT和SO_REUSEADDR也是可行的。 关于SO_REUSEPORT除了它在被添加到系统的时间比SO_REUSEPORT晚就没有其它需要说的了，这也是为什么在有些系统的socket实现上你找不到这个选项，因为这些系统的代码都是在这个选项被添加到BSD之前fork了BSD，这样就不能将两个socket绑定到真正相同的“地址” (address+port)。 Connect() Returning EADDRINUSE?绝大部分人都知道bind()可能失败返回EADDRINUSE，然而当你开始使用地址重用(address reuse)，你可能会碰到奇怪的情况:connect() 失败返回同样的错误EADDRINUSE。怎么会出现这种情况了? 一个远端地址(remote address)毕竟是connect添加到socket上的，怎么会已经被使用了? 将多个socket连接到相同的远端地址从来没有出现过这样的情况，这是为什么了？ 正如我在开头说过的，一个连接是被一个五元组定义的。同样我也说了任意两个连接的五元组不能完全一样，因为这样的话内核就没办法区分这两个连接了。然而，在地址重用的情况下，你可以把同协议的两个socket绑定到完全相同的源地址和源端口，这意味着五元组中已经有三个元素相同了(协议，源地址，源端口)。如果你尝试将这些socket连接到同样的目的地址和目的端口，你就创建了两个完全相同的连接。这是不行的，至少对TCP不行(UDP实际上没有真实的连接)。如果数据到达这两个连接中的任何一个，那么系统将无法区分数据到底属于谁。因此当源地址和源端口相同时，目的地址或者目的端口必须不同，否则内核无法进行区分，这种情况下，connect()将在第二个socket尝试连接时返回EADDRINUSE。 Multicast Address(多播地址)大部分人都会忽略多播地址的存在，但它们的确存在。单播地址(unicast address)用于单对单通信，多播地址用于单对多通信。大部分人在他们学习了IPv6后才注意到多播地址的存在，但在IPv4中多播地址就有了，尽管它们在公共互联网上用的并不多。 对多播地址来说，SO_REUSEADDR的含义发生了改变，因为它允许多个socket绑定到完全一样的多播地址和端口，也就是说，对多播地址SO_REUSEADDR的行为与SO_REUSEPORT对单播地址完全一样。事实上，对于多播地址，对SO_REUSEADDR和SO_REUSEPORT的处理完全一样，对所有多播地址，SO_REUSEADDR也就意味着SO_REUSEPORT。 FreeBSD/OpenBSD/NetBSD它们都是很晚的时候衍生自原生BSD的系统，它们与原生BSD的选项和行为都一样。 MacOS XMacOS X的内核就是一个BSD类型的UNIX，基于很新的BSD代码，甚至Mac OS 10.3的发布与FreeBSD 5都是同步的，因此MacOS与BSD一样提供相同的选项，处理行为也一样。 IOSIOS只是在内核上稍微修改了MacOS，因此选项和处理行为也和MacOS一样。 Linux在linux 3.9之前，只存在选项SO_REUSEADDR。除了两个重要的差别，大体上与BSD一样。第一个差别：当一个监听(listening)TCP socket绑定到通配地址和一个特定的端口，无论其它的socket或者是所有的socket(包括监听socket)都设置了SO_REUSEADDR，其它的TCP socket都无法绑定到相同的端口(BSD中可以)，就更不用说使用一个特定地址了。这个限制并不用在非监听TCP socket上，当一个监听socket绑定到一个特定的地址和端口组合，然后另一个socket绑定到通配地址和相同的端口，这样是可行的。第二个差别: 当把SO_REUSEADDR用在UDP socket上时，它的行为与BSD上SO_REUSEPORT完全相同，因此两个UDP socket只要都设置了SO_REUSEADDR，那么它们可以绑定到相同的地址和端口。 Linux 3.9加入了SO_REUSEPORT。这个选项允许多个socket(TCP or UDP)不管是监听socket还是非监听socket只要都在绑定之前都设置了它，那么就可以绑定到完全相同的地址和端口。为了阻止”port 劫持”(Port hijacking)有一个特别的限制：所有希望共享源地址和端口的socket都必须拥有相同的有效用户id(effective user ID)。因此一个用户就不能从另一个用户那里”偷取”端口。另外，内核在处理SO_REUSEPORT socket的时候使用了其它系统上没有用到的”特别魔法”：对于UDP socket，内核尝试平均的转发数据报，对于TCP监听socket，内核尝试将新的客户连接请求(由accept返回)平均的交给共享同一地址和端口的socket(监听socket)。这意味着在其他系统上socket收到一个数据报或连接请求或多或少是随机的，但是linux尝试优化分配。例如：一个简单的服务器程序的多个实例可以使用SO_REUSEPORT socket实现一个简单的负载均衡，因为内核已经把复制的分配都做了。 Android尽管整个Android系统与大多数linux发行版都不一样，但是它的内核是个稍加修改的linux内核，因此它的SO_REUSEADDR和SO_REUSEPORT与linux一样。 Windowswindows上只有SO_REUSEADDR选项，没有SO_REUSEPORT。在windows上设置了SO_REUSEADDR的socket其行为与BSD上设定了SO_REUSEPORT和SO_REUSEADDR的行为大致一样，只有一个差别：一个设置了SO_REUSEADDR的socket总是可以绑定到已经被绑定过的源地址和源端口，不管之前在这个地址和端口上绑定的socket是否设置了SO_REUSEADDR没有。这种行为在某种程度上有些危险因为它允许一个应用程序从别的应用程序上”偷取”已连接的端口。不用说，这对安全性有极大的影响，Microsoft意识到了这个问题，就加入了另一个socket选项: SO_EXECLUSIVEADDRUSE。设置了SO_EXECLUSIVEADDRUSE的socket确保一旦绑定成功，那么被绑定的源端口和地址就只属于这一个socket，其它的socket不能绑定，甚至他们使用了SO_REUSEADDR也没用。 SolarisSolaris是SunOS的后羿，SunOS起源于BSD，SunOS 5和之后的版本则基于SVR4，然而SVR4是BSD，System V和Xenix的集合体，所以从某种程度上说，Solaris也是BSD的分支，而且是相当早的一个分支。这就导致了Solaris只有SO_REUSEADDR而没有SO_REUSEPORT。Solaris上SO_REUSEADDR的行为与BSD的非常相似。从我知道的来看，在Solaris上没办法实现SO_REUSEPORT的行为，也就是说，想把两个socket绑定到相同的源地址和端口上是不可能的。 与Windows类似，Solaris也有一个选项提供互斥绑定，这个选项叫SO_EXCLBIND。如果在一个socket在绑定之前设置这个选项，那么在其他的socket上设置SO_REUSEADDR将没有任何影响。比如socketA绑定了一个通配地址，socketB设置了SO_REUSEADDR并且绑定到一个非通配地址和相同的端口，那么这个绑定将成功，除非socketA设置了SO_EXCLBIND，在这种情况下，socketB的绑定将失败不管它是否设定了SO_REUSEADDR。]]></content>
      <tags>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于CPU Cache -- 程序猿需要知道的那些事]]></title>
    <url>%2F2017%2F06%2F02%2F%E5%85%B3%E4%BA%8ECPU-Cache-%E7%A8%8B%E5%BA%8F%E7%8C%BF%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[文章欢迎转载，但转载时请保留本段文字，并置于文章的顶部 作者：卢钧轶(cenalulu) 本文原文地址：http://cenalulu.github.io/linux/all-about-cpu-cache/ 写在开头：本文系转载，所以以原有博文为主，以斜体注：开头表示添加内容。 先来看一张本文所有概念的一个思维导图 为什么要有CPU Cache随着工艺的提升最近几十年CPU的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存主要是DRAM并且在访问速度上没有质的突破。因此，CPU的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的CPU通过FSB直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低CPU整体吞吐量。同时又由于内存数据访问的热点集中性，在CPU和内存之间用较为快速而成本较高的SDRAM做一层缓存，就显得性价比极高了。 为什么要有多级CPU Cache随着科技发展，热点数据的体积越来越大，单纯的增加一级缓存大小的性价比已经很低了。因此，就慢慢出现了在一级缓存(L1 Cache)和内存之间又增加一层访问速度和成本都介于两者之间的二级缓存(L2 Cache)。下面是一段从 What Every Programmer Should Know About Memory) 中摘录的解释： Soon after the introduction of the cache the system got more complicated. The speed difference between the cache and the main memory increased again, to a point that another level of cache was added, bigger and slower than the first-level cache. Only increasing the size of the first-level cache was not an option for economical rea- sons. 此外，又由于程序指令和程序数据的行为和热点分布差异很大，因此L1 Cache也被划分成L1i (i for instruction)和L1d (d for data)两种专门用途的缓存。 下面一张图可以看出各级缓存之间的响应时间差距，以及内存到底有多慢！ 什么是Cache LineCache Line可以简单的理解为CPU Cache中的最小缓存单位。目前主流的CPU Cache的Cache Line大小都是64Bytes。假设我们有一个512字节的一级缓存，那么按照64B的缓存单位大小来算，这个一级缓存所能存放的缓存个数就是 512/64 = 8 个。具体参见下图： 为了更好的了解Cache Line，我们还可以在自己的电脑上做下面这个有趣的实验。 下面这段C代码，会从命令行接收一个参数作为数组的大小创建一个数量为N的int数组。并依次循环的从这个数组中进行数组内容访问，循环10亿次。最终输出数组总大小和对应总执行时间。 123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/time.h&gt;long timediff(clock_t t1, clock_t t2) &#123; long elapsed; elapsed = ((double)t2 - t1) / CLOCKS_PER_SEC * 1000; return elapsed;&#125;int main(int argc, char *argv[])&#123; int array_size=atoi(argv[1]); int repeat_times = 1000000000; long array[array_size]; for(int i=0; i&lt;array_size; i++)&#123; array[i] = 0; &#125; int j=0; int k=0; int c=0; clock_t start=clock(); while(j++&lt;repeat_times)&#123; if(k==array_size)&#123; k=0; &#125; c = array[k++]; &#125; clock_t end =clock(); printf(&quot;%lu\n&quot;, timediff(start,end)); return 0;&#125; 如果我们把这些数据做成折线图后就会发现：总执行时间在数组大小超过64Bytes时有较为明显的拐点（当然，由于博主是在自己的Mac笔记本上测试的，会受到很多其他程序的干扰，因此会有波动）。原因是当数组小于64Bytes时数组极有可能落在一条Cache Line内，而一个元素的访问就会使得整条Cache Line被填充，因而值得后面的若干个元素受益于缓存带来的加速。而当数组大于64Bytes时，必然至少需要两条Cache Line，继而在循环访问时会出现两次Cache Line的填充，由于缓存填充的时间远高于数据访问的响应时间，因此多一次缓存填充对于总执行的影响会被放大，最终得到下图的结果： 如果读者有兴趣的话也可以在自己的linux或者MAC上通过 gcc cache_line_size.c -o cache_line_size 编译，并通过 ./cache_line_size 执行。 了解Cache Line的概念对我们程序猿有什么帮助？ 我们来看下面这个C语言中常用的循环优化例子 下面两段代码中，第一段代码在C语言中总是比第二段代码的执行速度要快。具体的原因相信你仔细阅读了Cache Line的介绍后就很容易理解了。 1234567for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; int num; //code arr[i][j] = num; &#125;&#125; 1234567for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt; n; j++) &#123; int num; //code arr[j][i] = num; &#125;&#125; CPU Cache 是如何存放数据的你会怎么设计Cache的存放规则我们先来尝试回答一下那么这个问题： 假设我们有一块4MB的区域用于缓存，每个缓存对象的唯一标识是它所在的物理内存地址。每个缓存对象大小是64Bytes，所有可以被缓存对象的大小总和（即物理内存总大小）为4GB。那么我们该如何设计这个缓存？ 如果你和博主(注：原文博主)一样是一个大学没有好好学习基础/数字电路的人的话，会觉得最靠谱的的一种方式就是：Hash表。把Cache设计成一个Hash数组。内存地址的Hash值作为数组的Index，缓存对象的值作为数组的Value。每次存取时，都把地址做一次Hash然后找到Cache中对应的位置操作即可。 这样的设计方式在高等语言中很常见，也显然很高效。因为Hash值得计算虽然耗时(10000个CPU Cycle左右)，但是相比程序中其他操作（上百万的CPU Cycle）来说可以忽略不计。而对于CPU Cache来说，本来其设计目标就是在几十CPU Cycle内获取到数据。如果访问效率是百万Cycle这个等级的话，还不如到Memory直接获取数据。当然，更重要的原因是在硬件上要实现Memory Address Hash的功能在成本上是非常高的。 为什么Cache不能做成Fully AssociativeFully Associative 字面意思是全关联。在CPU Cache中的含义是：如果在一个Cache集内，任何一个内存地址的数据可以被缓存在任何一个Cache Line里，那么我们成这个cache是Fully Associative。从定义中我们可以得出这样的结论：给到一个内存地址，要知道他是否存在于Cache中，需要遍历所有Cache Line并比较缓存内容的内存地址。而Cache的本意就是为了在尽可能少得CPU Cycle内取到数据。那么想要设计一个快速的Fully Associative的Cache几乎是不可能的。 为什么Cache不能做成Direct Mapped和Fully Associative完全相反，使用Direct Mapped模式的Cache给定一个内存地址，就唯一确定了一条Cache Line。设计复杂度低且速度快。那么为什么Cache不使用这种模式呢？让我们来想象这么一种情况：一个拥有1M L2 Cache的32位CPU，每条Cache Line的大小为64Bytes。那么整个L2Cache被划为了 1M/64=16384 条Cache Line。我们为每条Cache Line从0开始编上号。同时32位CPU所能管理的内存地址范围是 2^32=4G，那么Direct Mapped模式下，内存也被划为 4G/16384=256K 的小份。也就是说每256K的内存地址共享一条Cache Line。但是，这种模式下每条Cache Line的使用率如果要做到接近100%，就需要操作系统对于内存的分配和访问在地址上也是近乎平均的。而与我们的意愿相反，为了减少内存碎片和实现便捷，操作系统更多的是连续集中的使用内存。这样会出现的情况就是0-1000号这样的低编号Cache Line由于内存经常被分配并使用，而16000号以上的Cache Line由于内存鲜有进程访问，几乎一直处于空闲状态。这种情况下，本来就宝贵的1M二级CPU缓存，使用率也许50%都无法达到。 什么是N-Way Set Associative为了避免以上两种设计模式的缺陷，N-Way Set Associative (注：也称为 N-Way M-Set Associative)缓存就出现了。他的原理是把一个缓存按照N个Cache Line作为一组（set），缓存按组划为等分。 cache 由 set 组成， set 由 line 组成， line 由 vaild bit,tag,data组成。其中data是真正要缓存的内存地址中的数据，而tag则是用来搜索cache line的标签。 这样一个64位系统的内存地址在4MB二级缓存中就划成了三个部分（见下图），低位6个bit表示在Cache Line中的偏移量，中间12bit表示Cache组号（set index），剩余的高位46bit就是内存地址的唯一id。这样的设计相较前两种设计有以下两点好处：(注：此处原博主假设为16-Way组相连) 给定一个内存地址可以唯一对应一个set，对于set中只需遍历16个元素就可以确定对象是否在缓存中（Full Associative中比较次数随内存大小线性增加） 每 2^18(256K)*16(way)=4M 的连续热点数据才会导致一个set内的conflict（Direct Mapped中512K的连续热点数据就会出现conflict） 注：此处相当于 16-Way 64K-set Associative 为什么N-Way Set Associative的Set段是从低位而不是高位开始的下面是一段从How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses摘录的解释： The vast majority of accesses are close together, so moving the set index bits upwards would cause more conflict misses. You might be able to get away with a hash function that isn’t simply the least significant bits, but most proposed schemes hurt about as much as they help while adding extra complexity. 由于内存的访问通常是大片连续的，或者是因为在同一程序中而导致地址接近的（即这些内存地址的高位都是一样的）。所以如果把内存地址的高位作为set index的话，那么短时间的大量内存访问都会因为set index相同而落在同一个set index中，从而导致cache conflicts使得L2, L3 Cache的命中率低下，影响程序的整体执行效率。 了解N-Way Set Associative的存储模式对我们有什么帮助了解N-Way Set的概念后，我们不难得出以下结论：2^(6Bits &lt;Cache Line Offset&gt; + 12Bits &lt;Set Index&gt;) = 2^18 = 256K。即在连续的内存地址中每256K都会出现一个处于同一个Cache Set中的缓存对象。也就是说这些对象都会争抢一个仅有16个空位的缓存池（16-Way Set）。而如果我们在程序中又使用了所谓优化神器的“内存对齐”的时候，这种争抢就会越发增多。效率上的损失也会变得非常明显。具体的实际测试我们可以参考：How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses 一文。 这里我们引用一张Gallery of Processor Cache Effects 中的测试结果图，来解释下内存对齐在极端情况下带来的性能损失。 该图实际上是我们上文中第一个测试的一个变种。纵轴表示了测试对象数组的大小。横轴表示了每次数组元素访问之间的index间隔。而图中的颜色表示了响应时间的长短，蓝色越明显的部分表示响应时间越长。从这个图我们可以得到很多结论。当然这里我们只对内存带来的性能损失感兴趣。有兴趣的读者也可以阅读原文分析理解其他从图中可以得到的结论。 从图中我们不难看出图中每1024个步进，即每1024*4即4096Bytes，都有一条特别明显的蓝色竖线。也就是说，只要我们按照4K的步进去访问内存(内存根据4K对齐），无论热点数据多大它的实际效率都是非常低的！按照我们上文的分析，如果4KB的内存对齐，那么一个240MB的数组就含有61440个可以被访问到的数组元素；而对于一个每256K就会有set冲突的16Way二级缓存，总共有256K/4K=64个元素要去(注：从整个缓存中)争抢16个空位，总共有61440/64=960个这样的元素。那么缓存命中率只有1%，自然效率也就低了。 除了这个例子，有兴趣的读者还可以查阅另一篇国人对Page Align导致效率低的实验：http://evol128.is-programmer.com/posts/35453.html 想要知道更多关于内存地址对齐在目前的这种CPU-Cache的架构下会出现的问题可以详细阅读以下两篇文章： How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses Gallery of Processor Cache Effects Cache淘汰策略在文章的最后我们顺带提一下CPU Cache的淘汰策略。常见的淘汰策略主要有LRU和Random两种。通常意义下LRU对于Cache的命中率会比Random更好，所以CPU Cache的淘汰策略选择的是LRU。当然也有些实验显示在Cache Size较大的时候Random策略会有更高的命中率 总结CPU Cache对于程序猿是透明的，所有的操作和策略都在CPU内部完成。但是，了解和理解CPU Cache的设计、工作原理有利于我们更好的利用CPU Cache，写出更多对CPU Cache友好的程序 ReferenceGallery of Processor Cache EffectsHow Misaligning Data Can Increase Performance 12x by Reducing Cache MissesIntroduction to Caches]]></content>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux TCP 编程]]></title>
    <url>%2F2017%2F05%2F26%2FLinux-TCP-%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[TCP(Transmission Control Protocol) 是由 IETF 的 RFC 793 定义的一种面向连接的、可靠的、基于字节流的传输层通信协议。 TCP 报文段TCP 数据被封装在一个 IP 数据报中，如下图所示： 下图是 TCP 首部的数据格式，如果不计任选字段，它通常是20个字节： 下面介绍重要的几个数据： 32位序号：表示数据当前发送的第一个字节在字节流中的序号 32位确认号：表示发送端所期望收到的下一个序号，因此该序号位上一次收到的序号加一 6个特殊标志bit: (按照排列顺序) URG: 紧急指针有效 ACK：确认序号有效 PSH：接收方应该尽快将这个报文段交给应用层 RST：重建连接 SYN：同步序号，用来发起一个连接 FIN：发送端完成任务，关闭发送端到接收端连接 其余的解释请参考 TCP/IP 协议详解。 TCP 连接的状态图 TCP 连接的建立与终止TCP 是一个面向连接的通信协议，这要求通信双方在进行通信之前，需要先建立其连接。在常见的客户端、服务器模式的程序中，通常是服务器绑定端口，并在该端口上监听客户端连接请求；客户端主动向服务器发起连接请求，待服务器响应后，双方建立起一条通信链路。 建立TCP 连接建立时通信双方的分组报文如下图所示： 如图所示，客户端发起 connect，此时客户端发送 SYN 报文；服务端使用 accept 接受该连接请求，同时反馈 SYN 和 ACK；等到客户端相应了 ACK后，双方建立起完整连接。 将上述过程映射到 TCP 状态图上进行观察，在服务器端： 刚开始服务器处于 CLOSED 状态 服务器初始化时绑定了具体的端口，并使用 listen 监听该端口，进入了 LISTEN 状态 服务端接收到了来自客户端的 SYN 请求，发送 SYN 和 ACK 给客户端，然后进入 SYN_RCVD 状态 当服务端接收到了客户端紧接着到达的 ACK 时，进入 ESTABLISHED 状态 客户端方面： 刚开始同样处于 CLOSED 状态 应用主动调用 CONNECT 发起连接，发送 SYN 给服务器，然后进入 SYN_SEND 状态 当接受到服务器的 SYN 和 ACK 后，发送对应的 ACK 给服务器，并进入 ESTABLISHED 状态 当双方都进入 ESTABLISHED 状态时，表示连接已经建立成功。 当然，客户端在发送了 SYN 后，等待超时，并重试几次后，便会触发 Timeout 进入 CLOSED，在应用层则表示为 connect 失败。 同时建立连接与常见的模式不同的是，TCP 允许连接双方同时发起建立连接的请求。此时分组报文如下图所示： 连接双方同时发送 SYN 到对方，然后同样地返回 SYN 和 ACK 给对方。将该过程对应到状态图中： 刚开始同样处于 CLOSED 状态 应用主动调用 CONNECT 发起连接，发送 SYN 给服务器，然后进入 SYN_SEND 状态 接收到 SYN 后进入 SYN-RCVD 状态 接收到 ACK 后建立连接，进入 ESTABLISHED 状态 关闭连接FIN 用于通知对方关闭本方向的连接。由于 TCP 是一个全双工的通信协议，像管道一样，支持关闭某一方向上的连接，所以在 TCP 中关闭连接需要双方都发送 FIN 报文。此时分组报文如下图所示： 当某一方关闭连接时，发送 FIN 给另一方，对方回复 ACK 后，同时也发送 FIN；等到双方都收到最后的 ACK 后，连接关闭。当然，如果另一方只回复了 ACK 而没有发起 FIN，则表示对方仍然想要发送数据，这种情况称为 TCP 的半关闭。只有当双方都发送了 FIN 并接收到对方的 ACK 后，才算真正的连接关闭。所以上图中 Server 端的 FIN 包可以在接收到 Client 的 FIN 包后，隔一段时间再发送。 在状态图中对应了主动关闭和被动关闭，首先观察主动关闭： 当应用使用 close 后，发送 FIN 给对方，并由 ESTABLISHED 状态进入 FIN_WAIT_1 状态 如果收到 ACK 后，进入 FIN_WAIT_2 状态 此时等待对方的 FIN 到达，并发送 ACK 给对方，进入 TIME_WAIT 状态 如果在 FIN_WAIT_1 状态直接接收到 FIN 和 ACK，则直接进入 TIME_WAIT 状态 TIME_WAIT 状态等待了 2 MSL 后，进入 CLOSED 状态，此时连接关闭 被动关闭则简单得多： 当收到对方的 FIN 后，发送 ACK 并由 ESTABLISHED 进入 CLOSE_WAIT 状态 等到用户层发出 close 后，发送 FIN 同时进入 LAST_ACK 状态 等到接收到对方的 ACK 后，进入 CLOSED 状态，连接关闭 TIME_WAIT 状态可能时状态图中最不易懂的地方，它也被称为 2 MSL 状态。每一个具体 TCP 实现必须选择一个报文段最大生存时间 MSL(Maximum Segment Lifetime)，表示任何报文段被丢弃前能在网络中存活的时间。当 TCP 执行主动关闭并发送了 ACK 给对方进入 TIME_WAIT 状态后，该连接必须在 TIME_WAIT 状态停留 2 倍的 MSL 。这样可以保证 TCP 在超时后再次发送最后的 ACK 以防止这个 ACK 丢失。使用 2 MSL 的另外一点是，当前的 socket 关闭后，可能立即被用于建立另一个 TCP 连接，而网络中可能存在着尚未到达具有 TIME_WAIT 状态一方的包，需要保证这些包不会影响到接下来即将建立的连接。2 MSL 的时间间隔中不允许 socket 被重新使用，同时也能够保证消耗掉网络中的包。所以 TIME_WAIT 状态存在有两个理由： 可靠地实现 TCP 全双工连接的终止 允许老的重复的包在网络中消逝 关于保证 TCP 超时后再次发送最后的 ACK 进行补充：在tcp协议中处于last_ack状态的连接，如果一直收不到对方的ack，会一直处于这个状态吗？- 知乎 同时关闭如 TCP 同时打开一样，TCP 也存在同时关闭状态，此时双方均进入 FIN_WAIT_1 状态，并再接收到 FIN 后进入 CLOSING 状态。等到接收到 ACK 后，则进入 TIME_WAIT 状态。 TCP 复位在 TCP 首部中 RST 位表示表示复位，用来异常的关闭连接，在 TCP 的设计中它是不可或缺的。发送 RST 包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓存区的包发送 RST 包。而接收端收到 RST 包后，也不必发送 ACK 包来确认。TCP 处理程序会在自己认为的异常时刻发送 RST 包。 下面来分析一下 TCP 中 RST 包出现的主要场景。 到不存在的端口的连接请求产生复位的一种常见情况是当连接请求到达时，目的端口没有进程在监听。例如，A 向 B 发起连接，但 B 之上并未监听相应的端口，这时 B 操作系统上的 TCP 处理程序会发 RST 包。 异常终止一个连接终止一个连接的正常方式是一方发送 FIN，这也成为有序释放，因为在所有排队数据都已经发送之后才发送 FIN ，正常情况下没有数据丢失。但是也可以使用 RST 来直接释放一个连接，这种方式称为异常释放。使用异常终止有两个有点： 丢弃任何待发送数据并立即发送复位报文段 RST 的接收方会区分另一端是异常还是正常关闭 检测半打开连接如果一方已经关闭或异常终止而另一方还不知道，这样的 TCP 连接被称为半打开的。比如系统断电而不是正常结束就可能造成半打开的连接。如果发生异常的一方重启后重新连接到远程服务，则会发生错误，此时远程服务器会发送 RST 关闭此连接。比如，AB 正常建立连接了，正在通讯时，A 向 B 发送了 FIN 包要求关连接，B 发送 ACK 后，网断了，A 通过若干原因放弃了这个连接（例如进程重启）。网通了后，B 又开始发数据包，A 收到后表示压力很大，不知道这野连接哪来的，就发了个 RST 包强制把连接关了，B 收到后会出现 connect reset by peer 错误。 Socket TCP 编程Socket 中文称为套接字，用于应用程序发出或相应网络请求。POSIX 提供了一套 Socket 编程标准 API，在进一步之前，先看看 Socket TCP 编程流程： 简单的 Socket 编程流程如上图所示，创建了 socket 后的客户端通过 connect 操作连接到了处于 listen 的服务器；当服务器使用 accept 接受新的连接请求后，双方建立起了连接，通过 read 和 write 传输数据；最后使用 close 来关闭连接。 简单的例子进一步深入了解如何使用 socket 编程前，先来看看例子： 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;error.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;typedef struct sockaddr *PSA;int main(int argc, char **argv) &#123; int fd = socket(AF_INET, SOCK_STREAM, 0); if (fd &lt; 0) &#123; perror(&quot;socket&quot;); return -1; &#125; struct sockaddr_in addr; memset(&amp;addr, 0, sizeof(addr)); addr.sin_len = sizeof(addr); addr.sin_family = AF_INET; addr.sin_port = htons(8080); addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); if (connect(fd, (PSA) &amp;addr, sizeof(addr)) &lt; 0) &#123; perror(&quot;connect&quot;); return -1; &#125; // do something close(fd);&#125; 上面是客户端，以及下面的服务器： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;error.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;typedef struct sockaddr *PSA;int main(int argc, char **argv) &#123; int fd = socket(AF_INET, SOCK_STREAM, 0); if (fd &lt; 0) &#123; perror(&quot;socket&quot;); return -1; &#125; struct sockaddr_in addr; memset(&amp;addr, 0, sizeof(addr)); addr.sin_len = sizeof(addr); addr.sin_family = AF_INET; addr.sin_port = htons(8080); addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); if (bind(fd, (PSA) &amp;addr, sizeof(addr)) &lt; 0) &#123; perror(&quot;bind&quot;); return -1; &#125; if (listen(fd, 10) &lt; 0) &#123; perror(&quot;listen&quot;); return -1; &#125; struct sockaddr_in clientaddr; socklen_t clientlen; for (;;) &#123; int clientfd = accept(fd, (PSA) &amp;clientaddr, &amp;clientlen); // do something close(clientfd); &#125;&#125; 这两段代码随手写的，没有经过验证。 上述代码是一个基本的客户端服务器 socket 编程模板，它展示了 socket 编程常用的 API 的用法。下面来看看如何使用 socket 编程 API。 套接字地址每一个 socket 对象在使用时都需要和一个具体的 socket 地址绑定，而每一个协议簇都有自己的套接字地址结构。这些结构以 sockaddr 开头，并以协议簇的唯一后缀结尾。 socket API 兼容多种协议簇。在实现上以一种通用套接字地址结构作为所有套接字地址的基类。（实际上在C语言中可以使用 void* 作为参数，不过 socket API 定义在 ANSI C 之前，此时还没有 void*。） 通用套接字地址结构在 &lt;sys/socket.h&gt; 头文件中定义了一个通用的套接字地址结构。 12345struct sockaddr &#123; uint8_t sa_len; sa_family_t sa_family; char sa_data[14];&#125;; 对于应用开发人员来说，需要的是使用 API 时，强制将其他协议簇的地址结构指针转换为通用地址结构指针。也就是说：通用 socket 地址结构唯一的作用就是用于对特定协议的地址结构执行强制类型转换，以统一类型。 IPv4 地址结构在实际编程中容易接触到的时 IP 协议簇，而 IP 协议簇又分为 IPv4 和 IPv6 两个版本。先看 IPv4 的 socket 地址结构： 123456789101112struct in_addr &#123; in_addr_t s_addr; /* 32 bit IPv4 address, in network byte ordered */&#125;;struct sockaddr_in &#123; uint8_t sin_len; /* length of structure (16) */ sa_family_t sin_family; /* AF_INET */ in_port_t sin_port; /* 16 bit port number，in network byte ordered */ struct in_addr sin_addr;/* 32 bit IPv4 address */ char sin_zero[8]; /* unused */&#125;; 该结构定义在文件 &lt;netinet/in.h&gt; 中，编程人员主要关心：sin_family、sin_addr 和 sin_port。sin_family 表示使用的使用的协议簇。sin_addr 和 sin_port 表示具体的 socket 地址，需要注意两者的数据都必须是网络字节序。关于网络字节序可以参考网络字节序-CSDN。 IPv6 地址结构IPv6 地址结构和 IPv4 地址结构定义在同一文件中，其内部布局如下： 12345678910111213struct in6_addr &#123; uint8_t s6_addr; /* 128 bit IPv6 address, in network byte ordered */&#125;;struct sockaddr_in6 &#123; uint8_t sin6_len; /* length of structure (28) */ sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port */ uint32_t sin6_flowinfo; /* flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* set of interfaces for a scope */&#125; 地址相关 API在使用的时候，需要在网络字节序和本地字节序之间进行转换，而 POSIX 提供了对应的字节序转换方法： 123456789#include &lt;netinet/in.h&gt;// 主机到网络uint16_t htons(uint16_t val);uint32_t htonl(uint32_t val);// 网络到主机uint16_t ntohs(uint16_t val);uint32_t ntohl(uint32_t val); 除了提供字节序转换方法外，标准还提供了点分制地址到网络序的二进制值之间进行转换的方法： 12345678#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;int inet_aton(const char *cp, struct in_addr *inp);in_addr_t inet_addr(const char *cp);in_addr_t inet_network(const char *cp);char *inet_ntoa(struct in_addr in); inet_aton 把 cp 对应的点分制的地址转换为网络地址并保存在 inp 中，如果地址正确则返回非零，否则返回0。 inet_addr 则是直接返回网络二进制地址，如果地址错误返回 INADDR_NONE。 inet_network 和 inet_addr 一样，但是返回的地址是主机序的二进制地址，如果错误返回 -1。 inet_ntoa 这个函数和前面的函数作用相反，是将网络序二进制地址转换为点分制的地址。需要注意的是如果再次调用该函数返回的 buffer 会被覆盖。 上面部分的内容是针对 IPv4 地址，对于 IPv6，标准提供了新的函数。 123#include &lt;arpa/inet.h&gt;int inet_pton(int af, const char *src, void *dst);const char *inet_ntop(int af, const void *src, char *dst, socklen_t size); 这两个函数同时支持 IPv4 和 IPv6 ，所以在使用中，建议使用这两个函数替代原有的函数。对于第一个参数 af 表示具体的协议：AF_INET 和 AF_INET6，如果不是这两个值，则返回一个错误，并将 errno 设置成 EAFNOSUPPORT。 第一个函数尝试转换字符串对应的地址，并将得到的二进制数据保存到 dst，若成功返回 1，否则表示对应的 family 协议的字符串不是有效的，返回 0。 第二个函数进行了相反的转换，size 用于保存目标存储单元的大小，用于防止缓冲区溢出。标准定义了一个具体的数值来帮助开辟缓冲区空间: 1234#include &lt;netinet/in.h&gt;#define INET_ADDRSTRLEN 16#define INET6_ADDRSTRLEN 46 如果缓冲区过小，那么返回一个空指针，并将 errno 设置为 ENOSPC。调用成功后，返回 dst 。 // TODO: IPv4 和 IPv6 混合 socket APIsocket 函数1234#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol); 使用 socket 函数创建一个通信的 socket，并返回其描述符。 domain 参数指定具体通行领域，用来告知具体的通信协议，TCP 中使用到了：AF_INET 和 AF_INET6。type 参数指定通信的语义，TCP 中主要关心 SOCK_STREAM —— 提供顺序，可靠的双向基于连接的字节流。可能支持带外数据传输机制。protocol 参数在此处只需要填 IPPROTO_TCP，表示使用 TCP 传输协议。 Since Linux 2.6.27, the type argument serves a second purpose: in addition to specifying a socket type, it may include the bitwise OR of any of the following values, to modify the behavior of socket(): SOCK_NONBLOCK Set the O_NONBLOCK file status flag on the new open file description. Using this flag saves extra calls to fcntl to achieve the same result. SOCK_CLOEXEC Set the close-on-exec (FD_CLOEXEC) flag on the new file descriptor. See the description of the O_CLOEXEC flag in open for reasons why this may be useful. 当函数成功后，将返回新套接字的文件描述符。出错时返回-1，并适当设置 errno。errno 的具体错误值可能如下： EAFNOSUPPORT 该实现不支持指定的地址族。 EINVAL 未知协议或协议族不可用或类型中的标记无效。 EMFILE 已达到打开文件描述符数的限制。 ENOBUFS or ENOMEM 内存不足可用。在释放足够的资源之前，无法创建套接字。 EPROTONOSUPPORT 该域中不支持协议类型或指定的协议。 bind 函数1234#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); bind 将由 addr 指定的地址分配给文件描述符 sockfd 引用的套接字。addrlen 指定 addr 指向的地址结构的大小（以字节为单位）。 传统上，这个操作称为“为套接字分配名称”。通常需要在 SOCK_STREAM 套接字接收（accept）连接之前使用 bind 分配本地地址。当函数成功后，将返回新套接字的文件描述符。成功返回 0 ，出错时返回-1，并适当设置 errno。errno 的具体错误值可能如下： EADDRINUSE 地址已经被使用了。 EBADF sockfd 不是不可用。 EINVAL 当前 socket 已经绑定过地址了。或者 addrlen 错误，或者 addr 不是合法的地址。 ENOTSOCK sockfd 不是一个 socket 描述符。 在通常的使用中，客户端程序没有调用 bind 直接使用 connect 创建连接，因为 socket 从系统内部选择一个端口组成 addr ，并将之与对应的 socket 绑定。也就是说，bind并不是仅仅用于 listen，也可以配合 connect 使用。如果没有使用 bind 绑定地址，可以使用 getsockname 获取地址信息。 connect 函数1234#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); connect 系统调用将文件描述符 sockfd 引用的套接字连接到 addr 指定的地址。addrlen 参数指定 addr 的大小。对于 TCP ，connect 触发三路握手，并在建立连接成功或者发生错误时返回，其中可能有以下几种情况： EADDRINUSE 地址已经被使用了。 EBADF sockfd 不是不可用。 timeout 如果 TCP 没有收到 SYN 分节的响应，则返回 ETIMEOUT。 reset 如果对方相应的时 RST ，表示服务器主机在我们指定的端口上没有程序监听，这是一种硬错误(hard error)，此时返回 ECONNREFUSED。 unreachable 如果目标主机不在当前网络中，发生了 ICMP 错误，则认为是一种软错误(soft error)，并返回 EHOSTUNREACH 或 ENETUNRECH 错误。 如果 connect 出现错误而失败，则不能再重新使用，需要使用 close 关闭。如果需要重新连接，则需要从头创建描述符。 listen 函数listen 函数仅仅由 TCP 服务器调用，它做两件事情： 将 socket 建立的主动 socket （默认为主动）转换为被动的 socket，因此此 socket 可以使用 accept 来接收到来的连接请求。然后 socket 对应的状态由 CLOSED 状态变为 LISTEN 状态 它指定了 socket 在内核中的排队连接的数量 1234#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;int listen(int sockfd, int backlog); sockfd 为对应的 socket 描述符。backlog 参数定义 sockfd 的挂起连接队列可能的最大长度。 如果连接请求在队列已满时到达，则客户端可能会收到带有 ECONNREFUSED 指示的错误，或者如果底层协议支持重传，则该请求可能会被忽略，以便以后重新尝试连接成功。 在 UNP 一书中说：内核为任何一个监听套接字维护两个队列。 未完成连接队列：其中的套接字表示正在完成三路握手过程。这些套接字此时处于 SYN_RCVD 状态。 已经完成队列：表示这些套接字已经完成了三路握手过程，处于 ESTABLISHED 状态，等到 accept 读取。 成功返回 0 ，出错时返回-1，并适当设置 errno。errno 的具体错误值可能如下： EADDRINUSE 地址已经被使用了。 EBADF sockfd 不是不可用。 ENOTSOCK sockfd 不是一个 socket 描述符。 EOPNOTSUPP sockfd 对应的 socket 不支持 listen 操作。 accept 函数1234#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); accept 函数从 sockfd 的已经完成队列中取出 socket。addr 表示接受的远程地址，addrlen 则是地址空间长度。在成功时，这些系统调用返回一个非负整数，它是接受的套接字的描述符。 出错时返回-1，并适当设置errno。在 linux 中还有一个新版本的函数 accept4： 1234&gt; #define _GNU_SOURCE /* See feature_test_macros(7) */&gt; #include &lt;sys/socket.h&gt;&gt; int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags);&gt; If flags is 0, then accept4() is the same as accept(). The following values can be bitwise ORed in flags to obtain different behavior: SOCK_NONBLOCK Set the O_NONBLOCK file status flag on the new open file description. Using this flag saves extra calls to fcntl(2) to achieve the same result. SOCK_CLOEXEC Set the close-on-exec (FD_CLOEXEC) flag on the new file descriptor. See the description of the O_CLOEXEC flag in open(2) for reasons why this may be useful. getsockname 和 getpeername 函数这两个函数分别返回与某个 socket 关联的本地地址，以及远程地址。 1234#include &lt;sys/socket.h&gt;int getsockname(int sockfd, int sockaddr *localaddr, socklen_t *addrlen);int getpeername(int sockfd, int sockaddr *remoteaddr, socklen_t *addrlen); 两个函数的用法一致。如果正确返回 0 ，错误返回 -1，并设置 errno。 关闭 socket 连接终止 socket 连接的通常方法是使用 close 函数，不过 close 函数有两个限制，而 shutdown 则可以避免： close 只是将引用计数减一，只有计数为 0 时才关闭套接字。而 shutdown 则可以不管引用技术直接触发 TCP 的正常连接终止序列。 close 会将读写两个方向的连接都关闭，而某些情况下 TCP 需要保持一方的连接。而 shutdown 则可以关闭某一方的连接，也就是 TCP 的半关闭状态。 shutdown 函数的原型如下： 123#include &lt;sys/socket.h&gt;int shutdown(int sockfd, int how); 该函数的行为依赖于 how 的值： SHUT_RD 关闭本端的读这一半，socket 不再接收新数据，同时丢弃缓冲区中的数据。 SHUT_WR 关闭写的这一半，当前缓冲区的数据将被发送。此时进程无法再对该 socket 进行写操作。 SHUT_RDWR 将读写都关闭，这等价于先调用 shutdown(fd, SHUT_RD) 然后调用 shutdown(fd, SHUT_WR)。 要注意，shutdown(fd, SHUT_RDWR)仅仅是断开了 socket 连接，但是并不意味着 socket 被关闭了，此时还需要调用 close(fd) 来释放文件描述符，否则会造成描述符泄露 。 socket options有多种办法获取或设置 socket 的选项： getsockopt 和 setsockopt 函数 fcntl 函数 ioctl 函数 getsockopt &amp; setsockopt这两个函数仅用于 socket： 12345#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 其中 sockfd 必须指向打开的套字符， level 指定如何解释后面的选项；optname 则是具体的选项内容；optval 指向某个具体变量，setsockopt 从 optval 指向的变量中读值，getsockopt 则将值写入 optval；显而易见的 optlen 为 optval 所指向变量的大小。 level 分别指出 optname 是 socket、ip 还是 TCP 的选项。首先来看 socket 的 SOL_SOCKET 所对一个的选项，只列出了重要的部分： SO_REUSEADDR &amp; SO_REUSEPORT：SO_REUSEADDR 主要有两个工作：1、改变了在处理源地址冲突时对通配地址(“any ip address”)的处理方式的处理方法；2、处于TIME_WAIT状态中的socket可以重用。关于这两者的行为及其异同不详述，请参考SO_REUSEADDR &amp; SO_REUSEPORT 的异同 SO_RECVBUF / SO_SNDBUF 先明确一个概念：每个TCP socket在内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式以及TCP的滑动窗口便是依赖于这两个独立的buffer以及此buffer的填充状态。接收缓冲区把数据缓存入内核，应用进程一直没有调用read进行读取的话，此数据会一直缓存在相应socket的接收缓冲区内。再啰嗦一点，不管进程是否读取socket，对端发来的数据都会经由内核接收并且缓存到socket的内核接收缓冲区之中。read所做的工作，就是把内核缓冲区中的数据拷贝到应用层用户的buffer里面，仅此而已。进程调用send发送的数据的时候，最简单情况（也是一般情况），将数据拷贝进入socket的内核发送缓冲区之中，然后send便会在上层返回。换句话说，send返回之时，数据不一定会发送到对端去（和write写文件有点类似），send仅仅是把应用层buffer的数据拷贝进socket的内核发送buffer中。如果应用进程一直没有读取，buffer满了之后，发生的动作是：通知对端TCP协议中的窗口关闭。这个便是滑动窗口的实现。保证TCP套接口接收缓冲区不会溢出，从而保证了TCP是可靠传输。因为对方不允许发出超过所通告窗口大小的数据。这就是TCP的流量控制，如果对方无视窗口大小而发出了超过窗口大小的数据，则接收方TCP将丢弃它。 SO_KEEPALIVE SO_KEEPALIVE 如果一方已经关闭或异常终止连接，而另一方却不知道，我们将这样的TCP连接称为半打开的。TCP通过保活定时器(KeepAlive)来检测半打开连接。设置该选项后，如果2小时内在此套接口的任一方向都没有数据交换，TCP 就自动给对方发一个保持存活探测分节(keepalive probe)。这是一个对方必须响应的TCP分节.它会导致以下三种情况： 对方接收一切正常：以期望的 ACK 响应，2小时后，TCP 将发出另一个探测分节。 对方已崩溃且已重新启动：以 RST 响应。套接口的待处理错误被置为 ECONNRESET，套接口本身则被关闭。 对方无任何响应：源自 berkeley 的 TCP 发送另外 8 个探测分节，相隔 75 秒一个，试图得到一个响应。在发出第一个探测分节 11 分钟 15 秒后若仍无响应就放弃。套接口的待处理错误被置为 ETIMEOUT，套接口本身则被关闭。如 ICMP 错误是“host unreachable(主机不可达)”，说明对方主机并没有崩溃，但是不可达，这种情况下待处理错误被置为 EHOSTUNREACH。 有关 SO_KEEPALIVE 的三个参数详细解释如下: tcp_keepalive_intvl: 保活探测消息的发送频率。默认值为 75s。发送频率tcp_keepalive_intvl 乘以发送次数 tcp_keepalive_probes ，就得到了从开始探测直到放弃探测确定连接断开的时间，大约为11min。 tcp_keepalive_probes，TCP 发送保活探测消息以确定连接是否已断开的次数。默认值为9（次）。注意：只有设置了 SO_KEEPALIVE 套接口选项后才会发送保活探测消息。 tcp_keepalive_time，在 TCP 保活打开的情况下，最后一次数据交换到 TCP 发送第一个保活探测消息的时间，即允许的持续空闲时间。默认值为 7200s（2h）。 SO_LINGER SO_LINGER 将决定系统如何处理残存在套接字发送队列中的数据。处理方式无非两种：丢弃或者将数据继续发送至对端，优雅关闭连接。事实上，SO_LINGER 并不被推荐使用，大多数情况下我们推荐使用默认的关闭方式。关于 SO_LINGER 具体描述可以参考：SO_LINGER 选项设置。 SO_RCVLOWAT / SO_SNDLOWAT 分别表示TCP接收缓冲区和发送缓冲区的低水位标记。它们一般被I/O复用系统调用用来判断socket是否可读或可写。当TCP接收缓冲区中可读数据的总数大于其低水位标记时，I/O复用系统调用将通知应用程序可以从对应的socket上读取数据；当TCP发送缓冲区中的空闲空间（可以写入数据的空间）大于其低水位标记时，I/O复用系统调用将通知应用程序可以往对应的socket上写入数据。默认情况下，TCP接收缓冲区的低水位标记为1字节和TCP发送缓冲区的低水位标记均为2048字节。 SO_RCVTIMEO / SO_SNDTIMEO 这两个选项给套接字的接收和发送设置一个超时值。注意，访问函数的参数是指向timeval结构的指针。通过设置值为0秒和0微妙禁止超时。缺省情况下，两个超时都是禁止的。 另外，实际编程中还关心 TCP 相关的选项 IPPROTO_TCP： TCP_NODELAY / TCP_CHORK 是否采用 Nagle 算法把较小的包组装为更大的帧。HTTP服务器经常使用 TCP_NODELAY 关闭该算法。相关的还有 TCP_CORK。 TCP_DEFER_ACCEPT 推迟 accept，实际上是当接收到第一个数据之后，才会创建连接。（对于像HTTP等非交互式的服务器，这个很有意义，可以用来防御空连接攻击。） TCP_KEEPCNT / TCP_KEEPIDLE / TCP_KEEPINTVL 这三个参数配合 SO_KEEPALIVE 使用，通过 TCP_KEEPIDLE、TCP_KEEPINTVL 和 TCP_KEEPCNT 设置 keepalive 的开始时间、间隔、次数等参数。保活时间：keepalive_time = TCP_KEEPIDLE + TCP_KEEPINTVL * TCP_KEEPCNT 从 TCP_KEEPIDLE 时间开始，向对端发送一个探测信息，然后每过 TCP_KEEPINTVL 发送一次探测信息。如果在保活时间内，就算检测不到对端了，仍然保持连接。超过这个保活时间，如果检测不到对端，服务器就会断开连接，如果能够检测到对方，那么连接一直持续。 非阻塞socket阻塞是指调用结果返回前，当前线程会被挂起。当函数结果返回时当前线程才恢复执行。非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。 前面的socket函数默认是阻塞模式，使用fcntl可以将socket设置为非阻塞模式。 12int flags = fcntl(fd, F_GETFL, 0);fcntl(fd, F_SETFL, flags | O_NONBLOCK); 非阻塞socket编程与阻塞编程的区别主要在于一些可能造成阻塞的操作在无法完成操作的情况下直接返回EAGAIN或EWOULDBLOCK。比如使用read，而此时输入缓冲区中没有任何数据，那么直接返回EWOULDBLOCK。这样服务器可以将CPU用于处理其他逻辑，而非等待数据到达。 对于非阻塞socket，可能写出下面的代码: 1234567int fds[MAX_FDS];// ...for (int i = 0; i &lt; max_fd; ++i) &#123; if (read(fds[i], buf, sizeof(buf)) != EWOULDBLOCK) &#123; // do something &#125;&#125; IO多路复用对于非阻塞式socket，如果使用轮询实现，每次都要陷入内核态，且依次轮询效率非常低，所以提出了IO多路复用机制。所谓IO多路复用，在实现上是将轮询机制转换为观察者模式。用户需要注册文件描述符以及需要监听事件，而内核负责在发生某些事件（可读等）时通知用户。也就是说原来需要在每条连接上进行监听，而使用IO多路复用后，监听过程交给了内核，由内核将消息分发到每一条连接上。 按照IO多路复用的发展历程，出现了select、poll和epoll（在BSD上对应kqueue)。 关于select使用参考Linux select 详解。 关于poll使用参考poll调用详解。 关于epoll使用参考通过完整示例来理解如何使用epoll。 References TCP - Wikis TCP/IP 详解 卷一：协议 UNIX 网络编程 卷一：套接字联网API 如何正确关闭 TCP 连接 - 知乎 浅谈服务端编程 TCP/IP Socket心跳机制so_keepalive的三个参数详解 SO_RCVLOWAT和SO_SNDLOWAT选项 TCP选项之SO_RCVLOWAT和SO_SNDLOWAT TCP选项之SO_RCVBUF和SO_SNDBUF]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Socket</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链接]]></title>
    <url>%2F2017%2F05%2F17%2F%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[链接是把各种代码、数据收集起来组合成单一文件的过程，这个文件可以被加载到内存中执行。在实际开发中，会将项目分散成小的、更容易管理的模块，然后独立的修改和编译这些模块。链接则是将各个模块组合成可执行文件的过程。 链接通常由链接器完成，不过现代编译器或编译环境已经处理了链接过程，需要手动使用链接器完成的场景已经很少了。大多数现代编译系统提供了编译驱动程序，它可以依次使用预处理、编译、汇编、链接器来完成编译到链接的过程，不需要用户干预。 比如由a.c和b.c两个文件，在编译驱动程序的帮助下，可以使用简单命令完成： 1gcc -o program a.c b.c 上述命令等价于下面这些命令： 1234567cpp a.c a.icpp b.c b.icc1 a.i -o a.Scc1 b.i -o b.Sas -o a.o a.Sas -o b.o b.Sld -o program a.o b.o 上述过程依次调用预处理、编译、汇编和链接器，最终生成了可执行文件。 像ld程序这样的静态链接器以一组可重定位的目标文件和参数作为输入，生成完全链接的可执行目标文件。可重定位目标文件由一系列的节(section)组成。 可重定位目标文件目标文件有三种 可重定位目标文件 可执行目标文件 共享目标文件 这里只关心可重定位目标文件，它包含了二进制代码和数据，不过其中的信息并不完善，需要和其他文件一起才能组成一个可执行目标文件或者共享目标文件。 所谓可重定位，是指包含的二进制代码中有引用到其他模块的，由于不知道其他模块中二进制代码布局，所以留了空等待回填。使用例子更方便理解可重定位目标文件。假设有下面的代码： 123456789101112#include &lt;stdio.h&gt;int a, a1=1;int main(void) &#123; static int b = 1; static int c; printf(&quot;hello world&quot;, a, b); return 0;&#125; 将之命名为hello.c，然后使用命令生成重定位目标文件： 1gcc -c hello.o hello.c 此时hello.o便是可重定位目标文件，使用objdump -h hello.o可以看看可重定位目标文件的节(section)： 1234567891011121314151617181920/mnt/d/tmp$ objdump -h hello.ohello.o: file format elf64-x86-64Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000028 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000008 0000000000000000 0000000000000000 00000068 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000004 0000000000000000 0000000000000000 00000070 2**2 ALLOC 3 .rodata 0000000c 0000000000000000 0000000000000000 00000070 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 00000035 0000000000000000 0000000000000000 0000007c 2**0 CONTENTS, READONLY 5 .note.GNU-stack 00000000 0000000000000000 0000000000000000 000000b1 2**0 CONTENTS, READONLY 6 .eh_frame 00000038 0000000000000000 0000000000000000 000000b8 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA Idx 是编号，Name 是节点名称，Size 是节大小，VMA 是在虚拟内存中的起点，LMA 是节的装载地址（除了ROM之外，通常与 VMA 相同），File off 是在文件中的具体偏移，Algn 是对齐地址。各节第二行描述了节的属性。CONTENTS 表示节在文件中占用了内存空间，ALLOC 则表示需要分配内存，RELOC 表示需要重定位。 .text 包含了已编译程序的二进制代码，.data是已经初始化的全局C变量或静态局部变量，.bss是未初始化的全局变量或静态局部变量，rodata包含只读数据。其他的数据暂时可以不用关心。 观察符号表来说明符号所在section： 12345678910111213141516171819/mnt/d/tmp$ objdump -t hello.ohello.o: file format elf64-x86-64SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 hello.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000004 l O .data 0000000000000004 b.22880000000000000000 l O .bss 0000000000000004 c.22890000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000004 O *COM* 0000000000000004 a0000000000000000 g O .data 0000000000000004 a10000000000000000 g F .text 0000000000000028 main0000000000000000 *UND* 0000000000000000 printf 各列分别是解内偏移，标记位，所在节，对齐方式和符号名。ABS 表示这是一个不和任何节相关的绝对符号，UND则这个符号不在本文件中定义，COM 表示还未分配位置的未初始化数据目标。 a和c没有初始化，放到了.bss节中，b和a1则是放到了.data节中，而mian表示的函数放到了.text节中，printf则是未定义的符号，需要进行重定位。使用objdump -r可以显示可重定位目标文件的重定位项： 123456789101112131415/mnt/d/tmp$ objdump -r hello.ohello.o: file format elf64-x86-64RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE0000000000000006 R_X86_64_PC32 .data000000000000000c R_X86_64_PC32 a-0x00000000000000040000000000000013 R_X86_64_32 .rodata000000000000001d R_X86_64_PC32 printf-0x0000000000000004RELOCATION RECORDS FOR [.eh_frame]:OFFSET TYPE VALUE0000000000000020 R_X86_64_PC32 .text 分别表示 .text 和 .eh_frame 节的重定位表。重定位表是在程序中留下的空位所在地方，可以修改代码简单验证一下。 123456789101112#include &lt;stdio.h&gt;int a;int main(void) &#123; static int b = 1; printf(&quot;hello world&quot;, a, b); printf(&quot;hello world&quot;, a, b); printf(&quot;hello world&quot;, a, b); return 0;&#125; 这里将printf使用多次，然后看看重定位表： 1234567891011121314151617181920212223/mnt/d/tmp$ objdump -r hello.ohello.o: file format elf64-x86-64RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE0000000000000006 R_X86_64_PC32 .data000000000000000c R_X86_64_PC32 a-0x00000000000000040000000000000013 R_X86_64_32 .rodata000000000000001d R_X86_64_PC32 printf-0x00000000000000040000000000000023 R_X86_64_PC32 .data0000000000000029 R_X86_64_PC32 a-0x00000000000000040000000000000030 R_X86_64_32 .rodata000000000000003a R_X86_64_PC32 printf-0x00000000000000040000000000000040 R_X86_64_PC32 .data0000000000000046 R_X86_64_PC32 a-0x0000000000000004000000000000004d R_X86_64_32 .rodata0000000000000057 R_X86_64_PC32 printf-0x0000000000000004RELOCATION RECORDS FOR [.eh_frame]:OFFSET TYPE VALUE0000000000000020 R_X86_64_PC32 .text 这样的结果刚好印证了前面的说法。 链接器将可重定位目标文件组合成为可执行或共享目标文件时，必须完成两个任务： 符号解析 符号解析是将符号的定义和每次使用联系起来 重定位 重定位则是将引用符号时留空填上对应的符号地址 符号解析链接器解析符号引用的办法是将每个引用与它输入的可重定位目标文件的符号表中一个确定的符号联系起来。如果符号的定义和引用都在同一文件内，解析起来非常方便。如果不是当前模块中定义的符号，则会在其他文件中查找，如果所有文件中都没有，那么会报错。比如对于下面的文件： 12345void bar(int,int);int main() &#123; bar(0,0); return 0;&#125; 编译器能够正常执行，并生成可重定位目标文件，但是链接器会报错误: 123/tmp/cc672f5D.o: In function `main&apos;:test.c:(.text+0x5): undefined reference to `bar&apos;collect2: error: ld returned 1 exit status NOTICE: 注意C++中符号的命名不同于C语言（存在重载），所以在C++中可能看到的符号名类似于_Z3barii 当然，如果多个文件中存在多重定义的全局符号，则会按照一定的规则来选出一个符号作为目标符号，具体信息可以查阅相关资料。 重定位你可能已经注意到在重定位表中存在这两种不同类型的重定义R_X86_64_PC32和R_X86_64_32。 前一种表示使用32位PC相对地址引用，比如pc+4之类的值，所以此处应该回填目标符号和当前符号的相对地址。 后一种表示使用32位绝对地址引用，说明此处可以直接填上符号的绝对地址，比如jmp bar。 链接器在所有的符号查找完成的同时记录下其真正的地址。链接器重定位算法大概如下： 123456789101112foreach section s &#123; foreach relocation entry r &#123; refptr = s + r.offset; if (r.type == XXXX_PC32) &#123; refaddr = ADDR(s) + r.offset; *refptr = ADDR(r.symbol) + *refptr - refaddr; &#125; if (r.type == XXXX_32) &#123; *refptr = ADDR(r.symbol) + *refptr; &#125; &#125;&#125; 其中的ADDR()表示了指定符号的真正地址。对于相对地址，首先用节的真实地址（这就是为甚么符号表中竟然含有节名）和符号在节中的偏移计算出需要回填的位置在内存中的真实地址。然后通过所引用符号的内存地址计算出其偏移。可能不能理解的是为何算法中加上了*refptr，我们可以看看重定位表项:a-0x0000000000000004，后面的值实际上就是*refptr的值。这样做可以在不同指令大小和编码方式不同的机器上，使用相同的链接器，即链接器可以透明的重定位引用，而不需要知道具体机器相关的细节。对于绝对地址，已经不需要再过解释。 静态链接库有时会用到一些第三方提供的库文件，但是只用到其中一两个函数，而整个文件非常大，感觉非常不合算。比如标准库函数，如果我们只需要一个printf却把整个标准库包含进去，得不偿失。此时静态库的概念被提出来，将所有相关的目标模块打包成为一个单独的文件，然后链接器链接的时候，只拷贝被程序引用到的目标模块或函数。 共享库与位置无关代码比如使用标准库，每个程序都拷贝一份标准库代码，如果 PC 中运行着非常多的程序时，那么标准库拷贝也会被复制多份，因此提出了共享库的概念。使用共享库，将原有的拷贝代码到程序中的方式改为 PC 中只运行一份代码库，所有程序中均调用该共享库的实例。共享库是一个目标模块，在运行时随机加载到储存器的任意地址，并和一个在储存器中的程序链接起来。这个过程成为动态链接，是由一个叫动态链接器的程序来执行的。共享库在 Unix 系统中通常使用后缀 so，在 Windows 系统中称为 DLL。 动态库是随机加载到存储器中，而用户程序怎么知道何时何地呢？此时使用叫做位置无关的代码(Position-Independent Code, PIC)来解决。举例来说明为何位置无关代码能解决这个问题，首先假设有 find_func_address 函数用于在共享库中查找目标函数地址： 1void *find_func_address(const char *name); 然后在具体的程序中使用共享库并使用内部函数： 123456789/* 假设共享库中有函数 bar，其签名如下 */typedef void (*Bar)();/* load library */Bar bar = (Bar)find_func_address(&quot;bar&quot;); bar(); /* call *//* release library */ 只需要 find_func_address 能找到函数在共享库中的地址，然后在需要的地方查找即可。不过程序员肯定受不了每次使用均调用一次 find_func_address ，并且程序中存在上千甚至更多次引用时，重复加载的效率也非常低。因此可以将代码改写一下： 123456789typedef void (*Bar)();void bar() &#123; static Bar bar_ = (Bar) find_func_address(&quot;bar&quot;); return bar_();&#125;...bar(); /* call */ 这里的代码解决了上面的两个问题：1、程序中引用共享库中的 bar 函数只需要使用 void bar() 函数即可；2、利用局部静态变量的初始化特性保证只初始化一次。 注意，上述代码并不是线程安全的，参考：多线程中局部静态变量初始化的陷阱 当然，这部分工作已经由编译器完成，我们不需要操心。在编译器实现中，使用了 GOT (global offset table) 和 PLT (procedure linkage table) 完成，而这个过程称为延迟绑定(lazy binding)。所谓延迟绑定，就是将过程地址的绑定推迟到第一次调用该过程（函数）时。每个函数均有对应的 GOT 表项和 PLT 表项，如果将之和上面的代码对应，那么 GOT 表项相当于 void bar()，而 PLT 表项相当于 static Bar bar_ = (Bar) find_func_address(&quot;bar&quot;);。在使用延迟绑定技术时，用户调用了共享库函数，此时 IP 跳转到该函数的 GOT 表项所在位置；对于首次调用，GOT 表项填着 PLT 表项地址，所以 IP 继续跳转到 PLT 表项所在位置，而 PLT 负责完成查找函数地址，并将地址保存到 GOT 表项，然后跳转到 GOT 表项从新执行；对于非首次访问，直接跳转到 GOT 所在地址，完成调用过程。 references[1] 深入理解计算机系统[2] Objdump 使用]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastJson 踩坑记录]]></title>
    <url>%2F2017%2F05%2F13%2FFastJson-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[关键字: fastjson stackoverflow本文使用的版本是 1.2.32 fastjson 是阿里开源的Json格式化工具库。在项目中使用了fastjson，然后出现了一个奇怪的bug。程序在序列化的时候递归调用了我调用序列化函数的函数。简单点说就是序列化中递归地调用了自己，最后stackoverflow。 下面是是使用的代码： 1234567891011121314151617public class Host &#123; private String name; public Host() &#123;&#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public static Host factory(byte [] bytes) &#123; return JSON.parseObjec(bytes, Host.class); &#125; public byte[] getJson() &#123; return JSON.toJSONBytes(this); &#125;&#125; 然后在程序中某处使用byte []bytes = host.getJson()，出现的错误大概如下： 123456789101112131415java.lang.StackOverflowError at com.alibaba.fastjson.serializer.JSONSerializer.setContext(JSONSerializer.java:113) at com.alibaba.fastjson.serializer.JSONSerializer.setContext(JSONSerializer.java:109) at com.alibaba.fastjson.serializer.ASMSerializer_1_Host.write(Unknown Source) at com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:275) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:679) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:605) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:598) at xxx.Host.getBytes(Host.java:38) at com.alibaba.fastjson.serializer.ASMSerializer_1_Host.write(Unknown Source) at com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:275) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:679) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:605) at com.alibaba.fastjson.JSON.toJSONBytes(JSON.java:598) at xxx.Host.getBytes(Host.java:38) 分析调用堆栈发现fastjson在生成的serializer.ASMSerializer\_1\_Host中调用了Host.getJson()导致了递归。排除自己的错误后，就将代码定位到了fastjson中，应该是fastjson中出了问题。然后开始调试代码： 1234567891011public static byte[] toJSONBytes(Object object, SerializeConfig config, int defaultFeatures, SerializerFeature... features) &#123; SerializeWriter out = new SerializeWriter(null, defaultFeatures, features); try &#123; JSONSerializer serializer = new JSONSerializer(out, config); serializer.write(object); return out.toBytes(IOUtils.UTF8); &#125; finally &#123; out.close(); &#125;&#125; 按照栈调用顺序来看，出错点应该在serializer.write(object)内部，继续深入： 123456789101112131415public final void write(Object object) &#123; if (object == null) &#123; out.writeNull(); return; &#125; Class&lt;?&gt; clazz = object.getClass(); ObjectSerializer writer = getObjectWriter(clazz); try &#123; writer.write(this, object, null, null, 0); &#125; catch (IOException e) &#123; throw new JSONException(e.getMessage(), e); &#125;&#125; 这里发现通过getObjectWriter(clazz)取得了host的writer，想必就是自动生成的ASMSerializer_1_Host实例。本来想进入writer.write中观察，没有源代码只好放弃。然后将目标放到getObjectWriter中，看看在writer实例构造过程中能不能找到点线索。 经过几层跳转，来到了真正的getObjectWriter中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235private ObjectSerializer getObjectWriter(Class&lt;?&gt; clazz, boolean create) &#123; ObjectSerializer writer = serializers.get(clazz); if (writer == null) &#123; try &#123; final ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); for (Object o : ServiceLoader.load(AutowiredObjectSerializer.class, classLoader)) &#123; if (!(o instanceof AutowiredObjectSerializer)) &#123; continue; &#125; AutowiredObjectSerializer autowired = (AutowiredObjectSerializer) o; for (Type forType : autowired.getAutowiredFor()) &#123; put(forType, autowired); &#125; &#125; &#125; catch (ClassCastException ex) &#123; // skip &#125; writer = serializers.get(clazz); &#125; if (writer == null) &#123; final ClassLoader classLoader = JSON.class.getClassLoader(); if (classLoader != Thread.currentThread().getContextClassLoader()) &#123; try &#123; for (Object o : ServiceLoader.load(AutowiredObjectSerializer.class, classLoader)) &#123; if (!(o instanceof AutowiredObjectSerializer)) &#123; continue; &#125; AutowiredObjectSerializer autowired = (AutowiredObjectSerializer) o; for (Type forType : autowired.getAutowiredFor()) &#123; put(forType, autowired); &#125; &#125; &#125; catch (ClassCastException ex) &#123; // skip &#125; writer = serializers.get(clazz); &#125; &#125; if (writer == null) &#123; if (Map.class.isAssignableFrom(clazz)) &#123; put(clazz, MapSerializer.instance); &#125; else if (List.class.isAssignableFrom(clazz)) &#123; put(clazz, ListSerializer.instance); &#125; else if (Collection.class.isAssignableFrom(clazz)) &#123; put(clazz, CollectionCodec.instance); &#125; else if (Date.class.isAssignableFrom(clazz)) &#123; put(clazz, DateCodec.instance); &#125; else if (JSONAware.class.isAssignableFrom(clazz)) &#123; put(clazz, JSONAwareSerializer.instance); &#125; else if (JSONSerializable.class.isAssignableFrom(clazz)) &#123; put(clazz, JSONSerializableSerializer.instance); &#125; else if (JSONStreamAware.class.isAssignableFrom(clazz)) &#123; put(clazz, MiscCodec.instance); &#125; else if (clazz.isEnum() || (clazz.getSuperclass() != null &amp;&amp; clazz.getSuperclass().isEnum())) &#123; JSONType jsonType = clazz.getAnnotation(JSONType.class); if (jsonType != null &amp;&amp; jsonType.serializeEnumAsJavaBean()) &#123; put(clazz, createJavaBeanSerializer(clazz)); &#125; else &#123; put(clazz, EnumSerializer.instance); &#125; &#125; else if (clazz.isArray()) &#123; Class&lt;?&gt; componentType = clazz.getComponentType(); ObjectSerializer compObjectSerializer = getObjectWriter(componentType); put(clazz, new ArraySerializer(componentType, compObjectSerializer)); &#125; else if (Throwable.class.isAssignableFrom(clazz)) &#123; SerializeBeanInfo beanInfo = TypeUtils.buildBeanInfo(clazz, null, propertyNamingStrategy); beanInfo.features |= SerializerFeature.WriteClassName.mask; put(clazz, new JavaBeanSerializer(beanInfo)); &#125; else if (TimeZone.class.isAssignableFrom(clazz) || Map.Entry.class.isAssignableFrom(clazz)) &#123; put(clazz, MiscCodec.instance); &#125; else if (Appendable.class.isAssignableFrom(clazz)) &#123; put(clazz, AppendableSerializer.instance); &#125; else if (Charset.class.isAssignableFrom(clazz)) &#123; put(clazz, ToStringSerializer.instance); &#125; else if (Enumeration.class.isAssignableFrom(clazz)) &#123; put(clazz, EnumerationSerializer.instance); &#125; else if (Calendar.class.isAssignableFrom(clazz) // || XMLGregorianCalendar.class.isAssignableFrom(clazz)) &#123; put(clazz, CalendarCodec.instance); &#125; else if (Clob.class.isAssignableFrom(clazz)) &#123; put(clazz, ClobSeriliazer.instance); &#125; else if (TypeUtils.isPath(clazz)) &#123; put(clazz, ToStringSerializer.instance); &#125; else if (Iterator.class.isAssignableFrom(clazz)) &#123; put(clazz, MiscCodec.instance); &#125; else &#123; String className = clazz.getName(); if (className.startsWith(&quot;java.awt.&quot;) // &amp;&amp; AwtCodec.support(clazz) // ) &#123; // awt if (!awtError) &#123; try &#123; put(Class.forName(&quot;java.awt.Color&quot;), AwtCodec.instance); put(Class.forName(&quot;java.awt.Font&quot;), AwtCodec.instance); put(Class.forName(&quot;java.awt.Point&quot;), AwtCodec.instance); put(Class.forName(&quot;java.awt.Rectangle&quot;), AwtCodec.instance); &#125; catch (Throwable e) &#123; awtError = true; // skip &#125; &#125; return AwtCodec.instance; &#125; // jdk8 if ((!jdk8Error) // &amp;&amp; (className.startsWith(&quot;java.time.&quot;) // || className.startsWith(&quot;java.util.Optional&quot;) // || className.equals(&quot;java.util.concurrent.atomic.LongAdder&quot;) || className.equals(&quot;java.util.concurrent.atomic.DoubleAdder&quot;) )) &#123; try &#123; put(Class.forName(&quot;java.time.LocalDateTime&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.LocalDate&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.LocalTime&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.ZonedDateTime&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.OffsetDateTime&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.OffsetTime&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.ZoneOffset&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.ZoneRegion&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.Period&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.Duration&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.time.Instant&quot;), Jdk8DateCodec.instance); put(Class.forName(&quot;java.util.Optional&quot;), OptionalCodec.instance); put(Class.forName(&quot;java.util.OptionalDouble&quot;), OptionalCodec.instance); put(Class.forName(&quot;java.util.OptionalInt&quot;), OptionalCodec.instance); put(Class.forName(&quot;java.util.OptionalLong&quot;), OptionalCodec.instance); put(Class.forName(&quot;java.util.concurrent.atomic.LongAdder&quot;), AdderSerializer.instance); put(Class.forName(&quot;java.util.concurrent.atomic.DoubleAdder&quot;), AdderSerializer.instance); writer = serializers.get(clazz); if (writer != null) &#123; return writer; &#125; &#125; catch (Throwable e) &#123; // skip jdk8Error = true; &#125; &#125; if ((!oracleJdbcError) // &amp;&amp; className.startsWith(&quot;oracle.sql.&quot;)) &#123; try &#123; put(Class.forName(&quot;oracle.sql.DATE&quot;), DateCodec.instance); put(Class.forName(&quot;oracle.sql.TIMESTAMP&quot;), DateCodec.instance); writer = serializers.get(clazz); if (writer != null) &#123; return writer; &#125; &#125; catch (Throwable e) &#123; // skip oracleJdbcError = true; &#125; &#125; if ((!springfoxError) // &amp;&amp; className.equals(&quot;springfox.documentation.spring.web.json.Json&quot;)) &#123; try &#123; put(Class.forName(&quot;springfox.documentation.spring.web.json.Json&quot;), // SwaggerJsonSerializer.instance); writer = serializers.get(clazz); if (writer != null) &#123; return writer; &#125; &#125; catch (ClassNotFoundException e) &#123; // skip springfoxError = true; &#125; &#125; if ((!guavaError) // &amp;&amp; className.startsWith(&quot;com.google.common.collect.&quot;)) &#123; try &#123; put(Class.forName(&quot;com.google.common.collect.HashMultimap&quot;), // GuavaCodec.instance); put(Class.forName(&quot;com.google.common.collect.LinkedListMultimap&quot;), // GuavaCodec.instance); put(Class.forName(&quot;com.google.common.collect.ArrayListMultimap&quot;), // GuavaCodec.instance); put(Class.forName(&quot;com.google.common.collect.TreeMultimap&quot;), // GuavaCodec.instance); writer = serializers.get(clazz); if (writer != null) &#123; return writer; &#125; &#125; catch (ClassNotFoundException e) &#123; // skip guavaError = true; &#125; &#125; if (className.equals(&quot;net.sf.json.JSONNull&quot;)) &#123; try &#123; put(Class.forName(&quot;net.sf.json.JSONNull&quot;), // MiscCodec.instance); &#125; catch (ClassNotFoundException e) &#123; // skip &#125; writer = serializers.get(clazz); if (writer != null) &#123; return writer; &#125; &#125; if (TypeUtils.isProxy(clazz)) &#123; Class&lt;?&gt; superClazz = clazz.getSuperclass(); ObjectSerializer superWriter = getObjectWriter(superClazz); put(clazz, superWriter); return superWriter; &#125; if (create) &#123; put(clazz, createJavaBeanSerializer(clazz)); &#125; &#125; writer = serializers.get(clazz); &#125; return writer;&#125; 简单扫描代码逻辑，发现writer是通过serializers.get(clazz)获取的。而代码中分别从Thread.currentThread().getContextClassLoader、JSON.class.getClassLoader以及最后对一下常见类分析来填充serializers。最后一种办法的末尾，走到了： 1put(clazz, createJavaBeanSerializer(clazz)); 可以发现逻辑是实在找不到，使用createJavaBeanSerializer(clazz)来创建clazz对应的writer。看来我们的目标应该是这个createJavaBeanSerializer函数，所以进一步深入： 12345678private final ObjectSerializer createJavaBeanSerializer(Class&lt;?&gt; clazz) &#123; SerializeBeanInfo beanInfo = TypeUtils.buildBeanInfo(clazz, null, propertyNamingStrategy, fieldBased); if (beanInfo.fields.length == 0 &amp;&amp; Iterable.class.isAssignableFrom(clazz)) &#123; return MiscCodec.instance; &#125; return createJavaBeanSerializer(beanInfo);&#125; 首先调用TypeUtils.buildBeanInfo来生成SerializerBeanInfo。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static SerializeBeanInfo buildBeanInfo(Class&lt;?&gt; beanType // , Map&lt;String, String&gt; aliasMap // , PropertyNamingStrategy propertyNamingStrategy // , boolean fieldBased //) &#123; JSONType jsonType = beanType.getAnnotation(JSONType.class); // fieldName,field ，先生成fieldName的快照，减少之后的findField的轮询 Map&lt;String, Field&gt; fieldCacheMap = new HashMap&lt;String, Field&gt;(); ParserConfig.parserAllFieldToCache(beanType, fieldCacheMap); List&lt;FieldInfo&gt; fieldInfoList = fieldBased ? computeGettersWithFieldBase(beanType, aliasMap, false, propertyNamingStrategy) // : computeGetters(beanType, jsonType, aliasMap, fieldCacheMap, false, propertyNamingStrategy); FieldInfo[] fields = new FieldInfo[fieldInfoList.size()]; fieldInfoList.toArray(fields); String[] orders = null; final int features; String typeName = null; if (jsonType != null) &#123; orders = jsonType.orders(); typeName = jsonType.typeName(); if (typeName.length() == 0) &#123; typeName = null; &#125; features = SerializerFeature.of(jsonType.serialzeFeatures()); &#125; else &#123; features = 0; &#125; FieldInfo[] sortedFields; List&lt;FieldInfo&gt; sortedFieldList; if (orders != null &amp;&amp; orders.length != 0) &#123; sortedFieldList = fieldBased ? computeGettersWithFieldBase(beanType, aliasMap, true, propertyNamingStrategy) // : computeGetters(beanType, jsonType, aliasMap,fieldCacheMap, true, propertyNamingStrategy); &#125; else &#123; sortedFieldList = new ArrayList&lt;FieldInfo&gt;(fieldInfoList); Collections.sort(sortedFieldList); &#125; sortedFields = new FieldInfo[sortedFieldList.size()]; sortedFieldList.toArray(sortedFields); if (Arrays.equals(sortedFields, fields)) &#123; sortedFields = fields; &#125; return new SerializeBeanInfo(beanType, jsonType, typeName, features, fields, sortedFields);&#125; 其中parserAllFieldToCache将字段保存起来，减少访问次数。紧接着设置fieldInfoList的值，此时fieldBase为false，所以进入了computeGetters。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265public static List&lt;FieldInfo&gt; computeGetters(Class&lt;?&gt; clazz, // JSONType jsonType, // Map&lt;String, String&gt; aliasMap, // Map&lt;String, Field&gt; fieldCacheMap, // boolean sorted, // PropertyNamingStrategy propertyNamingStrategy //) &#123; Map&lt;String, FieldInfo&gt; fieldInfoMap = new LinkedHashMap&lt;String, FieldInfo&gt;(); for (Method method : clazz.getMethods()) &#123; String methodName = method.getName(); int ordinal = 0, serialzeFeatures = 0, parserFeatures = 0; String label = null; if (Modifier.isStatic(method.getModifiers())) &#123; continue; &#125; if (method.getReturnType().equals(Void.TYPE)) &#123; continue; &#125; if (method.getParameterTypes().length != 0) &#123; continue; &#125; if (method.getReturnType() == ClassLoader.class) &#123; continue; &#125; if (method.getName().equals(&quot;getMetaClass&quot;) &amp;&amp; method.getReturnType().getName().equals(&quot;groovy.lang.MetaClass&quot;)) &#123; continue; &#125; JSONField annotation = method.getAnnotation(JSONField.class); if (annotation == null) &#123; annotation = getSuperMethodAnnotation(clazz, method); &#125; if (annotation != null) &#123; if (!annotation.serialize()) &#123; continue; &#125; ordinal = annotation.ordinal(); serialzeFeatures = SerializerFeature.of(annotation.serialzeFeatures()); parserFeatures = Feature.of(annotation.parseFeatures()); if (annotation.name().length() != 0) &#123; String propertyName = annotation.name(); if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; FieldInfo fieldInfo = new FieldInfo(propertyName, method, null, clazz, null, ordinal, serialzeFeatures, parserFeatures, annotation, null, label); fieldInfoMap.put(propertyName, fieldInfo); continue; &#125; if (annotation.label().length() != 0) &#123; label = annotation.label(); &#125; &#125; if (methodName.startsWith(&quot;get&quot;)) &#123; if (methodName.length() &lt; 4) &#123; continue; &#125; if (methodName.equals(&quot;getClass&quot;)) &#123; continue; &#125; if (methodName.equals(&quot;getDeclaringClass&quot;) &amp;&amp; clazz.isEnum()) &#123; continue; &#125; char c3 = methodName.charAt(3); String propertyName; if (Character.isUpperCase(c3) // || c3 &gt; 512 // for unicode method name ) &#123; if (compatibleWithJavaBean) &#123; propertyName = decapitalize(methodName.substring(3)); &#125; else &#123; propertyName = Character.toLowerCase(methodName.charAt(3)) + methodName.substring(4); &#125; propertyName = getPropertyNameByCompatibleFieldName(fieldCacheMap, methodName, propertyName,3); &#125; else if (c3 == &apos;_&apos;) &#123; propertyName = methodName.substring(4); &#125; else if (c3 == &apos;f&apos;) &#123; propertyName = methodName.substring(3); &#125; else if (methodName.length() &gt;= 5 &amp;&amp; Character.isUpperCase(methodName.charAt(4))) &#123; propertyName = decapitalize(methodName.substring(3)); &#125; else &#123; continue; &#125; boolean ignore = isJSONTypeIgnore(clazz, propertyName); if (ignore) &#123; continue; &#125; //假如bean的field很多的情况一下，轮询时将大大降低效率 Field field = ParserConfig.getFieldFromCache(propertyName, fieldCacheMap); if (field == null &amp;&amp; propertyName.length() &gt; 1) &#123; char ch = propertyName.charAt(1); if (ch &gt;= &apos;A&apos; &amp;&amp; ch &lt;= &apos;Z&apos;) &#123; String javaBeanCompatiblePropertyName = decapitalize(methodName.substring(3)); field = ParserConfig.getFieldFromCache(javaBeanCompatiblePropertyName, fieldCacheMap); &#125; &#125; JSONField fieldAnnotation = null; if (field != null) &#123; fieldAnnotation = field.getAnnotation(JSONField.class); if (fieldAnnotation != null) &#123; if (!fieldAnnotation.serialize()) &#123; continue; &#125; ordinal = fieldAnnotation.ordinal(); serialzeFeatures = SerializerFeature.of(fieldAnnotation.serialzeFeatures()); parserFeatures = Feature.of(fieldAnnotation.parseFeatures()); if (fieldAnnotation.name().length() != 0) &#123; propertyName = fieldAnnotation.name(); if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; &#125; if (fieldAnnotation.label().length() != 0) &#123; label = fieldAnnotation.label(); &#125; &#125; &#125; if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; if (propertyNamingStrategy != null) &#123; propertyName = propertyNamingStrategy.translate(propertyName); &#125; FieldInfo fieldInfo = new FieldInfo(propertyName, method, field, clazz, null, ordinal, serialzeFeatures, parserFeatures, annotation, fieldAnnotation, label); fieldInfoMap.put(propertyName, fieldInfo); &#125; if (methodName.startsWith(&quot;is&quot;)) &#123; if (methodName.length() &lt; 3) &#123; continue; &#125; if (method.getReturnType() != Boolean.TYPE &amp;&amp; method.getReturnType() != Boolean.class) &#123; continue; &#125; char c2 = methodName.charAt(2); String propertyName; if (Character.isUpperCase(c2)) &#123; if (compatibleWithJavaBean) &#123; propertyName = decapitalize(methodName.substring(2)); &#125; else &#123; propertyName = Character.toLowerCase(methodName.charAt(2)) + methodName.substring(3); &#125; propertyName = getPropertyNameByCompatibleFieldName(fieldCacheMap, methodName, propertyName,2); &#125; else if (c2 == &apos;_&apos;) &#123; propertyName = methodName.substring(3); &#125; else if (c2 == &apos;f&apos;) &#123; propertyName = methodName.substring(2); &#125; else &#123; continue; &#125; boolean ignore = isJSONTypeIgnore(clazz, propertyName); if (ignore) &#123; continue; &#125; Field field = ParserConfig.getFieldFromCache(propertyName,fieldCacheMap); if (field == null) &#123; field = ParserConfig.getFieldFromCache(methodName,fieldCacheMap); &#125; JSONField fieldAnnotation = null; if (field != null) &#123; fieldAnnotation = field.getAnnotation(JSONField.class); if (fieldAnnotation != null) &#123; if (!fieldAnnotation.serialize()) &#123; continue; &#125; ordinal = fieldAnnotation.ordinal(); serialzeFeatures = SerializerFeature.of(fieldAnnotation.serialzeFeatures()); parserFeatures = Feature.of(fieldAnnotation.parseFeatures()); if (fieldAnnotation.name().length() != 0) &#123; propertyName = fieldAnnotation.name(); if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; &#125; if (fieldAnnotation.label().length() != 0) &#123; label = fieldAnnotation.label(); &#125; &#125; &#125; if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; if (propertyNamingStrategy != null) &#123; propertyName = propertyNamingStrategy.translate(propertyName); &#125; //优先选择get if (fieldInfoMap.containsKey(propertyName)) &#123; continue; &#125; FieldInfo fieldInfo = new FieldInfo(propertyName, method, field, clazz, null, ordinal, serialzeFeatures, parserFeatures, annotation, fieldAnnotation, label); fieldInfoMap.put(propertyName, fieldInfo); &#125; &#125; Field[] fields = clazz.getFields(); computeFields(clazz, aliasMap, propertyNamingStrategy, fieldInfoMap, fields); return getFieldInfos(clazz, sorted, fieldInfoMap);&#125; 这里针对clazz的每一个方法进行了判断，由于只有get和set开头的函数，所以只关心methodName.startsWith(&quot;get&quot;)分支。最后进入了getPropertyNameByCompatibleFieldName所在的分支，并将propertyName设置为对应get的属性名。在getPropertyNameByCompatibleFieldName函数中，而compatibleWithFieldName设置为false所以相当于跳过了。 12345678910private static String getPropertyNameByCompatibleFieldName(Map&lt;String, Field&gt; fieldCacheMap, String methodName, String propertyName,int fromIdx) &#123; if (compatibleWithFieldName)&#123; if (!fieldCacheMap.containsKey(propertyName))&#123; String tempPropertyName=methodName.substring(fromIdx); return fieldCacheMap.containsKey(tempPropertyName)?tempPropertyName:propertyName; &#125; &#125; return propertyName;&#125; 继续分析，程序进入isJSONTypeIgnore根据注解判断是否跳过该字段，我的例子中不关心。紧接着调用了getFieldFromCache： 1234567891011121314151617181920212223public static Field getFieldFromCache(String fieldName, Map&lt;String, Field&gt; fieldCacheMap) &#123; Field field = fieldCacheMap.get(fieldName); if (field == null) &#123; field = fieldCacheMap.get(&quot;_&quot; + fieldName); &#125; if (field == null) &#123; field = fieldCacheMap.get(&quot;m_&quot; + fieldName); &#125; if (field == null) &#123; char c0 = fieldName.charAt(0); if (c0 &gt;= &apos;a&apos; &amp;&amp; c0 &lt;= &apos;z&apos;) &#123; char[] chars = fieldName.toCharArray(); chars[0] -= 32; // lower String fieldNameX = new String(chars); field = fieldCacheMap.get(fieldNameX); &#125; &#125; return field;&#125; 这里按照刚才取出的方法名来查找字段，如果失败则加上_或者m_之类的方法继续判断。返回继续分析，在做了部分如注解别名之类的处理后，将分析得到的结果生成一个FieldInfo，并保存在fieldInfoMap中。最后调用computeFields进一步处理一些public属性的fields数据。最后经过getFieldInfos处理后，将得到的List&lt;FieldInfo&gt;中，返回上一级。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private static void computeFields( Class&lt;?&gt; clazz, // Map&lt;String, String&gt; aliasMap, // PropertyNamingStrategy propertyNamingStrategy, // Map&lt;String, FieldInfo&gt; fieldInfoMap, // Field[] fields) &#123; for (Field field : fields) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; continue; &#125; JSONField fieldAnnotation = field.getAnnotation(JSONField.class); int ordinal = 0, serialzeFeatures = 0, parserFeatures = 0; String propertyName = field.getName(); String label = null; if (fieldAnnotation != null) &#123; if (!fieldAnnotation.serialize()) &#123; continue; &#125; ordinal = fieldAnnotation.ordinal(); serialzeFeatures = SerializerFeature.of(fieldAnnotation.serialzeFeatures()); parserFeatures = Feature.of(fieldAnnotation.parseFeatures()); if (fieldAnnotation.name().length() != 0) &#123; propertyName = fieldAnnotation.name(); &#125; if (fieldAnnotation.label().length() != 0) &#123; label = fieldAnnotation.label(); &#125; &#125; if (aliasMap != null) &#123; propertyName = aliasMap.get(propertyName); if (propertyName == null) &#123; continue; &#125; &#125; if (propertyNamingStrategy != null) &#123; propertyName = propertyNamingStrategy.translate(propertyName); &#125; if (!fieldInfoMap.containsKey(propertyName)) &#123; FieldInfo fieldInfo = new FieldInfo(propertyName, null, field, clazz, null, ordinal, serialzeFeatures, parserFeatures, null, fieldAnnotation, label); fieldInfoMap.put(propertyName, fieldInfo); &#125; &#125;&#125; 分析到这里，可以发现在fieldInfoList中实际上值：name,json。看到这里相比也能猜出大概了，现在继续跟踪。回到buildBeanInfo中，将刚才得到的fieldInfoList构造为SerializeBeanInfo并返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public ObjectSerializer createJavaBeanSerializer(SerializeBeanInfo beanInfo) &#123; JSONType jsonType = beanInfo.jsonType; if (jsonType != null) &#123; Class&lt;?&gt; serializerClass = jsonType.serializer(); if (serializerClass != Void.class) &#123; try &#123; Object seralizer = serializerClass.newInstance(); if (seralizer instanceof ObjectSerializer) &#123; return (ObjectSerializer) seralizer; &#125; &#125; catch (Throwable e) &#123; // skip &#125; &#125; if (jsonType.asm() == false) &#123; asm = false; &#125; for (SerializerFeature feature : jsonType.serialzeFeatures()) &#123; if (SerializerFeature.WriteNonStringValueAsString == feature // || SerializerFeature.WriteEnumUsingToString == feature // || SerializerFeature.NotWriteDefaultValue == feature) &#123; asm = false; break; &#125; &#125; &#125; Class&lt;?&gt; clazz = beanInfo.beanType; if (!Modifier.isPublic(beanInfo.beanType.getModifiers())) &#123; return new JavaBeanSerializer(beanInfo); &#125; boolean asm = this.asm &amp;&amp; !fieldBased; if (asm &amp;&amp; asmFactory.classLoader.isExternalClass(clazz) || clazz == Serializable.class || clazz == Object.class) &#123; asm = false; &#125; if (asm &amp;&amp; !ASMUtils.checkName(clazz.getSimpleName())) &#123; asm = false; &#125; if (asm) &#123; for(FieldInfo fieldInfo : beanInfo.fields)&#123; Field field = fieldInfo.field; if (field != null &amp;&amp; !field.getType().equals(fieldInfo.fieldClass)) &#123; asm = false; break; &#125; Method method = fieldInfo.method; if (method != null &amp;&amp; !method.getReturnType().equals(fieldInfo.fieldClass)) &#123; asm = false; break; &#125; JSONField annotation = fieldInfo.getAnnotation(); if (annotation == null) &#123; continue; &#125; if ((!ASMUtils.checkName(annotation.name())) // || annotation.format().length() != 0 || annotation.jsonDirect() || annotation.serializeUsing() != Void.class || annotation.unwrapped() ) &#123; asm = false; break; &#125; for (SerializerFeature feature : annotation.serialzeFeatures()) &#123; if (SerializerFeature.WriteNonStringValueAsString == feature // || SerializerFeature.WriteEnumUsingToString == feature // || SerializerFeature.NotWriteDefaultValue == feature) &#123; asm = false; break; &#125; &#125; &#125; &#125; if (asm) &#123; try &#123; ObjectSerializer asmSerializer = createASMSerializer(beanInfo); if (asmSerializer != null) &#123; return asmSerializer; &#125; &#125; catch (ClassFormatError e) &#123; // skip &#125; catch (ClassCastException e) &#123; // skip &#125; catch (Throwable e) &#123; throw new JSONException(&quot;create asm serializer error, class &quot; + clazz, e); &#125; &#125; return new JavaBeanSerializer(beanInfo);&#125; 经过处理后进入了createASMSerializer，其中调用createJavaBeanSerializer来创建具体的writer： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301public JavaBeanSerializer createJavaBeanSerializer(SerializeBeanInfo beanInfo) throws Exception &#123; Class&lt;?&gt; clazz = beanInfo.beanType; if (clazz.isPrimitive()) &#123; throw new JSONException(&quot;unsupportd class &quot; + clazz.getName()); &#125; JSONType jsonType = clazz.getAnnotation(JSONType.class); FieldInfo[] unsortedGetters = beanInfo.fields;; for (FieldInfo fieldInfo : unsortedGetters) &#123; if (fieldInfo.field == null // &amp;&amp; fieldInfo.method != null // &amp;&amp; fieldInfo.method.getDeclaringClass().isInterface()) &#123; return new JavaBeanSerializer(clazz); &#125; &#125; FieldInfo[] getters = beanInfo.sortedFields; boolean nativeSorted = beanInfo.sortedFields == beanInfo.fields; if (getters.length &gt; 256) &#123; return new JavaBeanSerializer(clazz); &#125; for (FieldInfo getter : getters) &#123; if (!ASMUtils.checkName(getter.getMember().getName())) &#123; return new JavaBeanSerializer(clazz); &#125; &#125; String className = &quot;ASMSerializer_&quot; + seed.incrementAndGet() + &quot;_&quot; + clazz.getSimpleName(); String packageName = ASMSerializerFactory.class.getPackage().getName(); String classNameType = packageName.replace(&apos;.&apos;, &apos;/&apos;) + &quot;/&quot; + className; String classNameFull = packageName + &quot;.&quot; + className; ClassWriter cw = new ClassWriter(); cw.visit(V1_5 // , ACC_PUBLIC + ACC_SUPER // , classNameType // , JavaBeanSerializer // , new String[] &#123; ObjectSerializer &#125; // ); for (FieldInfo fieldInfo : getters) &#123; if (fieldInfo.fieldClass.isPrimitive() // //|| fieldInfo.fieldClass.isEnum() // || fieldInfo.fieldClass == String.class) &#123; continue; &#125; new FieldWriter(cw, ACC_PUBLIC, fieldInfo.name + &quot;_asm_fieldType&quot;, &quot;Ljava/lang/reflect/Type;&quot;) // .visitEnd(); if (List.class.isAssignableFrom(fieldInfo.fieldClass)) &#123; new FieldWriter(cw, ACC_PUBLIC, fieldInfo.name + &quot;_asm_list_item_ser_&quot;, ObjectSerializer_desc) // .visitEnd(); &#125; new FieldWriter(cw, ACC_PUBLIC, fieldInfo.name + &quot;_asm_ser_&quot;, ObjectSerializer_desc) // .visitEnd(); &#125; MethodVisitor mw = new MethodWriter(cw, ACC_PUBLIC, &quot;&lt;init&gt;&quot;, &quot;(&quot; + desc(SerializeBeanInfo.class) + &quot;)V&quot;, null, null); mw.visitVarInsn(ALOAD, 0); mw.visitVarInsn(ALOAD, 1); mw.visitMethodInsn(INVOKESPECIAL, JavaBeanSerializer, &quot;&lt;init&gt;&quot;, &quot;(&quot; + desc(SerializeBeanInfo.class) + &quot;)V&quot;); // init _asm_fieldType for (int i = 0; i &lt; getters.length; ++i) &#123; FieldInfo fieldInfo = getters[i]; if (fieldInfo.fieldClass.isPrimitive() //// || fieldInfo.fieldClass.isEnum() // || fieldInfo.fieldClass == String.class) &#123; continue; &#125; mw.visitVarInsn(ALOAD, 0); if (fieldInfo.method != null) &#123; mw.visitLdcInsn(com.alibaba.fastjson.asm.Type.getType(desc(fieldInfo.declaringClass))); mw.visitLdcInsn(fieldInfo.method.getName()); mw.visitMethodInsn(INVOKESTATIC, type(ASMUtils.class), &quot;getMethodType&quot;, &quot;(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/reflect/Type;&quot;); &#125; else &#123; mw.visitVarInsn(ALOAD, 0); mw.visitLdcInsn(i); mw.visitMethodInsn(INVOKESPECIAL, JavaBeanSerializer, &quot;getFieldType&quot;, &quot;(I)Ljava/lang/reflect/Type;&quot;); &#125; mw.visitFieldInsn(PUTFIELD, classNameType, fieldInfo.name + &quot;_asm_fieldType&quot;, &quot;Ljava/lang/reflect/Type;&quot;); &#125; mw.visitInsn(RETURN); mw.visitMaxs(4, 4); mw.visitEnd(); boolean DisableCircularReferenceDetect = false; if (jsonType != null) &#123; for (SerializerFeature featrues : jsonType.serialzeFeatures()) &#123; if (featrues == SerializerFeature.DisableCircularReferenceDetect) &#123; DisableCircularReferenceDetect = true; break; &#125; &#125; &#125; // 0 write // 1 writeNormal // 2 writeNonContext for (int i = 0; i &lt; 3; ++i) &#123; String methodName; boolean nonContext = DisableCircularReferenceDetect; boolean writeDirect = false; if (i == 0) &#123; methodName = &quot;write&quot;; writeDirect = true; &#125; else if (i == 1) &#123; methodName = &quot;writeNormal&quot;; &#125; else &#123; writeDirect = true; nonContext = true; methodName = &quot;writeDirectNonContext&quot;; &#125; Context context = new Context(getters, beanInfo, classNameType, writeDirect, nonContext); mw = new MethodWriter(cw, // ACC_PUBLIC, // methodName, // &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;, // null, // new String[] &#123; &quot;java/io/IOException&quot; &#125; // ); &#123; Label endIf_ = new Label(); mw.visitVarInsn(ALOAD, Context.obj); //serializer.writeNull(); mw.visitJumpInsn(IFNONNULL, endIf_); mw.visitVarInsn(ALOAD, Context.serializer); mw.visitMethodInsn(INVOKEVIRTUAL, JSONSerializer, &quot;writeNull&quot;, &quot;()V&quot;); mw.visitInsn(RETURN); mw.visitLabel(endIf_); &#125; mw.visitVarInsn(ALOAD, Context.serializer); mw.visitFieldInsn(GETFIELD, JSONSerializer, &quot;out&quot;, SerializeWriter_desc); mw.visitVarInsn(ASTORE, context.var(&quot;out&quot;)); if ((!nativeSorted) // &amp;&amp; !context.writeDirect) &#123; if (jsonType == null || jsonType.alphabetic()) &#123; Label _else = new Label(); mw.visitVarInsn(ALOAD, context.var(&quot;out&quot;)); mw.visitMethodInsn(INVOKEVIRTUAL, SerializeWriter, &quot;isSortField&quot;, &quot;()Z&quot;); mw.visitJumpInsn(IFNE, _else); mw.visitVarInsn(ALOAD, 0); mw.visitVarInsn(ALOAD, 1); mw.visitVarInsn(ALOAD, 2); mw.visitVarInsn(ALOAD, 3); mw.visitVarInsn(ALOAD, 4); mw.visitVarInsn(ILOAD, 5); mw.visitMethodInsn(INVOKEVIRTUAL, classNameType, &quot;writeUnsorted&quot;, &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;); mw.visitInsn(RETURN); mw.visitLabel(_else); &#125; &#125; // isWriteDoubleQuoteDirect if (context.writeDirect &amp;&amp; !nonContext) &#123; Label _direct = new Label(); Label _directElse = new Label(); mw.visitVarInsn(ALOAD, 0); mw.visitVarInsn(ALOAD, Context.serializer); mw.visitMethodInsn(INVOKEVIRTUAL, JavaBeanSerializer, &quot;writeDirect&quot;, &quot;(L&quot; + JSONSerializer + &quot;;)Z&quot;); mw.visitJumpInsn(IFNE, _directElse); mw.visitVarInsn(ALOAD, 0); mw.visitVarInsn(ALOAD, 1); mw.visitVarInsn(ALOAD, 2); mw.visitVarInsn(ALOAD, 3); mw.visitVarInsn(ALOAD, 4); mw.visitVarInsn(ILOAD, 5); mw.visitMethodInsn(INVOKEVIRTUAL, classNameType, &quot;writeNormal&quot;, &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;); mw.visitInsn(RETURN); mw.visitLabel(_directElse); mw.visitVarInsn(ALOAD, context.var(&quot;out&quot;)); mw.visitLdcInsn(SerializerFeature.DisableCircularReferenceDetect.mask); mw.visitMethodInsn(INVOKEVIRTUAL, SerializeWriter, &quot;isEnabled&quot;, &quot;(I)Z&quot;); mw.visitJumpInsn(IFEQ, _direct); mw.visitVarInsn(ALOAD, 0); mw.visitVarInsn(ALOAD, 1); mw.visitVarInsn(ALOAD, 2); mw.visitVarInsn(ALOAD, 3); mw.visitVarInsn(ALOAD, 4); mw.visitVarInsn(ILOAD, 5); mw.visitMethodInsn(INVOKEVIRTUAL, classNameType, &quot;writeDirectNonContext&quot;, &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;); mw.visitInsn(RETURN); mw.visitLabel(_direct); &#125; mw.visitVarInsn(ALOAD, Context.obj); // obj mw.visitTypeInsn(CHECKCAST, type(clazz)); // serializer mw.visitVarInsn(ASTORE, context.var(&quot;entity&quot;)); // obj generateWriteMethod(clazz, mw, getters, context); mw.visitInsn(RETURN); mw.visitMaxs(7, context.variantIndex + 2); mw.visitEnd(); &#125; if (!nativeSorted) &#123; // sortField support Context context = new Context(getters, beanInfo, classNameType, false, DisableCircularReferenceDetect); mw = new MethodWriter(cw, ACC_PUBLIC, &quot;writeUnsorted&quot;, &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;, null, new String[] &#123; &quot;java/io/IOException&quot; &#125;); mw.visitVarInsn(ALOAD, Context.serializer); mw.visitFieldInsn(GETFIELD, JSONSerializer, &quot;out&quot;, SerializeWriter_desc); mw.visitVarInsn(ASTORE, context.var(&quot;out&quot;)); mw.visitVarInsn(ALOAD, Context.obj); // obj mw.visitTypeInsn(CHECKCAST, type(clazz)); // serializer mw.visitVarInsn(ASTORE, context.var(&quot;entity&quot;)); // obj generateWriteMethod(clazz, mw, unsortedGetters, context); mw.visitInsn(RETURN); mw.visitMaxs(7, context.variantIndex + 2); mw.visitEnd(); &#125; // 0 writeAsArray // 1 writeAsArrayNormal // 2 writeAsArrayNonContext for (int i = 0; i &lt; 3; ++i) &#123; String methodName; boolean nonContext = DisableCircularReferenceDetect; boolean writeDirect = false; if (i == 0) &#123; methodName = &quot;writeAsArray&quot;; writeDirect = true; &#125; else if (i == 1) &#123; methodName = &quot;writeAsArrayNormal&quot;; &#125; else &#123; writeDirect = true; nonContext = true; methodName = &quot;writeAsArrayNonContext&quot;; &#125; Context context = new Context(getters, beanInfo, classNameType, writeDirect, nonContext); mw = new MethodWriter(cw, ACC_PUBLIC, methodName, &quot;(L&quot; + JSONSerializer + &quot;;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/reflect/Type;I)V&quot;, null, new String[] &#123; &quot;java/io/IOException&quot; &#125;); mw.visitVarInsn(ALOAD, Context.serializer); mw.visitFieldInsn(GETFIELD, JSONSerializer, &quot;out&quot;, SerializeWriter_desc); mw.visitVarInsn(ASTORE, context.var(&quot;out&quot;)); mw.visitVarInsn(ALOAD, Context.obj); // obj mw.visitTypeInsn(CHECKCAST, type(clazz)); // serializer mw.visitVarInsn(ASTORE, context.var(&quot;entity&quot;)); // obj generateWriteAsArray(clazz, mw, getters, context); mw.visitInsn(RETURN); mw.visitMaxs(7, context.variantIndex + 2); mw.visitEnd(); &#125; byte[] code = cw.toByteArray(); Class&lt;?&gt; exampleClass = classLoader.defineClassPublic(classNameFull, code, 0, code.length); Constructor&lt;?&gt; constructor = exampleClass.getConstructor(SerializeBeanInfo.class); Object instance = constructor.newInstance(beanInfo); return (JavaBeanSerializer) instance;&#125; 到这里为止，我们的分析就可以结束了，实际上这里是根据fieldInfo，通过CodeGen技术生成一个writer实例。而getJson被简单当作了json属性的getter，所以在writer.write(object)中调用了getJson从而出现了递归。那么这个问题的简单解决办法就是将getJson换个名字，比如toJson。最后，在github的issue中也翻到了一个对应的问题，作者给出的答案就是换个名字。]]></content>
      <categories>
        <category>Debug 日志</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++ 调用约定]]></title>
    <url>%2F2017%2F05%2F07%2FC-C-%E8%B0%83%E7%94%A8%E7%BA%A6%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[__cdecl 是 C declaration 的缩写，表示 C 语言默认的函数调用方法： 所有参数从右到左依次入栈， 参数由调用者清除，称为手动清栈 被调用函数不会要求调用者传递多少参数，调用者传递过多或者过少的参数，甚至完全不同的参数都不会产生编译阶段的错误。 __stdcall 是 Standard Call 的缩写，是 C++ 的标准调用方式： 所有参数从右到左依次入栈，如果是调用类成员的话，最后一个入栈的是 this 指针。 这些堆栈中的参数由被调用的函数在返回后清除，使用的指令是 retn X，X 表示参数占用的字节数，CPU 在 ret 之后自动弹出 X 个字节的堆栈空间，称为自动清栈。 函数在编译的时候就必须确定参数个数，并且调用者必须严格的控制参数的生成，不能多，不能少，否则返回后会出错。 __pascal 是 Pascal 语言（Delphi）的函数调用方式，也可以在 C/C++ 中使用，参数压栈顺序与前两者相反。返回时的清栈方式与 __stdcall 相同。 __fastcall 是编译器指定的快速调用方式。由于大多数的函数参数个数很少，使用堆栈传递比较费时。因此 __fastcall 通常规定将前两个（或若干个）参数由寄存器传递，其余参数还是通过堆栈传递。不同编译器编译的程序规定的寄存器不同，返回方式和 __stdcall 相当。 __thiscall 是为了解决类成员调用中 this 指针传递而规定的。__thiscall 要求把 this 指针放在特定寄存器中，该寄存器由编译器决定。VC 使用 ecx，Borland 的 C++ 编译器使用 eax。返回方式和 __stdcall 相当。 __fastcall 和 __thiscall 涉及的寄存器由编译器决定，因此不能用作跨编译器的接口。所以 Windows 上的 COM 对象接口都定义为 __stdcall 调用方式。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SIMD 与编程]]></title>
    <url>%2F2017%2F05%2F07%2FSIMD-%E4%B8%8E%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[SIMD 简介在谈 SIMD 之前，不得不谈一谈计算机体系结构的分类。常见的体系结构分类方法有两种：冯氏分类法和 Flynn 分类法。 冯氏分类法使用系统的最大并行度对计算机进行分类。最大并行度的定义是：计算机系统在单位时间内能够处理的最大的二进制位数。 Flynn 分类法则是按照指令流和数据流的多倍性进行分类。在 Flynn 中有定义： 指令流（instruction stream），即计算机执行的指令序列 数据流（data stream），即由指令流调用的数据序列 多倍性（multiplicity），即在系统受限的部件上，同时处于同一执行阶段的指令或数据的最大数目 Flynn 把计算机系统结构分为4类： 单指令流单数据流（single instruction stream single data stream, SISD) 单指令流多数据流（single instruction stream multiple data stream, SIMD) 多指令流单数据流（multiple instruction stream single data stream, MISD) 多指令流多数据流（multiple instruction stream multiple data stream, MIMD) 其中 SIMD 就是今天的主角：单指令流多数据流是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。在微处理器中，单指令流多数据流技术则是一个控制器控制多个平行的处理微元。 SIMD 技术的关键是在一条单独的指令中同时执行多个运算操作，以增加处理器的吞吐量。为此，SIMD 结构的 CPU 有多个执行部件，但都在同一个指令部件的控制之下，中央控制器向各个处理单元发送指令，整个系统只要求有一个中央控制器，只要求存储一份程序，所有的计算都是同步的。 为了了解 SIMD 在性能上的优势，我们以加法指令为例进行说明：单指令流单数据流型 CPU 对加法指令译码后，执行部件先访问主存，取得第一个操作数，之后再一次访问主存，取得第二个操作数，随后才能进行求和运算；而在 SIMD 型 CPU 中，指令译码后，几个执行部件同时访问主存，一次性获得所有操作数进行运算。这一特点使得 SIMD 技术特别适合于多媒体应用等数据密集型运算，比如可以在 libx264、ffmpeg 等中看到其身影。 SIMD 在现代处理器上的应用SIMD 在现代处理器上得到了广泛的应用，其中 Intel 开发了 MMX、SSE、SSE2 等等，AMD 开发了 3D Now! ，而 neon 则是 ARM 在 Cortex-A 系列机上的 SIMD 支持。 MMXMMX 是 Intel 于1996年在奔腾上设计开发的 SIMD 支持，通过一次处理多个数据，增强了多媒体处理方面的能力。然而 MMX 占用浮点数寄存器进行运算，使得 MMX 指令和浮点操作指令不能同时运行，必须做密集的切换。 MMX 寄存器，称作 MM0-MM7，实际上就是处理器内部 80 比特字长的浮点寄存器栈 st（0）到 st (7)的尾数部分（64 比特长）的复用。由于浮点栈寄存器的高16位未被 MMX 技术使用，因此这 16 位都置为 1，因此从栈寄存器的角度看，其浮点值为 NaN 或 Infinities，这可用于区分寄存器是处于浮点栈状态还是 MMX 状态。利用了装配数据类型（packed data type）的概念，每个 MMX 寄存器的 64 比特字长可以看作是 2 个 32 位整数、或者 4 个 16 位整数、或者 8 个 8 位整数，从而可以执行整数 SIMD 运算。 SSE1999年，Intel在其Pentium III微处理器中集成了 SSE（Streaming SIMD Extensions）技术，有效增强了 CPU 浮点运算的能力。SSE兼容MMX指令，可以通过 SIMD 和单时钟周期并行处理多个浮点数据来有效提高浮点运算速度。具有 SSE 指令集支持的处理器有 8 个 128 位的寄存器，每一个寄存器可以存放 4 个单精度（32位）浮点数。SSE同时提供了一个指令集，其中的指令允许把浮点数加载到这些 128 位寄存器中，这些数就可以在这些寄存器中进行算术逻辑运算，然后把结果送回主存。也就是说，SSE 中的所有计算都可以针对 4 个浮点数一次性完成。 在 SSE 之后，Intel 对 SSE 进行了拓展。时至今日已经发展到了AVX（Advanced Vector Extensions）。 3D Now!3DNow!（据称是“3D No Waiting!”的缩写）是由AMD开发的一套SIMD多媒体指令集，支持单精度浮点数的矢量运算，用于增强x86架构的计算机在三维图像处理上的性能 NEONARM CPU 最开始只有普通的寄存器，可以进行基本数据类型的基本运算。自 ARMv5 开始引入了 VFP（Vector Floating Point）指令，该指令用于向量化加速浮点运算。自ARMv7开始正式引入 NEON 指令，NEON 性能远超 VFP，因此 VFP 指令被废弃。 SIMD 与编程1TODO: 自己都还没学会 入门可以参考在C/C++代码中使用SSE等指令集的指令(1)介绍 简单应用可以参考YUV视频格式到RGB32格式转换的速度优化 中篇 在 Intel 上与 SIMD 相关可以参考Intel Intrinsics Guide。 源码阅读可以参考DirectXMath。 References[1] 计算机系统结构 高等教育出版社 王志英[2] 单指令多数据流 - wiki[3] SIMD 技术 - 上海交通大学[4] Neon ARM架构处理器扩展结构 - 百度百科[5] MMX - wiki[6] SSE - wiki[7] 3DNow! - wiki]]></content>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浮点数]]></title>
    <url>%2F2017%2F05%2F07%2F%E6%B5%AE%E7%82%B9%E6%95%B0%2F</url>
    <content type="text"><![CDATA[在计算机科学中，浮点是一种对实数近似值的表现方法，有一个尾数（即小数）加上阶码（即指数）来表示，通常是乘以某个基数的指数次。使用这种办法表示的数值成为浮点数。计算机中一般采用二进制为基，加上固定的精度来表示浮点。 \begin{equation} f = \pm m \times b^{ \pm e } \end{equation} 此外，浮点数表示法通常还包括一些特别的数值：+∞ 和 −∞（正负无穷大）以及 NaN（Not a Number）。无穷大用于数太大而无法表示的时候，NaN 则指示非法操作或者无法定义的结果。其中，无穷大，可表示为inf，在内存中的值是阶码为全1，尾数全0。而NaN在内存中的值则是阶码全1，尾数不全0。 通常情况下，在电脑中使用的浮点规范为 IEEE 754。 IEEE 754 IEEE二进制浮点数算术标准（IEEE 754）是20世纪80年代以来最广泛使用的浮点数运算标准，为许多CPU与浮点运算器所采用。该标准的全称为IEEE二进制浮点数算术标准（ANSI/IEEE Std 754-1985），又称IEC 60559:1989，微处理器系统的二进制浮点数算术（本来的编号是IEC 559:1989）[1]。后来还有“与基数无关的浮点数”的“IEEE 854-1987标准”，有规定基数为2跟10的状况。现在最新标准是“ISO/IEC/IEEE FDIS 60559:2010”。 标准主要定义了下面的内容： 浮点数的格式 反常值（denormal number） 一些特殊数值（无穷（Inf）与非数值（NaN）） 以及这些数值的“浮点数运算符” 四种数值舍入规则 五种例外情况 同时，标准还规定了四种浮点数的表示方式：单精确度（32位）、双精确度（64位）、延伸单精确度（43比特以上，很少使用）与延伸双精确度（79比特以上，通常以80比特实做）。 存储格式IEEE 754 规定二进制了浮点数的存储格式： 1234+----------------------------+| sign | exponent | fraction |+----------------------------+e+f+1 e+f f 0 其中最高位为符号位，紧接着的 e 个 bit 存储指数部分，剩 f 个 bit 则表示小数部分。 需要注意的是 IEEE 754 的指数部分有一个指数偏移值，标准规定该值为：$ 2^{e - 1}-1 $。 指数偏移值（exponent bias），是指浮点数表示法中的指数域的编码值为指数的实际值加上某个固定的值。 以单精度为例，指数部分长度为 8 ，如果编码值为 128，那么实际值应该为 128 - 127 = 1 采用指数的实际值加上固定的偏移值的办法表示浮点数的指数，好处是可以用长度为e个比特的无符号整数来表示所有的指数取值，这使得两个浮点数的指数大小的比较更为容易，实际上可以按照字典序比较两个浮点表示的大小。这种移码表示的指数部分，中文称作阶码。如果不能理解，可以参考一张图看懂原码、反码、补码、移码。 浮点数的“规约”浮点数中存在多种表示为相同值的情况，比如: \begin{equation} 0.1 \times 10^2 = 0.01 \times 10^3 \end{equation} 为了统一，将指数部分的编码值在 $ 0 &lt; exponent &lt; 2^{e}-2 $ 之间，且尾数部分最高有效位（即整数字）是1的浮点数将被称为规约形式的浮点数。“规约”是指用唯一确定的浮点形式去表示一个值。 因为最高位始终为1，所以实际编码中可以省略，称为隐含的二进制有效数字，而 IEEE 754 称这种编码方式的尾数为有效数（significant）。 显然，有规约形式就有非规约形式，但是并非所以不是规约形式的浮点数都叫做非规约形式哦。非规约形式的浮点数（Denormalized Number）：规格浮点约定小数点前一位默认是1，而非规格浮点约定小数点前一位可以为0，这样小数精度就相当于多了最多2^22范围。可以看到，非规约形式的浮点数实际上也是“规约”的。IEEE 754 标准规定：非规约形式的浮点数的指数偏移值比规约形式的浮点数的指数偏移值大1。实际上非规约形式的浮点数比规约形式的浮点数更接近与 0 。如果不能理解为甚么有“规约”的非规约形式浮点数，可以参考你应该知道的浮点数基础知识。 浮点数比较通过规约化形式和指数偏移，浮点数基本上可以按照符号位、指数域、尾数域的顺序作字典比较。显然，所有正数大于负数；正负号相同时，指数的二进制表示法更大的其浮点数值更大；指数相同则比较尾数部分的大小。 这里有三个特殊值需要指出： 如果指数是0并且尾数的小数部分是0，这个数 ±0（和符号位相关） 如果指数 $ 2^{e}-1 $ 并且尾数的小数部分是0，这个数是 ±∞（同样和符号位相关） 如果指数 $ 2^{e}-1 $ 并且尾数的小数部分非0，这个数表示为不是一个数（NaN） 此时有： -Inf &lt; 负的规约浮点数数 &lt; 负的非规约浮点数 &lt; -0.0 = 0.0 &lt; 正的非规约浮点数 &lt; 正的规约浮点数 &lt; Inf -inf = -inf, inf = inf, NaN 与任何浮点数（包括自身）的比较结果都为假，即 (NaN ≠ x) = false. 编程语言中的浮点数如果 ISO C 有预定义 __STDC_IEC_559__ 时支持 IEC 60559:1989 (IEEE 754) 指定的浮点数，C++下则是浮点类型对应 numeric_limits 的 is_iec559 为 true 时。此时 float 和 double 浮点型分别对应的是单精度和双精度浮点数。 references[1] 浮点数 - wiki[2] IEEE 754 - wiki]]></content>
  </entry>
  <entry>
    <title><![CDATA[C语言格式化输出]]></title>
    <url>%2F2017%2F05%2F03%2FC%E8%AF%AD%E8%A8%80%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[介绍格式化输出函数会根据参数 format 字符串来转换并格式化数据，然后输出。其中字符串由多个指令组成。指令有以下两种： 非 % 字符，将会被原封不动的拷贝到输出流 由 % 字符开头的转换说明符号，每个都会从后面取出若干个参数，按照相应的转换规则（如果适用）转换并将结果写入输出流 一般而言，每个 % 符号在其后都必需有一个参数与之相呼应（只有当 %% 转换字符出现时会直接输出 % 字符），而欲输出的数据类型必须与其相对应的转换字符类型相同。 组成规则格式化说明符的组成规则如下： 1&apos;%&apos; [flags]zero-or-more [field-width]opt [precision]opt [length-modifier]opt conversition-specifier flags: 任意个数，用来修改转换说明符的行为 field-width: 可选，如果转换后的值的字符数少于字段宽度，则在左侧用空格填充剩余字段（默认情况下为左）。字段宽度采用星号*（稍后描述）或非负十进制整数的表示。 precision: 可选，参考 precision length-modifer: 可选，用于指定输入参数的长度 conversition-specifier: 字符，说明用什么转换类型来转换参数 flagsflag 字符可以按照任意的次序写，所有的 flag 字符和它们的含义如下： - 返回的结果为左对齐，默认情况为右对齐 + 有符号的转换结果前始终包括加号或者减号（默认情况下只有负数前才会显示一个符号） space 如果有符号的转换的结果第一个字符不是符号，或者如果有符号的转换结果没有字符，都会在前面加上一个空格。如果空格和 + 两个 flag 都出现，则忽略空格。 # 将结果转换为“替代形式”。对于 o 转换，当且仅当必要时，它会提高精度，以将结果的第一位数强制设为零（如果值和精度均为 0 ，则打印单个 0 ）。对于x（或 X ）转换，非零结果前将加上 0x（或 0X）前缀。 对于 a，e，E，f，F，g 和 G 转换，转换的结果总是包含一个小数点字符，即使小数点后没有数字（正常情况下只有后面有数字是才会出现小数点）。对于 g 和 G 转换，尾随零并不会从结果中移除。对于其他转换，行为是未定义的。 0 对于 d，i，o，u，x，x，a，A，e，E，f，F，g 和 G 转换，除非转换无效或者 NaN，使用前导零填充剩余宽度字符（在 +- 和 0x 的基础上）。如果同时出现 0 和 -，则 0 被忽略。对于其他转换，行为是未定义的。 precision(精度)precision 有几种情况： 给出 d，i，o，u，x 和 X 转换所显示的最小位数 给出 a，e，E，f 和 F 转换的小数点后出现的位数 g 和 G 格式代表有效位数的最大值 在 %s 格式代表字符串的最大长度 Notice: 如果精度和非上述类型说明符(conversition specifier)一起使用，行为是未定义的。 精度由 . (period) 开头，比如 .3d，后面加上 * 号或可选的十进制整数(如果仅仅只有一个.，那么精度为0)。 如上所述，字段宽度(field-width)或精度(precision)两者都可以用星号表示。在这种情况下，表示用一个 int 类型的参数提供字段的宽度或精度。指定字段宽度或精度或两者的参数将在要转换的参数（如果有的话）之前出现（按顺序）。 如果字段宽度为负数，相当于一个 - flag 加上正的字段宽度；如果精度为负数，那么会被忽略。 length modifierhh 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 signed char 或者 unsigned char 参数（参数已经通过整数提升提升了，但是它的值仍然应该被转换为对应的类型）；如果紧跟 n 说明符则表示参数应该是指向 signed char 类型的指针。 h 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 short int 或者 unsigned short int 参数（参数已经通过整数提升提升了，但是它的值仍然应该被转换为对应的类型）；如果紧跟 n 说明符则表示参数应该是指向 short int 类型的指针。 l(ell) 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 long int 或者 unsigned long int 参数；如果紧跟 n 说明符则表示参数应该是指向 long int 类型的指针；如果紧跟着 c 说明符则表示 wint_t 参数；如果紧跟着 s 则表示参数为 wchar_t 类型的指针；对于 a, A, e, E, f, F, g 和 G 则没有任何影响。 ll(ell-ell) 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 long long int 或者 unsigned long long int 参数；如果紧跟 n 说明符则表示参数应该是指向 long long int 类型的指针。 j 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 intmax_t 或者 uintmax_t 参数；如果紧跟 n 说明符则表示参数应该是指向 intmax_t 类型的指针。 z 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 size_t 或者相应的有符号整形参数；如果紧跟 n 说明符则表示转换规范适用于对应于 size_t 参数的带符号整数类型的指针。 t 表示紧跟着的 d, i, o, u, x 或者 X 转换说明符将被应用到 ptrdiff_t 或者相应的无符号整形参数；如果紧跟 n 说明符则表示参数应该是指向 ptrdiff_t 类型的指针。 L 表示紧跟着的 a, A, e, E, f, F, g 或者 G 转换说明符将被应用到 long double 类型的参数上。 conversition-specifier整数 %d,i 整数的参数会被转成有符号的十进制数字。 %u 整数的参数会被转成无符号的十进制数字。 %o 整数的参数会被转成无符号的八进制数字。 %x,X 整数的参数会被转成无符号的十六进制数字，并以小写abcdef 表示，对于 X 以大写ABCDEF 表示浮点型数（下同，不在赘述）。 %f,F double 型的参数会被转成十进制数字 [-]ddd.ddd，并取到小数点以下六位，四舍五入。如果为无穷(inﬁnity)则按照具体实现输出 [-]inf 或者 infinity；如果为 NaN 则输出 [-]nan 或者 [-]nan(any n-char-sequence)。 %e,E double 型的参数以指数形式打印，有一个数字会在小数点前，六位数字在小数点后，而在指数部分会以小写的 e 来表示[-]d.ddde+/-dd。如果参数表示无穷(inﬁnity)或者 NaN 则类似于 f 或 F。 %g,G double 型的参数会自动选择以 %f 或 %e 的格式来打印，其标准是根据打印的数值及所设置的有效位数来决定。 %a, A 浮点数、十六进制数字和p-记数法。把一个浮点数以一个十六进制的数如0x1.C0000p+1类似的样子输出一个浮点数。 字符及字符串 %c 整型数的参数会被转成 unsigned char 型打印出 %s 指向字符串的参数会被逐字输出，直到出现 &#39;\0&#39; 字符为止 %p 如果是参数是 void * 型指针则使用十六进制格式显示 others最后，标准规定： The number of characters that can be produced by any single conversion shall be at least 4095. references[1] ISO/IEC 9899:201x Committee Draft — December 2, 2010 N1548]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用Linux工具整理]]></title>
    <url>%2F2017%2F05%2F03%2F%E5%B8%B8%E7%94%A8Linux%E5%B7%A5%E5%85%B7%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[记录本人常用Linux命令 CClocCloc是一款使用Perl语言开发的开源代码统计工具，支持多平台使用、多语言识别，能够计算指定目标文件或文件夹中的文件数（files）、空白行数（blank）、注释行数（comment）和代码行数（code）。 Cloc具备很多特性以致于让它更方便于使用、完善、拓展和便携。 作为一个单一的独立形式存在的文件，Cloc只需要下载相应文件并运行这样最少的安装工作即可。 能够从源码文件中识别编程语言注释定义； 允许通过语言和项目来分开统计计算； 能够以纯文本、SQL、XML、YAML、逗号分隔等多样化的格式生成统计结果； 能够统计诸如tar、Zip等格式的压缩文件中的代码数； 有许多排除式的指令； 能够使用空格或者不常用的字符处理文件名和目录名； 不需要依赖外部标准的Perl语言配置； 支持多平台使用。 1Usage: cloc [options] &lt;file(s)/dir(s)&gt; | &lt;set 1&gt; &lt;set 2&gt; | &lt;report files&gt; Usage// TODO: GGDB开始和停止quit: 退出GDBrun: 运行程序（在此给出命令行参数）kill: 停止程序 断点break sum: 在函数 sum 入口设置断点break *0x8048394: 在地址 0x8048394 处设置断点delete 1: 删除断点1delete: 删除所有断点 执行stepi: 执行一条指令stepi 4: 执行四条指令nexti: 类似stepi，但是以函数调用为单位continue: 继续执行finish: 运行到当前函数返回 检查代码disas: 反汇编当前函数disas sum: 反汇编函数sumdisas 0x000001: 反汇编位于地址 0x000001 附近的函数disas 0x000000 0x000001: 反汇编指定范围的代码print /x $eip: 以十六进制输出程序计数器的内容 检查数据print $eax: 以十进制数出 $eax 的内容print /x $eax: 以十六进制输出print /t $eax: 以二进制输出print sum: 输出sum的值print *(int*)sum: 输出sum指向int的值x/20b sum: 检查函数sum的前20个字节x/2w 0xfff076b0: 检查0xfff076b0开始的4字节 有用的信息info frame: 有关与当前栈帧的信息info registers: 所有寄存器的值help: 显示GDB的帮助信息 OObjdumpinfoDisplay infomation from object files. 123456#include &lt;stdio.h&gt;int main(void) &#123; printf(&quot;hello world&quot;); return 0;&#125; 使用gcc hello.c生成hello.o文件，下面使用hello.o作为源文件使用objdump。 usage-f, --file-headers 显示整个文件头部的内容 123456/mnt/d/tmp$ objdump -f hello.ohello.o: file format elf64-x86-64architecture: i386:x86-64, flags 0x00000011:HAS_RELOC, HAS_SYMSstart address 0x0000000000000000 -h, --[section]-headers 显示文件的section头信息 1234567891011121314151617181920/mnt/d/tmp$ objdump -h hello.ohello.o: file format elf64-x86-64Sections:Idx Name Size VMA LMA File off Algn 0 .text 0000001a 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 0000000000000000 0000000000000000 0000005a 2**0 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000000 0000000000000000 0000000000000000 0000005a 2**0 ALLOC 3 .rodata 0000000c 0000000000000000 0000000000000000 0000005a 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 00000035 0000000000000000 0000000000000000 00000066 2**0 CONTENTS, READONLY 5 .note.GNU-stack 00000000 0000000000000000 0000000000000000 0000009b 2**0 CONTENTS, READONLY 6 .eh_frame 00000038 0000000000000000 0000000000000000 000000a0 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA Idx 是编号，Name 是节点名称，Size 是节大小，VMA 是在虚拟内存中的起点，LMA 是节的装载地址（除了ROM之外，通常与 VMA 相同），File off 是在文件中的具体偏移，Algn 是对齐地址。各节第二行描述了节的属性。CONTENTS 表示节在文件中占用了内存空间，ALLOC 则表示需要分配内存，RELOC 表示需要重定位。 -d, --disassemble 显示可执行section的反汇编代码 12345678910111213141516/mnt/d/tmp$ objdump --disassemble hello.ohello.o: file format elf64-x86-64Disassembly of section .text:0000000000000000 &lt;main&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: bf 00 00 00 00 mov $0x0,%edi 9: b8 00 00 00 00 mov $0x0,%eax e: e8 00 00 00 00 callq 13 &lt;main+0x13&gt; 13: b8 00 00 00 00 mov $0x0,%eax 18: 5d pop %rbp 19: c3 retq -D, --disassemble-all 显示所有section的反汇编 NOTICE: 反汇编过程中使用 -M 可以设置反汇编格式： 123456789101112131415161718(multiple options should be separated by commas): x86-64 Disassemble in 64bit mode i386 Disassemble in 32bit mode i8086 Disassemble in 16bit mode att Display instruction in AT&amp;T syntax intel Display instruction in Intel syntax att-mnemonic Display instruction in AT&amp;T mnemonic intel-mnemonic Display instruction in Intel mnemonic addr64 Assume 64bit address size addr32 Assume 32bit address size addr16 Assume 16bit address size data32 Assume 32bit data size data16 Assume 16bit data size suffix Always display instruction suffix in AT&amp;T syntax amd64 Display instruction in AMD64 ISA intel64 Display instruction in Intel64 ISA 比如要显示 Intel 格式的汇编代码： 12345678910111213141516/mnt/d/tmp$ objdump --disassemble -M intel hello.ohello.o: file format elf64-x86-64Disassembly of section .text:0000000000000000 &lt;main&gt;: 0: 55 push rbp 1: 48 89 e5 mov rbp,rsp 4: bf 00 00 00 00 mov edi,0x0 9: b8 00 00 00 00 mov eax,0x0 e: e8 00 00 00 00 call 13 &lt;main+0x13&gt; 13: b8 00 00 00 00 mov eax,0x0 18: 5d pop rbp 19: c3 ret -t, --syms 显示符号表内容 123456789101112131415/mnt/d/tmp$ objdump -t hello.ohello.o: file format elf64-x86-64SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 hello.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 g F .text 000000000000001a main0000000000000000 *UND* 0000000000000000 printf 各列分别是界内偏移，标记位，所在节，对齐方式和符号名。*ABS* 表示这是一个不和任何节相关的绝对符号，*UND*则这个符号不在本文件中定义，*COM* 表示还未分配位置的未初始化数据目标。 -T, --dynamic-syms 显示文件的动态符号表入口,仅仅对动态目标文件有意义，比如共享库。 -r, --reloc 显示重定位入口 12345678910111213:/mnt/d/tmp$ objdump -r hello.ohello.o: file format elf64-x86-64RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE0000000000000005 R_X86_64_32 .rodata000000000000000f R_X86_64_PC32 printf-0x0000000000000004RELOCATION RECORDS FOR [.eh_frame]:OFFSET TYPE VALUE0000000000000020 R_X86_64_PC32 .text 分别表示 text 和 eh_frame 节的重定位表。所谓重定位表是指代码中需要回填地址的表，链接器重定位算法大概如下： 123456789101112foreach section s &#123; foreach relocation entry r &#123; refptr = s + r.offset; if (r.type == XXXX_PC32) &#123; refaddr = ADDR(s) + r.offset; *refptr = ADDR(r.symbol) + *refptr - refaddr; &#125; if (r.type == XXXX_32) &#123; *refptr = ADDR(r.symbol) + *refptr; &#125; &#125;&#125; 如果配合d D使用,则以反汇编以后的格式显示: 123456789101112131415161718/mnt/d/tmp$ objdump -rd hello.ohello.o: file format elf64-x86-64Disassembly of section .text:0000000000000000 &lt;main&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: bf 00 00 00 00 mov $0x0,%edi 5: R_X86_64_32 .rodata 9: b8 00 00 00 00 mov $0x0,%eax e: e8 00 00 00 00 callq 13 &lt;main+0x13&gt; f: R_X86_64_PC32 printf-0x4 13: b8 00 00 00 00 mov $0x0,%eax 18: 5d pop %rbp 19: c3 retq -R, --dynamic-reloc 显示动态重定位入口，仅仅对动态文件起作用。 Ttime来自: Linux Man 手册time命令用于统计给定命令所花费的总时间。 语法1time 参数 参数指令：指定需要运行的额指令及其参数。实例 当测试一个程序或比较不同算法时，执行时间是非常重要的，一个好的算法应该是用时最短的。所有类UNIX系统都包含time命令，使用这个命令可以统计时间消耗。例如： 123456[root@localhost ~]# time ls anaconda-ks.cfg install.log install.log.syslog satools text real 0m0.009s user 0m0.002s sys 0m0.007s 输出的信息分别显示了该命令所花费的real时间、user时间和sys时间。 real时间是指挂钟时间，也就是命令开始执行到结束的时间。这个短时间包括其他进程所占用的时间片，和进程被阻塞时所花费的时间。 user时间是指进程花费在用户模式中的CPU时间，这是唯一真正用于执行进程所花费的时间，其他进程和花费阻塞状态中的时间没有计算在内。 sys时间是指花费在内核模式中的CPU时间，代表在内核中执系统调用所花费的时间，这也是真正由进程使用的CPU时间。 shell内建也有一个time命令，当运行time时候是调用的系统内建命令，应为系统内建的功能有限，所以需要时间其他功能需要使用time命令可执行二进制文件/usr/bin/time。 使用-o选项将执行时间写入到文件中： 1/usr/bin/time -o outfile.txt ls 使用-a选项追加信息： 1/usr/bin/time -a -o outfile.txt ls 使用-f选项格式化时间输出： 1/usr/bin/time -f &quot;time: %U&quot; ls -f选项后的参数：参数 描述%E real时间，显示格式为[小时:]分钟:秒%U user时间。%S sys时间。%C 进行计时的命令名称和命令行参数。%D 进程非共享数据区域，以KB为单位。%x 命令退出状态。%k 进程接收到的信号数量。%w 进程被交换出主存的次数。%Z 系统的页面大小，这是一个系统常量，不用系统中常量值也不同。%P 进程所获取的CPU时间百分百，这个值等于user+system时间除以总共的运行时间。%K 进程的平均总内存使用量（data+stack+text），单位是KB。%w 进程主动进行上下文切换的次数，例如等待I/O操作完成。%c 进程被迫进行上下文切换的次数（由于时间片到期）。 系统Ubuntu软件安装APT 安装普通安装：apt install softname1 softname2 ...修复安装: apt -f install softname1 softname2 ...重新安装: apt --reinstall install .... DPKG 安装dpkg -i package_name.deb 源码安装通过tar解压，然后configure后make install tar: tar method filename .tar.gz, .tar.Z, .tgz: zxf.tar: xf .bz2: bunzip xx.bz2 卸载APT方式移除式卸载：apt-get remove softname1 softname2 …;（移除软件包，当包尾部有+时，意为安装） 清除式卸载 ：apt-get --purge remove softname1 softname2...;(同时清除配置) 清除式卸载：apt-get purge sofname1 softname2...;(同上，也清除配置文件) Dpkg方式移除式卸载：dpkg -r pkg1 pkg2 ...; 清除式卸载：dpkg -P pkg1 pkg2...;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 32 Longest Valid Parenthess]]></title>
    <url>%2F2017%2F03%2F13%2FLeetCode-32-Longest-Valid-Parenthess%2F</url>
    <content type="text"><![CDATA[problemLongest Valid Parenthess solution((())))())())(()())，如果把这个中所有符合条件的找出来： 1((())) ) () ) (()()) 此时发现单独出现的 ) 是作为分隔符出现的。只要统计 ) 出现的次数就可以得到解。 code12345678910111213141516171819202122232425262728class Solution &#123;public: int longestValidParentheses(string s) &#123; int n = s.length(), longest = 0; stack&lt;int&gt; st; for (int i = 0; i &lt; n; i++) &#123; if (s[i] == &apos;(&apos;) st.push(i); else &#123; if (!st.empty()) &#123; if (s[st.top()] == &apos;(&apos;) st.pop(); else st.push(i); &#125; else st.push(i); &#125; &#125; if (st.empty()) longest = n; else &#123; int a = n, b = 0; while (!st.empty()) &#123; b = st.top(); st.pop(); longest = max(longest, a-b-1); a = b; &#125; longest = max(longest, a); &#125; return longest; &#125;&#125;;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Modern C++ - Type deduction]]></title>
    <url>%2F2017%2F03%2F12%2FEffective-Modern-C-Type-deduction%2F</url>
    <content type="text"><![CDATA[模板类型推导12template&lt;class Type&gt;void f(ParamType p); 如上述代码，对于模板有两种类型需要推导。而具体推导细节有三种方案： ParamType 为引用，但非 universal reference； ParamType 为 universal reference； ParamType 非引用 一对于第一种情况，推导方式如下： 参数如果为引用，那么忽略； 剩下部分与 ParamType 做匹配得出 Type 类型 二第二种情况涉及到引用折叠。 如果参数为左值引用，那么 Type 和 ParamType 类型为左值引用； 如果参数为右值引用，那么应用方案一的情况 三这种情况下，参数默认以 “pass by value” 的方式传递： 如果参数为引用，忽略引用部分； 忽略后以值拷贝规则匹配 Type 类型； autoauto 类型推导和模板类型推导的唯一区别是关于处理 braced initializer 的区别： auto 认为 braced initializer 表示为 std::initialzier 列表 同时，在 C++ 14 中，auto 还可以用于推导返回值类型，此时规则等同于模板类型推导。 decltype不同于 auto，decltype 返回表达式的具体类型。decltype 的更多用于推导与参数类型相关的返回类型： 1auto f(int a) -&gt; decltype(a) &#123;&#125; 因为 C++ 14 中可以使用 auto 推导返回值类型，而 auto 推导规则限定不太灵活。此时提供了 decltype(auto) 来完美推导返回值类型（decltype(auto) 也可以用于定义变量）。 C++ 中规定 (x) 返回的是左值引用，所以 decltype(x) 和 decltype((x)) 是不同的类型。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 28 Implement strStr()]]></title>
    <url>%2F2017%2F03%2F12%2FLeetCode-28-Implement-strStr%2F</url>
    <content type="text"><![CDATA[problemImplement strStr solution这道题很明显使用 mp 算法进行字符串匹配。 MP 算法假设原字符串：abbaabbaaba, 匹配字符串 abbaaba。现在我们要从原字符串中找到第一个满足匹配字符串的位置。一般的算法是匹配失败后从新开始匹配： 1234567abbaabbaaba匹配过程：abbaab|x x x ax ab|baaba 这种办法效率并不高，并不能利用我们已经知道的信息。观察有两个竖线分割开的部分，两部分左边有相同部分，如何把这部分信息利用起来就是 MP 算法的工作。 这里已经知道了匹配过程中失败了我们可以使用前缀信息来跳过部分无用匹配。现在将匹配字符串 abbaaba 的前缀展开： 12345671 a2 ab3 abb4 abba5 abbaa6 abbaab7 abbaaba 可以发现： 与 4 后缀匹配的最长前缀是 1 与 4 后缀匹配的最长前缀是 1 与 6 后缀匹配的最长前缀是 2 与 7 后缀匹配的最长前缀是 1 如何计算呢？假设 prefix[i] 表示i匹配的最长前缀是第几个，那么有： 对于 i=1 时，没有任何前缀； 当 i&gt;1 时，等于i-1的最长前缀的下一个字符和当前字符进行判断的结果 为了方便将定义改为 fail[i+1] 表示i匹配的最长前缀的下一个字符所在位置，所以计算fail的代码如下： 123456789vector&lt;int&gt; getNext(string &amp;str) &#123; vector&lt;int&gt; failed(str.size()+1, 0); for (int i = 1; i &lt; str.size(); ++i) &#123; int j = failed[i]; while (j &amp;&amp; str[j] != str[i]) j = failed[j]; failed[i+1] = str[j] == str[i] ? j+1 : 0; &#125; return failed;&#125; 如果匹配失败了，我们还可以继续以前缀的最长前缀继续寻找知道没有任何匹配前缀。 有了前缀后，就可以使用fail计算最长匹配。 code12345678910111213141516171819202122232425class Solution &#123;public: int strStr(string haystack, string needle) &#123; if (needle.empty()) return 0; vector&lt;int&gt; failed = getNext(needle); int j = 0; for (int i = 0; i &lt; haystack.size(); ++i) &#123; while (j &amp;&amp; haystack[i] != needle[j]) j = failed[j]; if (haystack[i] == needle[j]) j++; if (j == needle.size()) return i-j+1; &#125; return -1; &#125; vector&lt;int&gt; getNext(string &amp;str) &#123; vector&lt;int&gt; failed(str.size()+5, 0); for (int i = 1; i &lt; str.size(); ++i) &#123; int j = failed[i]; while (j &amp;&amp; str[j] != str[i]) j = failed[j]; failed[i+1] = str[j] == str[i] ? j+1 : 0; &#125; return failed; &#125;&#125;;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 15-3 Sum]]></title>
    <url>%2F2017%2F03%2F08%2FLeetCode-15-3-Sum%2F</url>
    <content type="text"><![CDATA[problem3 Sum solution最简单的办法是 n^3。如果我们对数组排序，使用 n^2 生成和，logn 查找，则可以降到 n^2 * logn。如果对 n^2进行查找呢？那么可以将匹配部分降低到 2nlogn。所以问题变成了求n^2内生成一个有序的n^2数组，不过这个问题也很困难。 123for (int i = 0; i &lt; length - 2; ++i) for (int j = i+1; j &lt; length - 1; ++j) cmp nums[i] + nums[j] 通过上面的代码发现虽然无法将整个 n^2 数组排序，但是对于每一层的i，生成的和一定是有序的。也就是说 nums[0] + nums[1] 一定小于 nums[0] + nums[2]，那么我们不需要对 n 的数组使用二分查找，只需从后向前遍历。对于每一层 i ，只需要对 N 的数组编译一次， 总共 n^2 次。所以目前的总效率为排序 nlogn 加上 n^2。 1234567891011121314for (int i = 0; i &lt; length - 2; ++i) &#123; int k = length - 1; for (int j = i + 1; j &lt; length - 1; ++j) &#123; int sum = nums[i] + nums[j]; while (sum + nums[k] &gt;= 0) &#123; if (sum + nums[k] == 0) &#123; // push i j k &#125; else &#123; k--; &#125; &#125; &#125;&#125; 上面是题解的大概逻辑。到这里我们可以发现等同于另外一种思路：对于 i ，存在 j 和 k，如果 sum = nums[i] + nums[j] + nums[k] 为 0 ，那么对于任意有 l,m (j &lt; l, m &lt; k)，至少要满足 nums[j] &lt; nums[l] &amp; nums[k] &gt; nums[m] 才能为 0 。所以上述方法也可以写成下面的代码： code12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; resultSet; if (nums.size() &lt; 3) return resultSet; std::sort(nums.begin(), nums.end()); int length = nums.size(); for (int i = 0; i &lt;= length - 3; ++i) &#123; int j = length - 1, k = i + 1; while (k &lt; j) &#123; int sum = nums[k] + nums[j] + nums[i]; if (sum == 0) &#123; resultSet.push_back(&#123;nums[i], nums[k], nums[j]&#125;); k++, j--; while (k &lt; j &amp;&amp; nums[k] == nums[k-1]) k++; while (k &lt; j &amp;&amp; nums[j] == nums[j+1]) j--; &#125; else if (sum &gt; 0) &#123; j--; &#125; else &#123; k++; &#125; &#125; while (i &lt;= length - 3 &amp;&amp; nums[i] == nums[i+1]) ++i; &#125; return resultSet; &#125;&#125;; 其中涉及到 i,j,k 的三个 while 主要用于避免重复。]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 11-Container With Most Water]]></title>
    <url>%2F2017%2F03%2F07%2FLeetCode-11-Container-With-Most-Water%2F</url>
    <content type="text"><![CDATA[problemContainer With Most Water solution这道题目直观的解法是每对线都比较一次，直到最大的： 123456789101112131415161718class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int m = 0; for (int i = 0; i &lt; height.size()-1; ++i) &#123; for (int j = 1; j &lt; height.size(); ++j) &#123; int value = (j-i) * min(height[i], height[j]); if (value &gt; m) m = value; &#125; &#125; return m; &#125; int min(int l, int r) &#123; return l &lt; r ? l : r; &#125;&#125;; 这样效率肯定不够高，会超时。 我们换一个角度来看，容积取决于最短的线。那么容积中最短的线，其与最远距离的乘积为容量。重复此操作就可以找到最大容积。所以问题就变成了求 a 到左边和右边最远的&gt;= a的点的距离。这个仍然不好求，换个角度来看，就是求a点出发，所有小于等于a的点的最大值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: struct Point &#123; int idx; int height; bool operator &lt; (const Point &amp;rhs) const &#123; return height &gt; rhs.height || (height == rhs.height &amp;&amp; idx &gt; rhs.idx); &#125; &#125;; void fill(priority_queue&lt;Point&gt; &amp;queue, const vector&lt;int&gt; &amp;height) &#123; for (size_t i = 0; i &lt; height.size(); ++i) &#123; queue.push(Point&#123;i, height[i]&#125;); &#125; &#125; int maxArea(vector&lt;int&gt;&amp; height) &#123; priority_queue&lt;Point&gt; left; fill(left, height); priority_queue&lt;Point&gt; right = left; int size = height.size(), result = 0; for (int i = 0; i &lt; size - 1; ++i) &#123; while (!left.empty()) &#123; Point point = left.top(); if (point.height &gt; height[i]) break; left.pop(); result = max(result, (point.idx - i) * point.height); &#125; &#125; for (int i = size - 1; i &gt; 0; --i) &#123; while (!right.empty()) &#123; Point point = right.top(); if (point.height &gt; height[i]) break; right.pop(); result = max(result, (i - point.idx) * point.height); &#125; &#125; return result; &#125;&#125;; 这样的算法肯定能够通过测试了。但是仍然不够快，为什么？因为我们这种办法求出了所有的点能组成的最大值，然而题目中只要求最大的。现在考虑一种情况，如果比a小的且离a最远的旁边还有值，那么意味着所有针对a的计算全是白费的（想想为什么）。 根据刚才的启示，在 a 和 b 的中间，除非有两个大于 a 和 b 的值，否则 a 与 b 最大（想想为什么）。不过话说回来，这么简单的思路为什么一开始想不到呢？ code1234567891011121314class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int water = 0; int i = 0, j = height.size() - 1; while (i &lt; j) &#123; int h = min(height[i], height[j]); water = max(water, (j - i) * h); while (height[i] &lt;= h &amp;&amp; i &lt; j) i++; while (height[j] &lt;= h &amp;&amp; i &lt; j) j--; &#125; return water; &#125;&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 10-Regular-Expression-Matching]]></title>
    <url>%2F2017%2F03%2F06%2FLeetCode-10-Regular-Expression%2F</url>
    <content type="text"><![CDATA[problemregular-expression-matching solution这道题目需要注意 zero or more 的处理。我的办法是开始不吃掉任何字符，直接判断；只讨论不能匹配的，此时吃掉一个字符后再行判断，直到所有字符判断完毕。 code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;public: struct Rule &#123; bool zeroOrMore; char ch; &#125;; bool isMatch(string s, string p) &#123; return normalRule(parseRexpr(p), s.data()); &#125; vector&lt;Rule&gt; parseRexpr(const string &amp;p) &#123; vector&lt;Rule&gt; rules; const char *s = p.data(); while (*s != &apos;\0&apos;) &#123; bool rep = false; char c = *s++; if (*s == &apos;*&apos;) &#123; rep = true; s++; &#125; rules.push_back((Rule)&#123;rep, c&#125;); &#125; return rules; &#125; bool normalRule(const vector&lt;Rule&gt; &amp;rules, const char *p) &#123; if (rules.empty() &amp;&amp; *p == &apos;\0&apos;) return true; for (vector&lt;Rule&gt;::const_iterator it = rules.begin(); it != rules.end(); it++) &#123; if (it-&gt;zeroOrMore) &#123; char ch = it-&gt;ch; return specialRule(vector&lt;Rule&gt;(++it, rules.end()), p, ch); &#125; else if (*p == &apos;\0&apos; || (it-&gt;ch != &apos;.&apos; &amp;&amp; it-&gt;ch != *p)) &#123; return false; &#125; else &#123; p++; &#125; &#125; return *p == &apos;\0&apos;; &#125; bool specialRule(vector&lt;Rule&gt; rules, const char *p, char ch) &#123; const char *tmp = p; while (*tmp == ch || (ch == &apos;.&apos; &amp;&amp; *tmp != &apos;\0&apos;)) &#123; if (normalRule(rules, tmp)) return true; tmp++; &#125; return normalRule(rules, tmp); &#125;&#125;;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective C++: Exception-safe code]]></title>
    <url>%2F2017%2F03%2F05%2FEffective-C-Exception-safe-code%2F</url>
    <content type="text"><![CDATA[异常安全异常安全的代码需要满足两个条件： 异常中立性 异常安全性 异常中立性是指任何底层的异常都能保持原样传递到外层调用代码。 而异常安全性也有两个条件： 不泄露任何资源 不允许数据破坏 只有满足上诉两个条件的函数才称为拥有异常安全性。 这里主要讨论异常安全性的保证。 不泄露任何资源解决资源泄露的问题比较容易，可以通过智能指针等对象管理资源来确保资源被正确释放。 不允许数据被破坏 基本承诺：如果异常被抛出，程序内的任何事物仍然保持在有效状态下。没有任何对象或数据机构会因此而被破坏，所有对象都处于一种内部前后一致的状态。 强烈保证：如果异常被抛出，程序状态不改变。调用这样的函数需要有这样的认知：如果函数成功，就是完全成功；如果函数失败，程序会回到“调用函数之前”的状态。 不抛出保证：保证绝对不抛出异常。对于所有对内建类型（例如，ints，指针，等等）的操作都是不抛出（nothrow）的（也就是说，提供不抛出保证）。这是异常安全代码中必不可少的基础构件。 一个异常安全的函数必须保证满足上诉三个条件之一。如果不这样，那么就不具备异常安全性。 实现数据不被破坏我们在写代码时，保证满足其中一个条件。从异常安全的角度来说，nothrow 是最优的选择，但是实际上很难不调用任何一个可能抛出异常的函数。所以大多数时候会选择 基本保证 和 强烈保证 之一。 实现 强烈保证 的一种策略是使用 copy and swap 技术： 为你打算修改的对象做一份备份，然后在副本上做一切必要的修改。若有任何修改动作抛出异常，原对象仍保持未改变状态。待所有改变都成功后，再将修改过的副本和原对象在一个不抛出异常的操作中做置换。 需要注意的是函数提供的“异常安全保证”通常只等于其所调用的各函数的“异常安全保证”中的最弱的一项。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective C++: Designs & Implements]]></title>
    <url>%2F2017%2F03%2F05%2FEffective-C-Designs-Implements%2F</url>
    <content type="text"><![CDATA[让接口容易被正确使用，不易被误用一个好的接口设计方式应该满足要求：“容易被正确使用，不易被误用”。所以设计主要分为两个方面，促进正确使用，阻止误用。 促进正确使用的方法主要有： 保持接口的一致性 与内置类型行为兼容 STL 勘称保持接口一致性的典范，这样降低了用户的记忆负担。而与内置行为兼容同时也保证不会出现违反用户直觉的问题。 阻止误用主要有： 建立新的类型 限制类型上的操作 束缚对象取值范围 消除客户对资源的管理 增加封装性如果某些东西被封装，它就不再可见；越多的东西被封装，那么看到它的人也就越少。而看到它的人越少，我们就有越大的弹性去变化它。所以我们推崇封装：它使我们能够改变事物而只影响有限的客户。 类的设计中，坚持以下两条准则有利于促进封装性： 成员变量 private 使用 non-member 和 non-friend 替换 member 函数 避免返回指向对象内部成分的 handles 将成员变量声明为 private 可以赋予客户访问数据的一致性、可细微划分访问控制、允诺约束条件获得保证，并提供 class 作者以充分实现弹性。 而尽可能的 member 函数，则减少其暴露数据，也能提高其封装性。 避免返回内部分成引用，可以保证对象状态不会被外部破坏，自然也能提高封装性。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective C++:Resource management]]></title>
    <url>%2F2017%2F03%2F05%2FEffective-C-Resource-management%2F</url>
    <content type="text"><![CDATA[C++ 中不同于Java之类的语言，编写者需要对资源进行手动管理。 Use object to manage resources和C语言一样，C++中也需要对手动申请的内存进行释放。 12345void bar() &#123; int *p = new int; //... delete p;&#125; 如果总是依赖于手动调用 delete 释放资源是行不通的。手动管理资源总会出现差错，比如后面修改代码时加上了一句 return ，那么申请的内存将得不到释放。另外，在一下非常复杂的系统中，可能出现资源被多个模块公有，如果简单释放，可能导致其他部分崩溃。 现在需要的是一种自动进行内存管理的机制：把资源放到对象内，依靠C++提供的“析构函数自动调用机制”确保资源的释放。这种机制有两个关键的想法： 获取资源后立刻放进管理对象内 管理对象运用析构函数确保资源被正确释放 实际上“以对象管理资源”的观念通常被称为“资源获取时机便是初始化时机（Resource Acquisition Is Initialization; RAII）。C++中提供了基础的 RAII 类，分别是: std::shared_ptr 及 std::weak_ptr std::unique_ptr 我们改写一下例子： 1234void bar() &#123; std::shared_ptr&lt;int&gt; wrapper(new int); //...&#125; 当然资源不仅仅是内存，也可以是文件描述符、互斥锁等。C++ 的 RAII 类中允许我们定义自己的删除函数，所以可以直接使用之管理其他非内存资源。 Think carefully about copying behavior in resource-managing classes资源因为其特殊性，所以不能简单拷贝。通常用于处理拷贝的方式有以下两种： 禁止复制 对底层资源进行“引用计数” unique_ptr 要求对象同一时刻只能拥有一个 owner，而 shared_ptr 则使用引用计数实现；对 unique_ptr 只能进行所有权转移，shared_ptr 则要避免循环计数。 Use the same form in corresponding uses of new and delete如果你在 new 表达式中使用了[]，那么也应该在 delete 中使用[]。当然 C++ 中提供了 vector 和 string 等 templates，可以将对数组的要求降为 0。如果你非要使用原生数组，也可以使用 unique_ptr 管理，只需要在类型模板参数后添加[]： 1unique_ptr&lt;int[]&gt; arrays(new int[10]); 然而 shared_ptr 并不支持，如果你非要使用，那么请自己定义 delete。 store newed objects in smart pointers in standalone statementsC++ 在实现上有很大的弹性，所以编译器可能会对指令进行重排，所以凡是写标准未定义执行顺序的代码，都可能出现问题。例如 C++ 没有规定参数求值，那么求值结果跟顺序有关时，就会出现非预期行为。 如果其中涉及到资源管理，那么可能造成资源泄露，所以 C++ 提供了单独的环境将对象置于资源管理对象中： 12345678910111213int foo() &#123; //... throw ...; //...&#125;void bar(std::shared_ptr&lt;int&gt; ptr, int);bar(std::shared_ptr&lt;int&gt;(new int), foo()); // dangerous// 上面的代码求值顺序未定义，通过编译器重排后可能导致内存泄露bar(std::make_shared&lt;int&gt;(), foo()); 单独的环境中确保资源能够正确放入资源管理对象，从而保证了不会发生资源泄露。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective c++:Constructors,Destructors,and Assignment Operators]]></title>
    <url>%2F2017%2F03%2F02%2FEffective-c-Constructors-Destructors-and-Assignment-Operators%2F</url>
    <content type="text"><![CDATA[C++ 中有三个特殊的函数，构造、析构、赋值。 Know what functions C++ silently writes and calls在 C++ 中，如果你没有事先没有声明，那么编译器会为它声明一个构造函数，一个 copy 构造函数，一个 copy assignment 操作符和一个析构函数。这些函数都是属于 public inline，且只有用户有调用的时候才会被创建。其中需要注意的有以下几点： 析构函数默认为 non-virtual copy 类默认拷贝每一个 non-static 函数的值 一旦定义了构造函数，则不会创建默认构造函数 有 reference 或 const 时不产生默认 operator= Explicitly disallow the use of compiler-generated functions you do not want有的时候我们不需要编译器产生的赋值或者其他默认函数，那我们可以将其声明为私有且不实现。不过这种办法并不完美，friend 是可以访问 private 的；另外有人不小心将其实现了也会违背预期。一种更好的办法是将其封装： 123456789class noncopyable &#123; noncopyable(const &amp;nocopyable); nocopyable &amp;operator(const noncopyable &amp;) const;public: noncopyable() &#123;&#125; ~noncopyable() &#123;&#125;&#125;;class Bar : noncopyable &#123;&#125; 总之，为驳回编译器自动提供的机制，可以将成员函数声明为 private 并且不予以实现；或者使用 noncopyable 这样的基类进行限制。 virtual function &amp; constructors and destructorsC++ 的虚函数可以提供动态绑定，不过在构造函数和析构函数中要避免使用到虚函数（哪怕是间接调用也不可以）。在构造完成之前和析构调用之后，对象都不再是一个完整的对象。这也不难理解，因为子类于父类前析构，那么此时父类调用的虚函数已经不再动态绑定到子类，则没有达到预期目的。 而对于任何具有多态性质的基类都应该将其析构函数声明为 virtual，否则会出现无法完全回收对象的问题。 1234567891011class base &#123;public: ~base() &#123;&#125;&#125;;class child : public base &#123; // ...&#125;;base *b = new child();delete b; // Error: boom Handle assignment to self in operator =对于自我赋值，一般的做法是进行证同测试，另外采用精心安排的语句导出异常安全的代码。一种比较好的办法则是使用 copy and swap 技术： 12345Class &amp;operator=(const Class &amp;c) &#123; Class s(c); swap(s); return *this;&#125; 这中办法将目标拷贝到一个临时变量中，然后和当前对象进行交换。如果构造变量失败时，不会影响原有的数据；并且保证了swap为异常安全，那么整个函数就能保证异常安全。最后，类似于 scope_ptr ，临时变量在退出时析构并释放资源。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective C++: Accustoming Yourself to C++]]></title>
    <url>%2F2017%2F03%2F02%2FEffective-C-Accustoming-Yourself-to-C%2F</url>
    <content type="text"><![CDATA[View C++ as a federation of languages今天的C++已经是一个多重泛型编程语言，它同时支持： 过程式 面对对象 函数形式 泛型形式 元编程形式 而我们在使用C++时，应当针对性的使用。C++的高效编程守则视情况而变化，取决于你使用他的那一部分。 Perfer consts, enums, and inlines to #defines在C++中，不建议使用 #define 来定义常量或者函数，应该使用语言自身机制，将预处理器的工作交给编译器来做。 使用 const 和 enum 可以让标识符进入符号表，报错的时候就不会出现“魔数”。而 inline 则替代宏函数，在保证函数行为一致性的同时，确保类型安全。 1234template&lt;typename T&gt;inline bool call(const T &amp;a, const T &amp;b) &#123; return (a &gt; b) ? a : b;&#125; Use const whenever possibleconst 允许你指定一个 语义约束 ，而编译器会强制执行这项约束。const 可以被施加于任何作用域内的对象、函数参数、函数返回类型、成员函数本体。 当 const 与指针同时出现的时候往往具有迷惑性，实际上并不高深莫测。如果 const 出现在 * 左边，表示被指物是常量；如果出现在右边，则表示指针本身是常量。 在使用 STL 的时候需要注意使用 const_iterator 而不是 const iterator 。因为 iterator 是模拟指针，在编译器的视角里于普通变量无异。 将 const 运用于成员函数的目的，是为了确认该成员函数可以作用于 const 对象。如果一个对象被定义为了 const，那么编译器会对它进行 bitwise constness 约束，即成员函数只有在不更改对象之任何成员变量（static 除外）时才可以说是 const。不过实际上项目中可能出现特殊情况，比如多线程中保证互斥的对象必须能改变，这就是 logic constness 。对于这种情况，可以使用 mutable 释放掉 non-static 成员变量的 bitwise 约束。 编译器强制实施 bitwise constness，但是你编写程序的时候应使用“概念上的常量”（conceptual constness）。 当 const 和 non-const 成员函数有着实质性的等价实现时，令 non-const 版本调用 const 版本可以避免代码重复。 Make sure that objects are initialized before they’re usedC++ 并没有保证所有的变量都能被初始化，而读取未初始化的值会导致不明确行为。所以要在使用对象之前将其进行初始化。对于没有任何成员的内置类型，需要手动完成初始化。对于内置类型外的，则由构造函数进行初始化，所以确保每一个构造函数都将对象的每一个成员初始化。 C++ 规定了对象成员变量的初始化动作发生在进入构造函数本体之前。最好的方式是总使用成员初值列表完成初始化。初值列表列出的成员变量，其排列次序应该和他们在class中的声明次序相同。 对于定义于不同编译单元内的 non-local static 对象初始化顺序，C++没有明确定义。而解决办法则是 Singleton 模式解决，因为 C++ 保证了函数内的 local static 会在“该函数被调用期间”“首次遇上该对象的定义式”时被初始化。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 4-Median of Two Sorted Arrays]]></title>
    <url>%2F2017%2F02%2F28%2FLeetCode-4-Median-of-Two-Sorted-Arrays%2F</url>
    <content type="text"><![CDATA[problemMedian of Two Sorted Arrays solution这道题目没能做出来，从网上找到了题解。题解是将问题转换为寻找第K小的数，且边际情况非常少。 首先假设数组A和B的元素个数都大于k/2，我们比较A的第k/2小的元素和B的第k/2小的元素A[k/2-1]和B[k/2-1]。 如果A[k/2-1]&lt;B[k/2-1]，这表示A[0]到A[k/2-1]的元素都在A和B合并之后的前k小的元素中。换句话说，A[k/2-1]不可能大于两数组合并之后的第k小值，所以我们可以将其抛弃。证明：假设A[k/2-1]大于合并之后的第k小值，我们不妨假定其为第（k+1）小值。由于A[k/2-1]小于B[k/2-1]，所以B[k/2-1]至少是第（k+2）小值。但实际上，在A中至多存在k/2-1个元素小于A[k/2-1]，B中也至多存在k/2-1个元素小于A[k/2-1]，所以小于A[k/2-1]的元素个数至多有k/2+ k/2-2，小于k，这与A[k/2-1]是第（k+1）的数矛盾。 当A[k/2-1]&gt;B[k/2-1]时存在类似的结论。 当A[k/2-1]=B[k/2-1]时，我们已经找到了第k小的数，也即这个相等的元素，我们将其记为m。由于在A和B中分别有k/2-1个元素小于m，所以m即是第k小的数。(这里可能有人会有疑问，如果k为奇数，则m不是中位数。这里是进行了理想化考虑，在实际代码中略有不同，是先求k/2，然后利用k-k/2获得另一个数。) 通过上面的分析，我们即可以采用递归的方式实现寻找数组A和B的元素个数都大于k/2时第k小的数。对于另一种情况，使用min(k / 2, A.size)和k-k/2且保证A.size&lt;B.size那么就可以转为前面的条件。 此外我们还需要考虑几个边界条件： . 如果A或者B为空，则直接返回B[k-1]或者A[k-1]；. 如果k为1，我们只需要返回A[0]和B[0]中的较小值；. 如果A[k/2-1]=B[k/2-1]，返回其中一个； code12345678910111213141516171819202122232425262728293031double findKth(int a[], int m, int b[], int n, int k) &#123; //always assume that m is equal or smaller than n if (m &gt; n) return findKth(b, n, a, m, k); if (m == 0) return b[k - 1]; if (k == 1) return min(a[0], b[0]); //divide k into two parts int pa = min(k / 2, m), pb = k - pa; if (a[pa - 1] &lt; b[pb - 1]) return findKth(a + pa, m - pa, b, n, k - pa); else if (a[pa - 1] &gt; b[pb - 1]) return findKth(a, m, b + pb, n - pb, k - pb); else return a[pa - 1]; &#125;class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; int *A = nums1.data(), m = nums1.size(), *B = nums2.data(), n = nums2.size(); int total = m + n; if (total &amp; 0x1) return findKth(A, m, B, n, total / 2 + 1); else return (findKth(A, m, B, n, total / 2) + findKth(A, m, B, n, total / 2 + 1)) / 2; &#125;&#125;;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - 3-Longest Substring Without Repeating Characters]]></title>
    <url>%2F2017%2F02%2F27%2FLeetCode-3-Longest-Substring-Without-Repeating-Characters%2F</url>
    <content type="text"><![CDATA[problemLongest Substring Without Repeating Characters solution 对于一个没有重复的字符串，加入一个新字符，长度+1 如果加入的字符已经存在，那么找到字符串中冲突字符后的字符串，构成新的未重复字符串 需要注意的是我开始潜意识认为字符串指“a-z”,实际上还包含“！@”之类的字符 code123456789101112131415161718192021222324252627282930int lengthOfLongestSubstring(string str) &#123; if (str.size() == 0 || str.size() == 1) return str.size(); int left = 0, right = 1; // [left, right) int index[128] = &#123;1&#125;, length = 1; index[str[left]] = 1; while (right &lt; str.size()) &#123; char a = str[right]; if (index[a] == 0) &#123; // without index[a] = 1; // add &#125; else &#123; while (str[left] != a) &#123; index[str[left]] = 0; // del left++; &#125; left++; &#125; right++; int current = right - left; if (length &lt; current) length = current; &#125; return length;&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock’ (2)]]></title>
    <url>%2F2017%2F02%2F23%2FMysql-ERROR-2002-HY000-Can%E2%80%99t-connect-to-local-MySQL-server-through-socket-%E2%80%98-var-lib-mysql-mysql-sock%E2%80%99-2%2F</url>
    <content type="text"><![CDATA[使用 mysql -uroot -p 连接 Mysql 时出现了下面的错误: 12ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’ (2) 经过排查，发现是权限问题，使用: 1chown -R mysql:mysql /var/run/mysqld 修改权限，然后启动，成功。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查看3306端口命令]]></title>
    <url>%2F2017%2F02%2F23%2FLinux-%E6%9F%A5%E7%9C%8B3306%E7%AB%AF%E5%8F%A3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看3306端口被什么程序占用 lsof -i :3306 查看3306端口是被哪个服务使用着 netstat -tunlp | grep :3306 查看3306端口的是否已在使用中，可验证使用该端口的服务是否已正常运行 netstat -an | grep :3306]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql The server quit without updating PID file (/var/run/mysqld/mysqld.pid)]]></title>
    <url>%2F2017%2F02%2F23%2FMysql-The-server-quit-without-updating-PID-file-var-run-mysqld-mysqld-pid%2F</url>
    <content type="text"><![CDATA[Mysql 启动时出现以下错误: 1The server quit without updating PID file (/var/run/mysqld/mysqld.pid) 根据网上方法，用: sudo find / -name my.conf 发现有多个 my.conf 文件存在: 12/var/my.conf/var/mysql/my.conf 删除 /etc/mysql/my.cnf 这个文件，启动MySql服务，成功。]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象线程安全]]></title>
    <url>%2F2017%2F01%2F15%2FC-%E5%AF%B9%E8%B1%A1%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[最近翻阅了陈硕先生写的《Linux 多线程服务端编程》一书，收益颇丰。书指出了不少异步编程中陷阱，并提供了最佳实践。书中把问题抽丝剥茧、娓娓道来，是一本不可多得的好书。 该书第一章为线程安全的对象生命周期管理，给出了C++中写出线程安全代码的良好建议。写出线程安全的具体逻辑代码并不是什么难事，通过同步原语保护内部数据、进行同步即可。在C++中，除了代码逻辑外，还需要对对象生死进行特殊处理。这是因为对象生死不能由其内部拥有的 mutex 来保护。因此，如何解决对象构造、析构时可能存在的竞争条件是C++多线程编程面临的一个基本问题。 什么是线程安全这里引用 Wiki 对线程安全的描述： 线程安全是一个计算机编程的概念，适用于多线程编程环境。我们说一段代码是线程安全的，当它只对共享的数据进行操作，且保证它在同一时刻被多个线程安全的执行。有很多策略可以生成线程安全的数据结构。程序可能在一个共享地址空间中创建多个线程并同步执行一段代码，在该地址空间中每个线程实际都可以访问其他线程的内存空间。线程安全是一种属性，它通过同步来重建代码片段与控制流的关联，从而保证代码在多线程环境的运行。 陈硕先生的书中也给出了线程安全的 class 应当满足的三个条件： 多个线程同时访问时，其表现出正确的行为 无论操作系统如何调度这些线程，无论这些线程的执行顺序如何交织 调用端代码无额外的同步或其他协调动作 按照上述条件来约束对象，那么 C++ 标准库中常用的容器并非线程安全的，如：std::string、std::map、std::vector。 基本保证对于对象中的除构造、析构外的成员函数，写出线程安全的代码十分容易，通过 mutex 进行同步就好。 12345678910111213141516171819202122#include &lt;mutex&gt;templete &lt;typename T&gt;class blocking_queue &#123;public: void push_back(const T &amp;t) &#123; std::lock_guard lock(mutex_); queue_.push(t); &#125; T pop() &#123; std::lock_guard lock(mutex_); T t = queue_.front(); queue_.pop(); return t; &#125;private: std::mutex mutex_; std::queue&lt;T&gt; queue_;&#125;; 对象创建约束根据《Linux 多线程服务端编程》书中所说： 对象构造要做到线程安全，唯一的要求时在构造期间不要泄露 this 指针，即： 不要在构造函数中注册任何回调函数 也不要在构造函数中把 this 对象传给跨线程对象 即便时在构造函数最后一句也不行 也就是说一个对象在未构造完成之际，是不能暴露给外部的。对于上面三条准则最后一条，先生也给了解释：如果该类被继承，那么其优先于子类构造，也会出现访问到不完整对象。 对象销毁相比对象创建，对象销毁则相对复杂。比如一个线程准备销毁对象，而另一个线程正在进行数据访问，那么致命错误便出现了。对于对象销毁，并没有比较好的方法。 使用 shared_ptr、weak_ptr 管理对象生命周期使用 shared_ptr 和 weak_ptr 对对象进行生命周期管理能解决对象销毁的问题。对象拥有者持有 shared_ptr，而对象使用者持有 weak_ptr。持有者在使用的时候，申请借用提升为 shared_ptr。这样，如果出项上述情况，那么拥有者便将对象托管给使用者，同时自己释放掉对象引用。等到使用者完成工作时，就会触发 shared_ptr 释放对象。 对于那些在引用之前便被释放的对象，weak_ptr 提升便会失败，也保证了不会悬垂指针的危险。 shared_ptr 线程安全至于 shared_ptr 本身，并非线程安全的，所以要使用被多个线程访问的 shared_ptr 对象，那么需要手动控制同步。 所以，在编写 C++ 程序的时候，应当尽量使用 shared_ptr 而非原始指针，这样自动化的管理资源，不仅解放大脑，还能避免潜在错误。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LL-Script implements]]></title>
    <url>%2F2016%2F11%2F28%2FLL-Script-implements%2F</url>
    <content type="text"><![CDATA[LL-Script 是一个简单的脚本语言，最初写的时候是为了给游戏做脚本，后来还是使用lua替代。很久后又重新开始按照规范写了一次，这次整体流程走通了，但是设计杂乱无章。前些日子从新写了一次，采用了一些良好的设计，这就是先在这个版本。 脚本源码在github上，访问这里。 概述首先看整体流程：输入代码、输出opcode并执行 1234Lexer(source code) =&gt; token streamParser(token stream) =&gt; SSA (static single assginment form)CodeGen(SSA) =&gt; opcodeVirtualMachine(opcode) =&gt; result 这里直接从源码构造中间代码，省去了语法树部分。另外Parser后应该为优化阶段，其输出为优化后的 SSA IR。 词法分析、语法分析词法分析部分是简单的 ad-hoc 生成 token stream。Parser 按照 LL(1) 文法分析，并直接生成 SSA IR。 Script 只有最基本的作用域，没有块级作用域，整个函数中的变量在函数任意位置均可访问。FunctionScope 表示一个函数作用域，其原型如下： 12345678910111213141516struct FunctionScope &#123; typedef std::unordered_map&lt;std::string, unsigned&gt; Symbols; // symbol type enum &#123; None, Define, Let &#125;; FunctionScope() : cfg_(nullptr) , block_(nullptr) &#123;&#125; CFG *cfg_; Symbols symbolTable_; BasicBlock *block_; std::unordered_set&lt;std::string&gt; captures_;&#125;; cfg 表示函数对应 SSA 的控制流程图，主要用于提供源代码直接到IR的转换，block_ 表示当前翻译过程中源代码对应IR所在的基本块。Symbols 使用 unordered_map 来表示符号容器，其中first表示符号名，second表示符号类别，由enum { None, Define, Let };决定。symbolTable_ 就是主要的符号表，函数作用域中定义的符号均记录在此。captures_表示函数的捕获(c++名词)列表，记录在此，给翻译收尾工作提供必要的信息。 在翻译过程中，主要用到查找符号原型如下： 12bool tryToCatchID(std::string &amp;name);bool tryToCatchID(scope_iterator iter, std::string &amp;name); 首先通过原型1在当前作用域中查找，如果找到返回true，如果没有，则从里向外递归地遍历函数作用域栈。找到后，如果为外部符号，则加入捕获列表，否则返回false。 SSA 形式中间代码生成从源代码直接生成 SSA 形式代码可以参考论文： Simple and Efficient Construction of Static Single Assignment FormMatthias Braun1, Sebastian Buchwald1, Sebastian Hack2, Roland Leißa2, Christoph Mallon2, and Andreas Zwinkau1 Script 中涉及到的代码主要在 Parser 分析过程中以及 CFG 中，CFG 部分内容如下： 12345678910111213141516class CFG&#123;public: // .... // SSA form construction. void sealOthersBlock(); void sealBlock(BasicBlock *block); void saveVariableDef(std::string name, BasicBlock *block, Value *value); Value *readVariableDef(std::string name, BasicBlock *block);protected: // SSA Value *readVariableRecurisive(std::string name, BasicBlock *block); Value *addPhiOperands(std::string name, Phi *phi); Value *tryRemoveTrivialPhi(const std::string &amp;name, Phi *phi); // ....&#125;; 这部分代码详细使用请看论文或博客。 SSA IRSSA IR 的 use-def chain 主要参考 LLVM 2.0 源码。SSA IR 中基础数据结构有 Use、Value、User，每一条 Instruction 既是 Value 又是 User，User 和 Value 通过 Use 关联起来。一些列指令组成 BasicBlock，一些列 BasicBlock 组成 CFG。IRContext包装了Instruction创建的工作。每一个函数由一个 CFG 组成，所有函数一起组成 IRModule。也就是说 Parser 输出为 IRModule。 函数处理生成 SSA IR 部分内容并不复杂，除了有关函数、Lambda部分。Script中无论函数定义可以看作如下替换(步骤1)： 1234function bar() &#123;&#125;=&gt;function $lambda_1_bar() &#123;&#125;define bar = $lambda_1_bar; 因为闭包对于普通变量通过拷贝、对于复合变量通过引用(实际实现为指针)实现。所以可以通过类似于C++std::bind的机制实现 closure(步骤2)。 1234567let a = 10;define call = lambda(x) &#123; return x + a;&#125;=&gt;let call_tmp = lambda(a, x) .... define call = call_tmp(a); 不过这样处理就会涉及到函数中访问其自己名字的问题，或者说叫访问lambda函数自己。这个问题可以通过 Y combinator 解决。Script 中使用的办法比较简单(步骤3)： 1234567891011let fib = lambda(n) &#123; if (n &lt; 2) return 0; return fib(n-1) + fib(n-2);&#125;=&gt;let tmp = lambda(fib, n) &#123; fib = fib(fib); if (n &lt; 2) return 0; return fib(n-1) + fib(n-2);&#125;let fib = tmp(fib); 有了上述基础，就可以看相关代码： 12345678910111213141516171819202122232425Value *Parser::parseFunctionCommon(const std::string &amp;name)&#123; // create function and generate parallel invoke. // for module require, need insert file name IRFunction *function = module_.createFunction( Combinator(lexer_.filename(), name)); pushFunctionScopeAndInit(function); Strings params; getFunctionParamsAndBody(params, function); // save current captures. std::vector&lt;std::string&gt; prototype; getFunctionPrototype(name, prototype, params); function-&gt;setParams(std::move(prototype)); std::unordered_set&lt;std::string&gt; captures; std::swap(captures, scope-&gt;captures_); if (captures.find(name) != captures.end()) dealRecursiveDecl(name); popFunctionScope(function); // create closure for function. return createClosureForFunction(name, captures);&#125; parseFunctionCommon 首先分析函数参数和函数体，然后获取函数原型(步骤2)，根据函数是否递归调用自身，调用dealRecursiveDecl(步骤3)，最后为函数创建闭包(步骤1)。 在函数原型部分，Script 将自身的名字放到 capture 列表的最后部分位置，这样使得处理递归调用变得简单。 目标代码生成代码生成流程如下: 1234567891011121314151617void CodeGen::runOnFunction(IRFunction *func)&#123; std::list&lt;LiveInterval&gt; intervals; &#123; LiveIntervalAnalysis analysis; analysis.runOnFunction(func); analysis.swapIntervals(intervals); &#125; SimpleRegisterAllocation RA(255, intervals); RA.runOnFunction(func); PhiElimination PE; PE.runOnFunction(func); numOfRegister = RA.totalRegister(); genFunction(func);&#125; 首先是分析变量活性区间，然后通过活性区间进行寄存器分配，最后消除 Phi 结点，此时 IR 退出 SSA 形式。然后在这个基础上以函数为单位进行代码生成。 CodeGen 目标为opcode，而opcode相关操作包装在OPBuilder中。具体逻辑比较简单，请直接看源码。 活性区间计算与寄存器分配活性区间及寄存器分配以: Linear Scan Register Allocation for the Java HotSpot™ Client Compiler - Christian Wimmer 论文为基础，详细逻辑可以参考该论文。 活性区间计算涉及到函数如下： 123void buildIntervals(IRFunction *func);void computeLocalLiveSet(IRFunction *func);void computeGlobalLiveSet(IRFunction *func); 按照论文，首先计算 BasicBlock 顺序并编号，然后依次计算本地活性集和全局活性集，最后才建立活性区间。 1234567void LiveIntervalAnalysis::runOnFunction(IRFunction *func)&#123; func-&gt;computeBlockOrder(); computeLocalLiveSet(func); computeGlobalLiveSet(func); buildIntervals(func);&#125; 寄存器分配部分，原先的想法是使用线性扫描寄存器分配方法，在实现过程中，部分细节不知道怎么处理，所以就使用了比较简单的分配方式，将所有变量放到栈上，所有临时变量才分配寄存器，由 VM 约定最多255个寄存器。在 SimpleRegisterAllocation 中具体操作如下： 12345void initAndSortIntervals();void assignRegister(IRFunction *func);void allocateNewRegister(LiveInterval &amp;interval);void expiredOldIntervals(unsigned current, ActiveSet &amp;active, ActiveSet &amp;inactive);bool tryToAllocateRegister(LiveInterval &amp;interval, ActiveSet &amp;active, ActiveSet &amp;inactive); 具体实现过程，参考博客; Runtime虚拟机的数据对象采用 Tagging 标记方式，整个 Runtime 以 C 语言为主实现，封装后供 C++ 使用。对象基本结构如下： 12345678910111213141516171819202122232425262728293031323334353637enum Tag &#123; TagNot = 0, TagFixnum = 1, TagReal = 2, TagSpec = 3, TagNil = 7, TagShift = 2, TagMask = 3, TagSpecalMask = 0xf, TagSpecalShift = 4,&#125;;// 8bitsenum Type &#123; TypeString = 0, TypeArray = TypeString + 1, TypeClosure = TypeString + 2, TypeUserFunc = TypeString + 3, TypeHashNode = TypeString + 4, TypeUserData = TypeString + 5, TypeHashTable = TypeString + 6,&#125;;// common property of heap object// obType_ is the type of object#define HEAP_OBJECT_HEAD \ int8_t obType; \ int8_t resv1; \ int8_t resv2; \ int8_t resv3typedef struct &#123; HEAP_OBJECT_HEAD;&#125; CommonObject; Tag 用于标记简单对象类型，复合对象继承自 CommonObject，使用 obType 表示具体对象类型即 Type 中对应的类型。 以String为例 ： 123456typedef struct&#123; HEAP_OBJECT_HEAD; size_t length; char str[];&#125; String; 任何一个 String 对象长度为 sizeof(String) + String.length。所有数据结构中，最为复杂的是 Hash 表的设计。 123456789101112131415typedef struct HashNodeList&#123; HEAP_OBJECT_HEAD; size_t capacity; HashNode content[0];&#125; HashNodeList;typedef struct Hash&#123; HEAP_OBJECT_HEAD; size_t capacity; size_t size; size_t max_idx; HashNodeList *content;&#125; Hash; Hash 是 Hash 表的数据结构，其中数据存放在 HashNodeList 部分，这样设计是用于后面的 Expand 以及 Shrink 操作。这里说明 hash 表 set 操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static void HashSet(Object self, uintptr_t key, Object value)&#123; assert(IsFixnum(value)); Hash *hash = (Hash*)self; uintptr_t index = key % hash-&gt;capacity; uintptr_t slot = hash-&gt;capacity; if (IsNil(value)) &#123; value = CreateUndef(); &#125; HashNodeList *list = hash-&gt;content; while (list-&gt;content[index].key != key &amp;&amp; !IsNil(list-&gt;content[index].value)) &#123; if (slot == hash-&gt;capacity &amp;&amp; IsUndef(list-&gt;content[index].value)) &#123; slot = index; break; &#125; index = HashNextIndex(index, hash-&gt;capacity); &#125; if (list-&gt;content[index].key == key) slot = index; if (slot == hash-&gt;capacity) slot = index; if (!IsUndef(value) &amp;&amp; (IsNil(list-&gt;content[slot].value) || IsUndef(list-&gt;content[slot].value))) &#123; assert(hash-&gt;size != hash-&gt;capacity); if (key == HashKey(CreateFixnum(hash-&gt;max_idx))) hash-&gt;max_idx++; hash-&gt;size++; &#125; if (IsUndef(value) &amp;&amp; !IsUndef(list-&gt;content[slot].value) &amp;&amp; !IsNil(list-&gt;content[slot].value)) &#123; assert(hash-&gt;size); if (key == HashKey(CreateFixnum(hash-&gt;max_idx - 1))) hash-&gt;max_idx--; hash-&gt;size--; &#125; list-&gt;content[slot].value = value; list-&gt;content[slot].key = key;&#125; 首先计算hash对象所在 HashNodeList 中的 slot，如果当前位置已经被占用，则计算下一个 slot 所在位置。找到位置后，根据是否 nil 判断是否删除结点。 1234567891011121314151617181920Object HashFind(Object self, Object key)&#123; assert(IsHash(self)); Hash *hash = (Hash*)self; uint32_t hash_key = HashKey(key); uintptr_t index = hash_key % hash-&gt;capacity; HashNodeList *list = hash-&gt;content; while (list-&gt;content[index].key != hash_key &amp;&amp; !IsNil(list-&gt;content[index].value)) &#123; if (IsUndef(list-&gt;content[index].value)) break; index = HashNextIndex(index, list-&gt;capacity); &#125; if (IsNil(list-&gt;content[index].value)) return CreateUndef(); else return list-&gt;content[index].value;&#125; find 操作查找部分与 set 类似，最后直接返回对象值。实际上对外暴露的接口是： 12345678910111213void HashSetAndUpdate(Object self, Object key, Object value)&#123; assert(IsHash(self)); if (key == CreateFixnum(-1)) key = CreateFixnum(((Hash*)self)-&gt;max_idx); uint32_t hash_key = HashKey(key); HashSet(self, hash_key, value); if (HashNeedExpand(self)) HashExpand(self); else if (HashNeedShrink(self)) HashShrink(self);&#125; 这里对 set 后的表进行判断，并根据结果伸展或者收缩表。伸展表时，目标容积为原容积的 3/2，收缩时，目标容积为原容积的 2/3。 需要注意的是 Runtime 中申请内存也必须在 Runtime 中，保证 GC 能够访问到该内存。所以 Runtime 设计中出现的内存分配必须使用 GC 提供的接口。另外，如果分配过程中发生了 GC，也需要保证所有指针均指向正确的位置。 123456789101112131415// // just expand content.static void HashExpand(Object self)&#123; assert(IsHash(self)); Hash *hash = (Hash*)self; size_t future_capacity = HashExpandSize(hash-&gt;capacity); // before gc, save it as global object GlobalObjectBuffer = &amp;self; HashNodeList *cap = (HashNodeList*)HashNewNodeList(future_capacity); GlobalObjectBuffer = NULL; HashRehash(self, cap);&#125; 因此，在 Runtime 中提供了一个特殊的对象 GlobalObjectBuffer来保证内存指针始终指向正确的位置。 Virtual Machine &amp; GC1234567891011121314151617181920212223242526272829303132333435363738394041424344454647typedef int8_t Byte;enum Opcode &#123; OK_Goto = 0, // goto lable@_addr // operator // single OK_Not, // temp = !temp // binary OK_Add, // temp = temp + temp OK_Sub, // temp = temp - temp OK_Mul, // temp = temp * temp OK_Div, // temp = temp / temp // relop OK_Great, // temp = temp &gt; temp OK_GreatThan, // temp = temp &gt;= temp OK_Less, // temp = temp &lt; temp OK_LessThan, // temp = temp &lt;= temp OK_Equal, // temp = temp == temp OK_NotEqual, // temp = temp != temp // move OK_MoveS, // temp = string index OK_MoveI, // temp = constant OK_MoveF, // temp = float OK_MoveN, // temp = null OK_Move, // temp = temp // memory OK_Load, // load id to temp OK_Index, // load id [ temp ] to temp OK_Store, // store id from temp OK_SetIndex, // store id [ temp ] from temp // condition jmp OK_If, // if temp goto label // call OK_Param, // push temp OK_Call, // temp = call Label in num params OK_TailCall, OK_Return, // return temp OK_NewHash, // tmp = new hash OK_NewClosure, // tmp = new string(idx) OK_UserClosure, // tmp = new user closure OK_Halt, // stop&#125;; opcode 设计如上，VM 对其加以解释执行。 VM 中有三个重要的数据结构，VMFrame、VMScene、VMState，VMFrame 是运行时的一个调用栈帧，保存了当前所在位置的运行时数据。VMScene是一个运行场景，每一个程序一个运行场景，当前场景运行不会影响到后续场景的运行。VMState是opcode解释器，绑定VMScene运行。在同一时刻，只能有一个VMState运行，因为需要涉及到Runtime中的设计。当然这中设计导致了这种缺陷，但是目前是最简单的实现方式。 GC 采用了semi-space swap算法， 12345678910111213141516171819202122232425262728293031struct Semispace&#123; Object allocateMemory(size_t size); bool contains(Object obj); void reset();&#125;;class GarbageCollector&#123;public: Object allocate(size_t size); void bindReference(std::function&lt;VariableReference&gt; call); void bindGlobals(std::function&lt;GloablVariable&gt; call); void processReference(Object *slot);private: void garbageCollect(); void swapSpace(); void cleanSpace(Semispace *space); bool isForwarded(Object obj); void forwardTo(Object obj, Object new_addr); Object forwardee(Object obj); Object swap(Object obj, size_t size); Semispace *from_space_; Semispace *to_space_;&#125;; 主要数据结构如上。其中有两个回掉函数，其中GloablVariable用于与VM沟通，获取根结点数据;VariableReference用于与Runtime沟通，处理变量引用，这样将GC与VM和Runtime解耦，以后修改GC更为方便。GC详细介绍可以看文章。 在 buildin.cpp 中提供了 Runtime 涉及到的操作和 GC 耦合部分内容: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051void ProcessGlobals(void *scene)&#123; using script::VMFrame; using script::VMScene; using script::GarbageCollector; VMScene *vmscene = static_cast&lt;VMScene*&gt;(scene); GarbageCollector *GC = &amp;vmscene-&gt;GC; for (auto &amp;frame : vmscene-&gt;frames) &#123; GC-&gt;processReference(&amp;frame.params); GC-&gt;processReference(&amp;frame.registers); &#125; for (auto &amp;object : vmscene-&gt;paramsStack) &#123; GC-&gt;processReference(&amp;object); &#125; if (GlobalObjectBuffer != NULL) GC-&gt;processReference(GlobalObjectBuffer);&#125;void ProcessVariableReference(void *scene, Object *object)&#123; using script::VMScene; using script::GarbageCollector; VMScene *vmscene = static_cast&lt;VMScene*&gt;(scene); GarbageCollector *GC = &amp;vmscene-&gt;GC; if (IsClosure(*object)) &#123; size_t hold = ClosureHold(*object); Object *params = ClosureParams(*object); for (size_t idx = 0; idx &lt; hold; ++idx) &#123; GC-&gt;processReference(&amp;(params[idx])); &#125; &#125; else if (IsArray(*object)) &#123; size_t length = ArraySize(*object); Object *array = ArrayPointer(*object); for (size_t idx = 0; idx &lt; length; ++idx) &#123; GC-&gt;processReference(&amp;array[idx]); &#125; &#125; else if (IsHash(*object)) &#123; GC-&gt;processReference(HashNodeListGet(*object)); &#125; else if (IsHashNodeList(*object)) &#123; size_t size = NodeListElementCapacity(*object); HashNode *nodes = HashNodeListElement(*object); for (size_t idx = 0; idx &lt; size; ++idx) &#123; GC-&gt;processReference(&amp;nodes[idx].value); &#125; &#125;&#125; 上面代码就是用于处理 GC 的回掉工作。 在 VM 当中提供了 tailCall 指令用于尾调用(并不局限与尾递归)优化，对于那些在返回语句中调用了其他函数的调用语句均可以优化。具体VM中则是重复利用当前 VMFrame ，达到尾调用的目的。 仍然需要注意的是使用 GC 出现的具有迷惑性的问题，如果某条指令执行过程中，创建了对象，就要保证创建前后指针值的位置正确。 FFI 支持在Runtime和VM中提供了FFI支持： 12345678////// user func object///typedef struct&#123; HEAP_OBJECT_HEAD; void *content;&#125; UserClosure; 该结构用于包装用户函数，然后 VM 中可以使用 callUserClosure 与用户定义函数进行交互。 这些用户定义函数需要在编译器中先进行注册后才能被编译器识别： 123456789101112131415161718192021222324252627282930313233343536Object lib_require(VMState *state, size_t paramsNums)&#123; assert(globalReguireCallback); if (paramsNums != 1) &#123; state-&gt;runtimeError(&quot;require only takes one parameter&quot;); &#125; Object res = state-&gt;getScene()-&gt;paramsStack.back(); if (IsString(res)) &#123; // save it. std::string filename = StringGet(res); VMScene *scene = state-&gt;getScene(); unsigned resReg = static_cast&lt;unsigned&gt;(scene-&gt;lastValue); globalReguireCallback(filename.c_str(), resReg); &#125; return CreateUndef();&#125;static Lib libs[] = &#123; &#123; &quot;require&quot;, lib_require &#125;, &#123; nullptr, nullptr &#125;&#125;;void RegisterLibrary(LibRegister lib_register)&#123; Lib *lib = libs; while (lib-&gt;name) &#123; lib_register(lib-&gt;name, lib-&gt;closure); lib++; &#125;&#125;void RegisterRequire(RequireCallback require)&#123; globalReguireCallback = require;&#125; 这里是对脚本提供了模块加载功能，首先用用户提供自定义函数(原型与lib_require一致)，然后保存在libs[]中，编译器初始化时，会将具体的注册函数传递给RegisterLibrary并一一注册。 对于一个C函数的定义，在注册过程中需要向Parser和opcode中注册，方便符号查找。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL traceball]]></title>
    <url>%2F2016%2F11%2F21%2FOpenGL-traceball%2F</url>
    <content type="text"><![CDATA[这是图形学的一个作业，记录在此。 这次作业要求实现一个 traceball，需求如下： 鼠标按住滑动，物体跟随鼠标转动 滑动后释放鼠标，则物体保持最后旋转方向继续转动 直接点击则可以停止旋转 现在需要把三个要求转换为程序实现，这里使用 freeglut 库开发。 设计设计时需要考虑到的问题主要有下面两点。 物体旋转OpenGL 中旋转通过 glRotate*() 函数实现，该函数需要提供两种含义的参数：1、旋转角度；2、旋转轴矢量。即用户改变旋转状态时，只需找出旋转角度与旋转轴矢量。除此之外，具体实现时我们还需要记录旋转前的状态，即每次绘制图像时先旋转到先前位置，然后进行下一步旋转。因此，多个旋转组合，理论上左乘顺序，依次给出旋转的矩阵。然而CTM实现是右乘属性。这里用栈操作实现不了顺序，只能靠自己编程设置矩阵保存上次旋转后的组合矩阵，再CTM右乘它。公式为： 1234初始：CTM(0)=I, M(0)=ICTM(i)=I*R(i)*M(i-1); M(i)=CTM(i）; 鼠标跟随这里假设我们的视点放在 Z 轴上，方向朝向远点，正方向为上。因此我们可以把屏幕上任意一点看成(x, y, 0)，方便后续计算。OpenGL 提供了鼠标相关回掉设置，可以监听鼠标移动和点击事件。对于鼠标移动，可以每次记录当前位置和前一刻位置，算出鼠标移动矢量 a。算出与矢量 a 垂直的平面，可以算出 xoy 平面和该平面的交线即为旋转轴。旋转角度则可以通过旋转方向矢量长度计算。 现在可以监听鼠标按键信息，按下表示开始旋转，弹起表示监控旋转结束；如果按下和弹起位置一样，那么停止旋转，否则继续保持旋转。 Code下面直接给出源码，其中有部分完成作业中其他需求部分也保留了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344#include &lt;math.h&gt;#include &lt;stdlib.h&gt;#include &lt;GL/glut.h&gt;#define PI 3.1415926#define ORITHOGRAPHIC 1#define PERSPECTIVE 2typedef GLfloat Point3f[3];void Idle(void);void Gasket(void);void Render(void);void Initialize(void);void Reshape(int w, int h);void Perspective(int w, int h);void MouseMotion(int x, int y);void Orthographic(int w, int h);void Keyboard(unsigned char key, int x, int y);void MouseEvent(int button, int state, int x, int y);int gProjectStyle;int gWindowWidth, gWindowHeight;int gCurrentX, gCurrentY;int gStartX, gStartY;int gGasketLevel;// lookAt 相关GLfloat gZNear = 3.f, gZFar = 10.f;GLfloat gZeye = 5.f;// trackball 相关GLfloat gLastPosition[3] = &#123; 0.f, 0.f, 0.f &#125;;GLfloat gAxis[3] = &#123; 0.f, 0.f, 0.1f &#125;;GLfloat gAngle = 0.f;bool gIsRedrawContinue = false;// 保存矩阵GLfloat CompositeTransMatrix[4][4];int main(int argc, char **argv)&#123; gWindowWidth = gWindowHeight = 600; glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH); glutInitWindowSize(gWindowWidth, gWindowHeight); glutCreateWindow(&quot;trackball Color Gasket&quot;); Initialize(); glutMainLoop();&#125;void Identity(GLfloat matrix[4][4])&#123; for (int i = 0; i &lt; 4; ++i) &#123; for (int j = 0; j &lt; 4; ++j) &#123; matrix[i][j] = i == j ? 1.f : 0.f; &#125; &#125;&#125;void MenuSelect(int item)&#123; if (item == ORITHOGRAPHIC) &#123; Orthographic(gWindowWidth, gWindowHeight); gProjectStyle = ORITHOGRAPHIC; glutPostRedisplay(); &#125; else if (item == PERSPECTIVE) &#123; Perspective(gWindowWidth, gWindowHeight); gProjectStyle = PERSPECTIVE; glutPostRedisplay(); &#125;&#125;void InitMenu(void)&#123; glutCreateMenu(MenuSelect); glutAddMenuEntry(&quot;Orthographic&quot;, ORITHOGRAPHIC); glutAddMenuEntry(&quot;Perspective&quot;, PERSPECTIVE); glutAttachMenu(GLUT_RIGHT_BUTTON);&#125;void InitCallback(void)&#123; glutReshapeFunc(Reshape); glutDisplayFunc(Render); glutIdleFunc(Idle); glutMouseFunc(MouseEvent); glutMotionFunc(MouseMotion); glutKeyboardFunc(Keyboard);&#125;void Initialize(void)&#123; InitCallback(); InitMenu(); gGasketLevel = 3; Identity(CompositeTransMatrix); glEnable(GL_DEPTH_TEST); glShadeModel(GL_FLAT); glClearColor(1.0, 1.0, 1.0, 1.0); gProjectStyle = ORITHOGRAPHIC; Orthographic(gWindowWidth, gWindowHeight);&#125;void Reshape(int w, int h)&#123; if (gProjectStyle == ORITHOGRAPHIC) Orthographic(w, h); else Perspective(w, h);&#125;void Idle(void)&#123; if (gIsRedrawContinue == true) &#123; gAngle = 0.01f; glutPostRedisplay(); &#125;&#125;// // 计算透视窗口// void CalView(int w, int h, GLfloat *left, GLfloat *right, GLfloat *bottom, GLfloat *top)&#123; if (w &lt;= h) &#123; *left = -2.0f; *right = 2.0f; *bottom = -2.0f * h / w; *top = 2.0f * h / w; &#125; else &#123; *left = -2.0f * w / h; *right = 2.0f * w / h; *bottom = -2.0f; *top = 2.0f; &#125;&#125;void Perspective(int w, int h)&#123; GLfloat left, right, bottom, top; CalView(w, h, &amp;left, &amp;right, &amp;bottom, &amp;top); glViewport(0, 0, w, h); glMatrixMode(GL_PROJECTION); glLoadIdentity(); glFrustum(left, right, bottom, top, gZNear, gZFar); glutPostRedisplay(); gWindowWidth = w; gWindowHeight = h;&#125;void Orthographic(int w, int h)&#123; GLfloat left, right, bottom, top; CalView(w, h, &amp;left, &amp;right, &amp;bottom, &amp;top); glViewport(0, 0, w, h); glMatrixMode(GL_PROJECTION); glLoadIdentity(); glOrtho(left, right, bottom, top, gZNear, gZFar); glMatrixMode(GL_MODELVIEW); glutPostRedisplay(); gWindowWidth = w; gWindowHeight = h;&#125;// // 将屏幕坐标转换到 vector3f// void TrackballPToV(int x, int y, int w, int h, GLfloat v[3])&#123; v[0] = (2.0f*x - w) / w; v[1] = (h - 2.0f*y) / h; float d = sqrtf(v[0] * v[0] + v[1] * v[1]); v[2] = cosf((PI / 2.0f) * ((d &lt; 1.0f) ? d : 1.0f)); float a = 1.0f / sqrtf(v[0] * v[0] + v[1] * v[1] + v[2] * v[2]); v[0] *= a; v[1] *= a; v[2] *= a;&#125;void MouseMotion(int x, int y)&#123; float curPos[3], dx, dy, dz; TrackballPToV(x, y, gWindowWidth, gWindowHeight, curPos); dx = curPos[0] - gLastPosition[0]; dy = curPos[1] - gLastPosition[1]; dz = curPos[2] - gLastPosition[2]; if (dx || dy || dz) &#123; gAngle = 90.0F * sqrtf(dx*dx + dy*dy + dz*dz); gAxis[0] = gLastPosition[1] * curPos[2] - gLastPosition[2] * curPos[1]; gAxis[1] = gLastPosition[2] * curPos[0] - gLastPosition[0] * curPos[2]; gAxis[2] = gLastPosition[0] * curPos[1] - gLastPosition[1] * curPos[0]; gLastPosition[0] = curPos[0]; gLastPosition[1] = curPos[1]; gLastPosition[2] = curPos[2]; &#125; glutPostRedisplay();&#125;void StartMotion(int x, int y)&#123; gIsRedrawContinue = false; gStartX = x; gStartY = y; gCurrentX = x; gCurrentY = y; TrackballPToV(x, y, gWindowWidth, gWindowHeight, gLastPosition);&#125;void StopMotion(int x, int y)&#123; if (gStartX != x &amp;&amp; gStartY != y) &#123; gIsRedrawContinue = true; &#125; else &#123; gAngle = 0.0f; gIsRedrawContinue = false; &#125;&#125;void MouseEvent(int Botton, int State, int MouseX, int MouseY)&#123; if (Botton == GLUT_LEFT_BUTTON) &#123; switch (State) &#123; case GLUT_DOWN: StartMotion(MouseX, MouseY); break; case GLUT_UP: StopMotion(MouseX, MouseY); break; &#125; &#125;&#125;void Render(void)&#123; GLfloat *pCompositeTransMatrix = *CompositeTransMatrix; glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); /* 多个旋转组合 */ glMatrixMode(GL_MODELVIEW); glLoadIdentity(); glRotatef(gAngle, gAxis[0], gAxis[1], gAxis[2]); glMultMatrixf(pCompositeTransMatrix); glGetFloatv(GL_MODELVIEW_MATRIX, pCompositeTransMatrix); // 设置 lookAtMatrix 应该在最开始的位置 glLoadIdentity(); gluLookAt(0, 0, gZeye, 0, 0, 0, 0, 1, 0); glMultMatrixf(pCompositeTransMatrix); Gasket(); glutSwapBuffers();&#125;void Keyboard(unsigned char key, int x, int y)&#123; if (&apos;0&apos; &lt;= key &amp;&amp; key &lt;= &apos;3&apos;) &#123; gGasketLevel = key - &apos;0&apos;; glutPostRedisplay(); &#125; else if (key == &apos;q&apos; || key == &apos;Q&apos;) &#123; exit(0); &#125;&#125;void Triangle(const Point3f p1, const Point3f p2, const Point3f p3, const Point3f color)&#123; glBegin(GL_POLYGON); &#123; glColor3fv(color); glVertex3fv(p1); glVertex3fv(p2); glVertex3fv(p3); &#125; glEnd();&#125;void Tetrahedron(const Point3f p1, const Point3f p2, const Point3f p3, const Point3f p4)&#123; const static Point3f Color[] = &#123; &#123; 1.f, 0.f, 0.f &#125;, &#123; 0.f, 1.f, 0.f &#125;, &#123; 0.f, 0.f, 1.f &#125;, &#123; 1.f, 1.f, 0.1f &#125;, &#125;; Triangle(p1, p2, p3, Color[0]); Triangle(p1, p2, p4, Color[1]); Triangle(p1, p3, p4, Color[2]); Triangle(p2, p4, p3, Color[3]);&#125;void DivideVertices(Point3f p1, Point3f p2, Point3f p3, Point3f p4, int level)&#123; Point3f v0, v1, v2, v3, v4, v5; if (level &gt; 0) &#123; for (int j = 0; j&lt;3; j++) v0[j] = (p1[j] + p2[j]) / 2; for (int j = 0; j&lt;3; j++) v1[j] = (p1[j] + p3[j]) / 2; for (int j = 0; j&lt;3; j++) v2[j] = (p1[j] + p4[j]) / 2; for (int j = 0; j&lt;3; j++) v3[j] = (p2[j] + p3[j]) / 2; for (int j = 0; j&lt;3; j++) v4[j] = (p2[j] + p4[j]) / 2; for (int j = 0; j&lt;3; j++) v5[j] = (p4[j] + p3[j]) / 2; DivideVertices(p1, v0, v1, v2, level - 1); DivideVertices(v0, p2, v3, v4, level - 1); DivideVertices(v1, v3, p3, v5, level - 1); DivideVertices(v2, v4, v5, p4, level - 1); &#125; else &#123; Tetrahedron(p1, p2, p3, p4); &#125;&#125;void Gasket(void)&#123; static Point3f Vertices[] = &#123; &#123; -1.f, -1.f, 0.5773f &#125;, &#123; 0.f, -1.f, -1.15475 &#125;, &#123; 1.0f, -1.0f, 0.5773f &#125;, &#123; 0.0f, 1.0f, 0.0f &#125;, &#125;; DivideVertices(Vertices[0], Vertices[1], Vertices[2], Vertices[3], gGasketLevel);&#125;]]></content>
      <tags>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[市场失灵与政府的不可或缺]]></title>
    <url>%2F2016%2F11%2F09%2F%E5%B8%82%E5%9C%BA%E5%A4%B1%E7%81%B5%E4%B8%8E%E6%94%BF%E5%BA%9C%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%88%96%E7%BC%BA%2F</url>
    <content type="text"><![CDATA[绪论亚当·斯密认为：经济参与者受利己心所驱动，而市场上这只看不见的手指引这种利己心去促进总体的经济福利。市场并不是万能的，它也有失效的时候，这时候需要政府进行干预。而政府在经济生活中扮演了一个重要的角色，它对经济生活有着巨大的影响力。它可以促进经济福利增长，也会减少总体经济福利。 政府与社会稳定动乱的时候，战火蔓延到的地方大都无法安稳的生产，贸易也会因为战火中断。另外如果普通家庭没有任何保障，那么生产服务也会停止。比如你生产的谷物可能会被全部征收，那么你可能就会放弃种庄稼。以上的问题除了要保证没有战乱外，还需要有强有力的政府维持社会治安，实施产权的制度，保障每个人控制稀缺资源的权利。只有政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能展现其魔力。 政府干预市场资源配置看不见的手再对稀缺资源分配时，未必完全符合政府预期，那么政府便会对市场进行干预。政府干预经济并改变资源配资的原因主要时两点：促进效率或促进平等。 效率平等目标看不见的手仅仅带来了效率上的产出，但是它并不负责消除经济福利分配的不平等。比如演员的工资高于实业者，这时由市场选择的结果。对于经济福利分配上的不平等，政府主要把行动放在公共政策上，比如征收所得税、社会福利保障，保障普通人享有基本的福利。 市场失灵的两种情况经济学家用市场失灵这个术语来指市场本身不能有效配置资源的情况。市场失灵主要有两个方面：外部性、市场势力。 外部性市场外部性是指一个人的行为对旁观者福利的影响。比较常见的是企业为了发展排放了污染，从而引起了周围居民的健康问题。出现这种问题的主要原因是企业利益和周围居民健康没有直接关系，那么企业在决策时，不会将排污带来的外部性考虑在内。对于外部性，政府可以通过政策将外部性转换成内部性，从而消除这些问题。比如可以通过收污染税，或者对环保措施进行补贴，这些政策将会使企业决策者在排放污染时权衡利益，从而减少污染排放或者升级技术减少排污。 市场势力市场势力是指单个人或企业（团体）不适当的影响市场价格的能力。通常情况下，市场通过竞争来约束个人或企业的利己行为，而市场势力正是因为这部分人逃脱了竞争的约束。比如某个人拥有了某种稀缺资源的完全控制权，而市场上没有任何可以替代的资源，那么这个人则不会受到残酷竞争的约束，且可以利用这来达到利己的目的。同样的，政府也是使用政策来解决这个问题。另外也从一个方面说明了重要资源应当由政府负责管理。 对于市场失灵的问题，其实个人也是能够解决的。科斯定理里说：私人经济主体可以解决他们之间的外部性问题，无论最初的权利如何分配，有关各方面总可以达成一种协议，在这种协议种，每个人的状况都可以变得更好，而且结果是有效率的。但是实际操作种会受到交易成本的约束，比如个人于企业较量中，个人属于弱势一方，如果不能承受高额交易成本，那么他可能选择默默承受污染带来的健康问题。所以一个好的政府，应当合理设计公共政策，最大程度的保障每个人的基本利益。这正是因为权利分配决定了经济福利的分配。 公共物品和公共资源这里需要先引入两个概念，排他性和竞争性。排他性指可以阻止人们使用这些物品。竞争性是指一个人使用某些物品会减少其他人对该物品的使用。通过这两个概念，可以将物品分为四类：私人物品、公共物品、公共资源、俱乐部物品。 公共物品既无排他性，也无竞争性的物品称为公共物品。这时一个非常好理解的概念，比如空气就属于公共物品，每个人都可以呼吸空气，没有人可以限制其他人呼吸的权利。按照市场原则，没有人可以从公共物品中获取利益（这里指的是除了使用物品需要支付的利益），所以没有人会主动提供公共物品。比如某地有危险，但是发现者没有任何利益驱动他去警告他人。而政府可以潜在的解决这个问题。如果政府确信一种公共物品的总利益大于成本，它就可以提供该公共物品，并用税收收入对其进行支付，从而可以使每个人的状况变好。如国防、基础研究就属于重要的抽象的公共物品。 公共资源公共物品是指具有竞争性但是没有排他性的物品。因为一个人使用公共资源就会减少其他人对它的享用，所以市场会驱使人们过度的消耗公共资源。此时政府就需要通过管制或者税收来减少公共资源的消耗问题。比如高速路有收费站进行收费，否则高速路会变得非常拥堵。 总结上面分为多个部分内容，但是它们都有一个共同的主题，即市场没有有效的配置资源。总之，市场并不是万能的，市场的最终目标是实现效率的最大化。我们所生活的世界是人组成的社会，除了效率的追求外，还有更多的于人相关的追求。这要求政府通过政策来约束市场，使之按照我们预期，向对人利益最大化的地方发展。]]></content>
      <tags>
        <tag>Economic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直方图均衡化]]></title>
    <url>%2F2016%2F11%2F09%2F%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%2F</url>
    <content type="text"><![CDATA[直方图均衡化直方图均衡化是图像处理领域中利用图像直方图进行对比度调整的方法。通过这种方法亮度可以更好的在直方图上分布。 灰度直方图是灰度级的函数，表示图像中具有某种灰度级的像素的个数，反映了图像中某种灰度出现的频率。 原理假设原始图像灰度级范围为[0,L-1],$r_k$为第k级灰度，图像中该像素出现的个数为$n_k$。则图像概率密度为： \begin{equation}P_{origin}(r_k)=\frac{n_k}{n},k \in \left[0,1,\ldots,L-1 \right]\end{equation} 其中n表示图像像素个数。 现在用t表示变换后的图像灰度，那么就是要求出函数$t=T(r)$使得$P_{target}(s_k)=c$，其中c为常数。首先变换函数T必须要满足下面条件： 在$ 0 \leq r \leq 1 $范围内为单调递增函数，保证图像的灰度级从黑到白的次序不变； 在$ 0 \leq r \leq 1 $内，有$ 0 \leq T(r) \leq 1 $，保证变换后的像素灰度在允许范围内； T的反函数$ T^-1 $同样应该满足上面两个条件； 通过概率统计的知识，我们容易得到关于$ P_{origin} $和$ P_{target} $之间的关系： \begin{equation} P_{target}(s) = P_{origin}(r) \left| \frac{dr}{ds} \right| \end{equation} 这里给出一个变换函数形式如下： \begin{equation} s=T(r)=(L-1) \int_{0}^{r}P_{origin}(\chi)d\chi \end{equation} 因为概率密度函数始终为正，且积分单调递增。当$r=L-1$的时候，$s=L-1$保证了灰度范围。满足上面的条件。下面把上诉函数代入密度函数关系式： \begin{equation}\frac{ds}{dr}=\frac{dT(r)}{dr}=(L-1) \left| \int_{0}^{r}P_{origin}(\chi)d\chi \right| = (L-1)P_{origin}(r)\end{equation} \begin{equation} P_{target}(s) = P_{origin}(r) \left| \frac{1}{(L-1)P_{origin}(r)} \right| = \frac{1}{L-1} \end{equation} 所以，函数T是我们预期的函数值，通过这个函数就可以对直方图进行均衡化。因为图像灰度为离散值，在实际处理前需要将将函数中积分形式等价替换为求和形式。]]></content>
      <tags>
        <tag>Digital Image Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对比度线性展宽和动态范围调整]]></title>
    <url>%2F2016%2F11%2F08%2F%E5%AF%B9%E6%AF%94%E5%BA%A6%E7%BA%BF%E6%80%A7%E5%B1%95%E5%AE%BD%E5%92%8C%E5%8A%A8%E6%80%81%E8%8C%83%E5%9B%B4%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[图像增强图像增强是指对图像的某些特征进行强调或尖锐化，以便于显示、观察或进一步分析与处理。 对比度对比度是指一幅图像中明暗区域最亮的白和最暗的黑之间不同亮度层级的测量，即一幅图像中灰度反差的大小。对比度越大，渐变层级就越多，灰度表现力就越丰富，图像越醒目；否则，图像清晰度越低，层次感就差。 对比度调整通过调整图像对比度，达到改善图像质量的目的。对比度调整也属于图像增强的一种。 对比度线性展宽对比度展宽实质上就是降低图像中不重要的信息的对比度，从而留出多余的空间，对重要的信息进行展宽。对比度线性展宽则是对对比度进行线性操作。 方法假设处理前后的图像都是 8 位图，即灰度范围的 [0, 255]。现在我们希望对图像中灰度级位 [a, b] 的范围进行展宽，使其变成 [a’, b’] {a’ &lt; a &amp;&amp; b’ &gt; b}。现在我们希望对图像中灰度级位进行展宽。 这里定义图片灰度函数： \begin{equation}gray=f\left(x, y\right)\end{equation} 其中 x, y 为像素位置，下面给出像素映射斜率： \begin{equation}K_1=\frac{a’}{a}\end{equation} 及 \begin{equation}K_2=\frac{b’-a’}{b-a}\end{equation} 及 \begin{equation}K_3=\frac{255-b’}{255-b}\end{equation} 通过上述公式来计算目标灰度函数 f&#39; : \begin{equation}f’ (x, y)=\begin{cases} &amp; K_1 \times f(x,y), \text{ if } 0 \leq f(x,y) &lt; a \\ &amp; K_2 \times (f(x,y)-a) + a’, \text{ if } a \leq f(x,y) &lt; b \\ &amp; K_3 \times (f(x,y)-b) + b’, \text{ if } b \leq f(x,y) &lt; 255\end{cases}\end{equation} 上面就是目标灰度函数，通过这个可以求出目标图像。 动态范围调整动态范围调整就是利用人眼的视觉特性，将动态范围进行压缩，将感兴趣的区域变化范围变大，从而达到改善图像质量的目的。因此，经过处理后的图形灰度分布与人眼视觉特性相匹配，能够获得较好的视觉质量。 方法动态范围调整 可以直接给出公式： \begin{equation}f’(x,y)=c \times \lg (1 + f(x,y))\end{equation} 其中 c 为增益系数。]]></content>
      <tags>
        <tag>Digital Image Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android asynchronized programming summary]]></title>
    <url>%2F2016%2F10%2F16%2FAndroid-asynchronized-programming-summary%2F</url>
    <content type="text"><![CDATA[开发过程中涉及到异步操作非常多，更确切的说不涉及的非常少。这里说一说我遇到的一些问题。 MessageQueue、Looper、Handler 与 ThreadThread 是最基本的调度单位，也是异步操作的基础。Thread 内有一个 MessageQueue，用与处理外部发送的 Message。Looper 则被 Thread 用于处理 MessageQueue, 并把 Message 发送给对应的 Handler。Handler 正是用来处理各种 Message，同时也是 Message 的发送者。 123456// 简单结构描述代码class thread &#123; void run &#123; mLooper.loop(mQueue); &#125;&#125; 在 Thread 内部，由 Looper 处理消息队列，而 Looper 中不断取出消息并发送。 12345678910class Looper &#123; void loop(MessageQueue queue) &#123; while (true) &#123; Message message = queue.pop(); if (message == null) return; message.handler.detachMessage(); &#125; &#125;&#125; Handler 同时是消息真正处理者，也是消息发送者。除了给当前 Thread 发送消息外，也能给其他 Thread 发送，这就奠定了多线程协作的基础。比如， Android 为我们提供了几种在 UI 线程中运行 Runable 对象的方法： Activity.runOnUiThread(Runnable) View.post(Runnable) View.postDelayed(Runnable, long) Handler Blocking Request &amp; AsyncTaskAndroid 无时无刻不进行了大量异步操作，当我们打开一个 App 时，后台正在请求网络数据，数据库操作和图片处理等。如果这些费时的工作全部像工厂里流水线一样执行，那么阻塞在某一个异步操作上都会导致其余部分无法进展任何工作即用户眼中的程序无响应。且等到上一个步骤完成后才能进行下一步操作，这一定不是一个好的用户体验。 现在假设某个 App 需要请求网络图片资源，那么应该这么写： 123456new Thread(new Runable() &#123; final Bitmap bitmap = getBitmapFromNet(url); runOnUiThread(new Runable() &#123; renderImageView(bitmap); &#125;);&#125;).run(); 这样写能够正确的工作，在下载期间，用户还可以与程序进行沟通。 不过，这一定不是最佳实践，实际生产环境中建议不要这么写（应该使用我们后面将会介绍的 AsyncTask 替代），下面会详细说明为什么。首先，Thread 的准备工作其实是非常耗时的。这里只展示了加载一涨图片，而实际应用中，可能由几十甚至上百张图片同时加载，而频繁的 new Thread 不仅会耗尽系统内存和计算资源，而且会增加上下文切换时间占用比。更好的方法是使用线程池。其次，异步嵌套逻辑不宜过长，更好的实践是将它封装起来。简单的例子就是”Callback Hell”。 因为上面的问题，Android 为我们提供了 AsyncTask 专门处理这种逻辑。所以在实际 Android 开发中，上面的代码应该写成下面的形式： 123456789new AsyncTask() &#123; protected Bitmap doInBackground(String... urls) &#123; return getBitmapFromNet(); &#125; protected void onPostExecute(Bitmap bitmap) &#123; renderImageView(bitmap); &#125;&#125; 当然，这里的代码只是演示作用，关于 AsyncTask 详细使用说明请看 SDK。 RxJava 和 异步流水线操作 RxJava 在 GitHub 主页上的自我介绍是 “a library for composing asynchronous and event-based programs using observable sequences for the Java VM”（一个在 Java VM 上使用可观测的序列来组成异步的、基于事件的程序的库）。RxJava 的本质可以压缩为异步这一个词。说到根上，它就是一个实现异步操作的库，而别的定语都是基于这之上的。 RxJava 的魅力在于能够在完成复杂的逻辑工作，并极大地保持代码整洁度。关于 RxJava 的学习请看这里。 异步流水线操作 - 其实我也不知道该怎么说明这种情况，所以就给它取了这么个名字。这个名词主要用来描述一些逻辑上是流水线执行，但是实现上涉及到异步操作比如文件操作、数据库操作还有就是网络请求。 假设你 Boss 让你每天登录网页写当天总结，几天后你再也无法忍受每天干些重复性的工作，所以你想写个程序来帮你做： 12// 你希望敲下面几个键就能完成工作fuck_work summary.txt 现在你要来实现这个程序。假设写总结的流程如下：登录 -&gt; 编辑 -&gt; 保存所以你写成了下面的代码: 123456789101112131415161718192021new AsyncTask() &#123; Object doInBackground() &#123; // Login &#125; void onPostExecute() &#123; new AsyncTask() &#123; Object doInBackground() &#123; // edit &#125; void onPostExecute() &#123; new AsyncTask() &#123; Object doInBackground() &#123; // save &#125; &#125;.run(); &#125; &#125;.run(); &#125;&#125;.run(); 上面的代码惨不忍睹，为了实现这种流水线操作你不得不忍受这种 “Callback Hell”。这里 RxJava 就可以大展身手了，你可以把代码写成下面的样子： 12345Observable.create() .flatMap(Task::login) .flatMap(Task::edit) .flatMap(Task::save) .subscribe(); 上述代码只是简单演示，不完整。可以看到 RxJava 可以非常简单明了的表达这种逻辑，这也是我非常喜欢它的原因。 Be cautious异步操作不像同步操作，它并不按照人逻辑思维来进行，所以在使用的时候应该多注意避免任何可能出现的逻辑顺序假设。 比如你正在写一个网络图片浏览页面，你准备使用 ListView 来做，所以你把代码写成了下面的样子： 123456789101112131415View getView(int pos, View c, ViewGroup parent) &#123; // ... imageView = ... new AsyncTask() &#123; Bitmap doInBackground() &#123; return getBitmapFromNet() &#125; onPostExecute(bitmap Bitmap) &#123; imageView.setBitmap(bitmap); &#125; &#125;.run(); // ... return c;&#125; 实际上上面包含了一种假想的逻辑顺序，即当图片加载完成时，ImageView 没有被挪作他用。然而用户在实际使用中，可能出现任何未知行为，其中某些行为比如稍稍滑动了一下界面，就可能导致图片显示到错误的位置上。 Last but not least, 实际生产中，如果有可用的三方库，还是不要自己造轮子吧。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linear Scan Register Allocation]]></title>
    <url>%2F2016%2F09%2F06%2FLinear-Scan-Register-Allocation%2F</url>
    <content type="text"><![CDATA[概述图着色和线性扫描算法是常见的寄存器分配算法。其中图着色分配效果最好，但是分配效率不高，而线性扫描算法虽然非最优解，但生成结果并不比图着色差多少，且效率远远高于图着色寄存器分配方法。 介绍线性扫描寄存器分配方法是对变量(VR)的活跃期间(Live Interval)为单位分配的。 原始分配方法原始的Poletto等人的论文中给出了线性扫描寄存器分配方法的最基本方式： 1、使用数据流分析方法计算出每个变量(VR)的活跃期间[start, end] 2、遍历整个区间序列进行寄存器分配，这里需要引入两个辅助集合，Active 和 Unhandled List，Unhandled List 表示还未进行分配的区间，以 start 递增的顺序组成链式序列。**Active 表示包含当前点且已经分配了寄存器的区间，其中的区间都按照 end 递增的方式排序。 3、当每次扫描到一个区间的时候，首先将 Active 集合中不再包含当前点的区间移除，并把其占用寄存器设置为未使用；判断还有没有空闲寄存器，如果有，则分配一个寄存器，并将该区间移入 Active 集合，否则将区间溢出(Spill)到栈上。溢出是指从 active 列表的最后一个区间和当前区间中选择一个，将其溢出到栈槽(stack slot)中，选择的方法就是看谁的结束位置更迟，该场景下也就是谁的结束位置更大。 123456789101112131415161718192021222324252627LinearScanRegisterAllocation active ←&#123;&#125; foreach live interval i, in order of increasing start point ExpireOldIntervals(i) if length(active)=R then SpillAtInterval(i) else register[i] ←a register removed from pool of free registers add i to active, sorted by increasing end pointExpireOldIntervals(i) foreach interval j in active, in order of increasing end point if endpoint[j] ≥ startpoint[i] then return remove j from active add register[j] to pool of free registersSpillAtInterval(i) spill ← last interval in active if endpoint[spill] &gt; endpoint[i] then register[i] ← register[spill] location[spill] ← new stack location remove spill from active add i to active, sorted by increasing end point else location[i] ← new stack location 其中需要注意的是 Spill 操作，其本质表示直接把该 VR 映射到 Stack Slot 中，并不为其分配寄存器，需要使用的时候才加载到寄存器。这中间可能有许多迷惑性的细节，具体可以参考Register allocation and spilling, the easy way?和Register Allocation in Compilers 这里以一个例子来讲解线性扫描方法： 12345a = 1 live &#123;a&#125;b = 1 live &#123;a b&#125;c = a + b live &#123;a b c&#125;d = 1 live &#123;b d a&#125;c = b + d + a live &#123;c&#125; 根据上面代码可以得到区间如下： 1a[1, 4], b[2, 3], c[3, 5], d[4, 4] 排序后得到序列 a b c d 以此分配寄存器，这里假设只有三个可用寄存器，a b c 各自占用一个寄存器，当开始分配 d 的时候，需要在 a 和 d 中选择一个溢出，此时溢出 d。 利用活跃区间间隙改进上面我们发现其实 c 的区间可以分为 [3, 3] 和 [5, 5] 两个小区间，如果可以利用这中间的空隙 (lifetime hole)，那么可以减少栈溢出次数。 下面就以论文2中使用的改进方法来理解，这种方法是在 CFG 形式下做的寄存器分配，所以会和上面的有点差别。 该方法同样需要计算活性区间，计算方法如下： 首先将 CFG 线性化，这里就涉及到为基本块(Basic Block)排序操作 123456789101112COMPUTE_BLOCK_ORDER append first block of method to work_list while work_list is not empty do BlockBegin b = pick and remove first block from work_list append b to blocks for each successor sux of b do decrement sux.incoming_forward_branches if sux.incoming_forward_branches = 0 then sort sux into work_list end if end for end while 为排好序的基本块中代码设置好操作数编号，这里每个操作数都加上了2，方便以后在两个操作数之间插入其他操着数 12345678NUMBER_OPERATIONS int next_id = 0 for each block b in blocks do for each operation op in b.operations do op.id = next_id next_id = next_id + 2 end for end for 计算 Local live set 12345678910111213141516171819COMPUTE_LOCAL_LIVE_SETS LIR_OpVisitState visitor // used for collecting all operands of an operation for each block b in blocks do b.live_gen = &#123; &#125; b.live_kill = &#123; &#125; for each operation op in b.operations do visitor.visit(op) for each virtual register opr in visitor.input_oprs do if opr ∉ block.live_kill then b.live_gen = b.live_gen ∪ &#123; opr &#125; end for for each virtual register opr in visitor.temp_oprs do b.live_kill = b.live_kill ∪ &#123; opr &#125; end for for each virtual register opr in visitor.output_oprs do b.live_kill = b.live_kill ∪ &#123; opr &#125; end for end for end for 计算 Global live set 12345678910COMPUTE_GLOBAL_LIVE_SETS do for each block b in blocks in reverse order do b.live_out = &#123; &#125; for each successor sux of b do b.live_out = b.live_out ∪ sux.live_in end for b.live_in = (b.live_out – b.live_kill) ∪ b.live_gen end for while change occurred in any live set 根据上面计算的集合建立活性区间 1234567891011121314151617181920212223242526272829BUILD_INTERVALS LIR_OpVisitState visitor; // visitor used for collecting all operands of an operation for each block b in blocks in reverse order do int block_from = b.first_op.id int block_to = b.last_op.id + 2 for each operand opr in b.live_out do intervals[opr].add_range(block_from, block_to) end for for each operation op in b.operations in reverse order do visitor.visit(op) if visitor.has_call then for each physical register reg do intervals[reg].add_range(op.id, op.id + 1) end for end if for each virtual or physical register opr in visitor.output_oprs do intervals[opr].first_range.from = op.id intervals[opr].add_use_pos(op.id, use_kind_for(op, opr)) end for for each virtual or physical register opr in visitor.temp_oprs do intervals[opr].add_range(op.id, op.id + 1) intervals[opr].add_use_pos(op.id, use_kind_for(op, opr)) end for for each virtual or physical register opr in visitor.input_oprs do intervals[opr].add_range(block_from, op.id) intervals[opr].add_use_pos(op.id, use_kind_for(op, opr)) end for end for end for 这样，建立的区间就包含 lifetime hole 信息，然后可以开始寄存器分配了。 1234567891011121314151617181920212223242526272829303132333435363738WALK_INTERVALS unhandled = list of intervals sorted by increasing start point active = &#123; &#125; inactive = &#123; &#125; // note: new intervals may be sorted into the unhandled list during // allocation when intervals are split while unhandled ≠ &#123; &#125; do current = pick and remove first interval from unhandled position = current.first_range.from // check for intervals in active that are expired or inactive for each interval it in active do if it.last_range.to &lt; position then move it from active to handled else if not it.covers(position) then move it from active to inactive end if end for // check for intervals in inactive that are expired or active for each interval it in inactive do if it.last_range.to &lt; position then move it from inactive to handled else if it.covers(position) then move it from inactive to active end if end for // find a register for current TRY_ALLOCATE_FREE_REG if allocation failed then ALLOCATE_BLOCKED_REG end if if current has a register assigned then add current to active end if end while 这里引入了一个新的集合 inactive 用来表示当前点落入了该 interval 的 lifetime hole 中。另外在算法中增加了 active 与 inactive 相互移动及移除部分代码。 1234567891011121314151617181920TRY_ALLOCATE_FREE_REG set free_pos of all physical registers to max_int for each interval it in active do set_free_pos(it, 0) end for for each interval it in inactive intersecting with current do set_free_pos(it, next intersection of it with current) end for reg = register with highest free_pos if free_pos[reg] = 0 then // allocation failed, no register available without spilling return false else if free_pos[reg] &gt; current.last_range.to then // register available for whole current assign register reg to interval current else // register available for first part of current assign register reg to interval current split current at optimal position before free_pos[reg] end if 在检查有没有空闲寄存器的时候也不能简单的判断，需要按照上面的条件，找出最合适的寄存器，如果没有找到，则要选择一个区间 Spill。 123456789101112131415161718192021222324252627282930ALLOCATE_BLOCKED_REG set use_pos and block_pos of all physical registers to max_int for each non-fixed interval it in active do set_use_pos(it, next usage of it after current.first_range.from) end for for each non-fixed interval it in inactive intersecting with current do set_use_pos(it, next usage of it after current.first_range.from) end for for each fixed interval it in active do set_block_pos(it, 0) end for for each fixed interval it in inactive intersecting with current do set_block_pos(it, next intersection of it with current) end for reg = register with highest use_pos if use_pos[reg] &lt; first usage of current then // all active and inactive intervals are used before current, so it is best to spill current itself assign spill slot to current split current at optimal position before first use position that requires a register else if block_pos[reg] &gt; current.last_range.to then // spilling made a register free for whole current assign register reg to interval current split and spill intersecting active and inactive intervals for reg else // spilling made a register free for first part of current assign register reg to interval current split current at optimal position before block_pos[reg] split and spill intersecting active and inactive intervals for reg end if 按照上面的方法选择一个寄存器并溢出，至此，基本方法都差不多了。这里还需要补充一下，当我们将 CFG 线性化的时候，有一些细节仍然需要处理： 12345678910B1:a = ...;if (...) THEN: a = ...;else ELSE: a = ...;ENDIF:use a 这里以一个简单例子说明为什么需要一步特殊的操作，假设 b1 中为 a 分配了一个寄存器，在 else 中，a 被 spill 到 stack slot 上，而 then 中仍然处于寄存器中，那么在 endif 中就出现了矛盾，a 在寄存器上还是在栈上？下面的算法用来解决这个问题。 123456789101112131415161718192021RESOLVE_DATA_FLOW MoveResolver resolver // used for ordering and inserting moves into the LIR for each block from in blocks do for each successor to of from do // collect all resolving moves necessary between the blocks from and to for each operand opr in to.live_in do Interval parent_interval = intervals[opr] Interval from_interval = parent_interval.child_at(from.last_op.id) Interval to_interval = parent_interval.child_at(to.first_op.id) if from_interval ≠ to_interval then // interval was split at the edge between the blocks from and to resolver.add_mapping(from_interval, to_interval) end if end for // the moves are inserted either at the end of block from or at the beginning of block to, // depending on the control flow resolver.find_insert_position(from, to) // insert all moves in correct order (without overwriting registers that are used later) resolver.resolve_mappings() end for end for SSA form 线性扫描寄存器分配SSA 形式的线性扫描的主体与上述类似， SSA 带来的优点就是能有效的降低单个 interval 的长度，这在 CISC 指令集计算机中会非常有效。同时，充分利用 SSA 形式的 IR 的稀疏特性，避免迭代式的 liveness analysis，有效的降低时间复杂度。 下面介绍基于上面算法改进的 SSA form 的寄存器分配算法： 该方法使用 SSA 上活性区间分析方法建立活性区间 123456789101112131415161718192021BUILDINTERVALS for each block b in reverse order do live = union of successor.liveIn for each successor of bfor each phi function phi of successors of b do live.add(phi.inputOf(b))for each opd in live do intervals[opd].addRange(b.from, b.to)for each operation op of b in reverse order do for each output operand opd of op do intervals[opd].setFrom(op.id) live.remove(opd) for each input operand opd of op do intervals[opd].addRange(b.from, op.id) live.add(opd)for each phi function phi of b do live.remove(phi.output)if b is loop header then loopEnd = last block of the loop starting at b for each opd in live do intervals[opd].addRange(b.from, loopEnd.to)b.liveIn = live 按照第二种分配方法分配寄存器 改进 Resolve 12345678910111213141516RESOLVE for each control flow edge from predecessor to successor do for each interval it live at begin of successor do if it starts at begin of successor then phi = phi function defining it opd = phi.inputOf(predecessor) if opd is a constant then moveFrom = opd else moveFrom = location of intervals[opd] at end of predecessor else moveFrom = location of it at end of predecessor moveTo = location of it at begin of successor if moveFrom ≠ moveTo then mapping.add(moveFrom, moveTo) mapping.orderAndInsertMoves() 本质思想一样，不过针对了 SSA form 做了特有优化。 Reference Linear Scan Register Allocation - MASSIMILIANO POLETTO Laboratory for Computer Science, MIT and VIVEK SARKAR IBM Thomas J. Watson Research Center Linear Scan Register Allocation for the Java HotSpot™ Client Compiler - Christian Wimmer Linear Scan Register Allocation on SSA Form - Christian Wimmer Michael Franz 寄存器分配问题？- 知乎]]></content>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Simple and Direction SSA Constriruction Algorithm]]></title>
    <url>%2F2016%2F08%2F18%2FSimple-and-Direction-SSA-Constriruction-Algorithm%2F</url>
    <content type="text"><![CDATA[前面讲到了传统的 SSA 构造方式，直接从线性 IR 构造 SSA。而本文将介绍另外的方法允许从 AST、Bytecode 甚至源代码直接构造 SSA 形式。 LLVM 中的方法LLVM ir 为 SSA 形式，如果用户手工翻译 AST，那么只有在翻译的时候直接生成 SSA 形式中间代码。不过 LLVM 给用户留下了一个后门，可以将变量全部表达成为 Memory 形式，通过指针操作。然后通过 Mem2Reg pass 转换成 SSA 形式。 这里不介绍翻译时候的方式，仅仅介绍一下 Mem2Reg pass。下面的代码抄自 LLVM 中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 遍历指令序列找到 allocafor (Instruction instr : instructions)&#123; if (isa&lt;Alloca&gt;(instr)) allocas.push_back(instr);&#125;// 一个一个的提升 alloca 指令for (Alloca alloca : allocas)&#123; // 判断是否可以提升 if (!alloca.isAllocaPromoteable()) continue; // 跳过无使用者的alloca指令 if (alloca.user_begin() == alloca.user_end()) continue; // 收集alloca指令的使用，定义信息 info.analyzeAlloca(alloca); // 下面的函数，对只有一次定义（即只有一条 store 指令）的 alloca 进行优化 // 把所有的 load 指令全部用定义时保存的 value 替换 if (info.definingBlocks.size() == 1) rewriteSingleStoreAlloca(alloca, info); // 下面的代码仅仅对只在一个基本块中使用和定义的alloca指令进行优化 if (info.onlyUsedOneBlock) promoteSingleBlockAlloca(alloca, info); // 插入无参数的Phi函数，使用标准的基于支配边界的算法，其中使用DJ图的方式进行了优化 determineInsertionPoint(alloca, allocaNum, info); // 使用 IDF 和标准 ssa 构造算法提升 alloca ，决定那些需要插入 Phi 函数 DefBlocks.insert(Info.DefiningBlocks.begin(), Info.DefiningBlocks.end()); ComputeLiveInBlocks(AI, Info, DefBlocks, LiveInBlocks); IDF.setLiveInBlocks(LiveInBlocks); IDF.setDefiningBlocks(DefBlocks); IDF.calculate(PHIBlocks); // 执行 SSA 重命名算法，并插入 Phi 节点 RenamePassWorkList.emplace_back(&amp;F.front(), nullptr, std::move(Values)); do &#123; // RenamePass may add new worklist entries. RenamePass(RPD.BB, RPD.Pred, RPD.Values, RenamePassWorkList); &#125; while (!RenamePassWorkList.empty()); // 移除 allocas for (unsigned i = 0, e = Allocas.size(); i != e; ++i) &#123; Instruction *A = Allocas[i]; A-&gt;replaceAllUsesWith(UndefValue::get(A-&gt;getType())); A-&gt;eraseFromParent(); &#125; // 最后执行一趟消除平凡Phi函数的操作， while (eliminatedAPHI) &#123; // if the phi merges one value and/or undefs, get the value if ((V = simplifyInstruction(phi, DT)) != null) &#123; phi.replaceAllUsesWith(V); phi.eraseFromBasicBlock(); newPhiNodes.remove(entity); eliminatedAPHI = true; continue; &#125; &#125;&#125; 直接构造这种方法来源于论文： Simple and Eﬃcient Construction of Static Single Assignment FormMatthias Braun1, Sebastian Buchwald1, Sebastian Hack2, Roland Leißa2, Christoph Mallon2, and Andreas Zwinkau1 下面介绍该构造方法。 Local Value Numbering这部分操作以基本块为单位，所以生成的 IR 必须为 CFG 形式。CFG 形式能够非常容易的从源代码构造，这里略过。 该方法按照程序执行的顺序处理所有的表达式，并且在变量和其定义表达式之间建立映射。也就是说当遇到对变量赋值时，把赋值符号右边的表达式最为当前变量的定义。当一个变量被访问的时候，我们就查找其定义。上述的过程就叫做 local value numbering。 如果一个基本块中完成了 local value numbering，这个基本块就被称为 filled。 只有一个基本块完成了 local value numbering 后，才能够添加后继基本块。这个属性会在处理 incomplete CFGs 的时候使用。 Algorithm 1: Implementation of local value numbering 123456789writeVariable(variable, block, value): currentDef[variable][block] ← value readVariable(variable, block): if currentDef[variable] contains block: # local value numbering return currentDef[variable][block] # global value numbering return readVariableRecursive(variable, block) Global Value Numbering正如上面算法展示，当读取变量定义的时候，如果当前基本块没有变量的定义，那么只能递归地查找其前驱基本块。递归地查找算法如下： 如果基本块只有一个前驱，仅仅在其前驱中查找定义，否则，构造一个 φ 函数，将其所有前驱中定义加入该 φ 函数，并将该 φ 函数作为该基本块的定义。 需要注意的是该查找方式可能导致循环查找，比如在循环体中查找定义。为了避免程序死循环，在查找前先为该基本块建立一个没有任何操作数的 φ 函数作为其定义。 Algorithm 2: Implementation of global value numbering 123456789101112131415161718192021readVariableRecursive(variable, block): if block not in sealedBlocks: # Incomplete CFG val ← new Phi(block) incompletePhis[block][variable] ← val else if |block.preds| = 1: # Optimize the common case of one predecessor: No phi needed val ← readVariable(variable, block.preds[0]) else : # Break potential cycles with operandless phi val ← new Phi(block) writeVariable(variable, block, val) val ← addPhiOperands(variable, val) writeVariable(variable, block, val) return valaddPhiOperands(variable, phi): # Determine operands from predecessors for pred in phi.block.preds: phi.appendOperand(readVariable(variable, pred)) return tryRemoveTrivialPhi(phi) 这种查找方式可能导致多余的 φ 函数，称为 trivial 。如果一个 φ 函数引用了自身和另一个定义，那么就叫做 trivial φ 函数。比如有 a.1 = φ&lt;a.1, a.0&gt;。这个 φ 函数完全可以被另一个定义给替换。还有一种特殊的情况，φ 函数仅仅引用了自身，这种情况仅仅发生在不可达或者开始基本块，这时用一个 Undef 值代替。 需要注意的是如果我们替换了 trivial φ 函数，可能导致引用该 φ 函数的值也变成 trivial φ 函数，所以还需要递归地进行替换操作。 Algorithm 3: Detect and recursively remove a trivial φ function 123456789101112131415161718192021222324tryRemoveTrivialPhi(phi): same ← None for op in phi.operands: if op = same || op = phi: # Unique value or self−reference continue if same = None: # The phi merges at least two values: not trivial return phi same ← op if same = None: # The phi is unreachable or in the start block same ← new Undef() # Remember all users except the phi itself users ← phi.users.remove(phi) # Reroute all uses of phi to same and remove phi phi .replaceBy(same) # Try to recursively remove all phi users, # which might have become trivial for use in users: if use is a Phi: tryRemoveTrivialPhi(use) return same 上述操作目前还无法处理未完成的循环，比方说如果循环体未处理完，那么循环头部分仍然有可能加入新的前驱，这就是前面引用到的 Incomplete CFGs。 Handling Incomplete CFGs如果一个基本块不会再加入任何前驱结点，那么就可以称为 sealed 基本块。因为只有 filled 基本块拥有后继，所以前驱基本块必须是 filled。 filled 基本块可以为其后继提供变量定义，而 sealed 基本块可能会从其前驱中查找变量定义。 Algorithm 4: Handling incomplete CFGs 1234sealBlock(block): for variable in incompletePhis[block]: addPhiOperands(variable, incompletePhis[block][variable]) sealedBlocks.add(block) 如果在一个属于 filled 且非 sealed 基本块中查找变量定义呢？如前面算法2提到的，对于非 sealed 基本块，建立一个 函数并保存在 incompletePhis 中为其后继提供定义。当该非 sealed 基本块不会有新的前驱加入时，对其进行 seal 操作。 seal 操作会对该基本块的所有 incompletePhis 进行处理，完成处理后将该基本块加入 sealed 集合。 结束通过上述四个算法，能够完成 SSA 形式构造，当然，还有进一步的优化这里就不讲了，有兴趣可以直接看论文。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Traditional SSA Construction Algorithm]]></title>
    <url>%2F2016%2F08%2F17%2FTraditional-SSA-Construction-Algorithm%2F</url>
    <content type="text"><![CDATA[由于 SSA (static single assignment form) 能够使得程序分析变得更方便快捷，已经被许多编译器用于 IR (intermediate representations)。 SSA是什么？SSA 即静态单赋值，之所以称之为单赋值，是因为每个名字在SSA中仅被赋值一次。 传统编译器流程在传统的编译器中，parse 过后通常生成 AST，并将 AST 转换为线性 IR, 并在这个基础上构造 SSA，然后进行寄存器分配生成目标代码等。 线性 IR 到 SSA 构造具体步骤这里介绍本文剩下部分的内容–构造 SSA from。 遍历 IR 构造 CFG 计算支配边界 确定 Phi 函数位置 变量重命名 遍历 IR 构造 CFGCFG 由基本块组成，所以首先确定基本块： 基本块算法：a) 找基本块入口源代码的首行或者转移代码（有条件和无条件）或者转移代码的下一行b) 基本块构造：通过入口点开始，将其组成各自的基本块。基本块语句序列的特征：从不包含它本身的进入点到其他进入点或者到某条转移语句或者到某条停止语句c) 如果有语句不在任一基本块中，那么它为 ”死代码“，删除 当确定基本块后，紧接着构造 CFG: 控制流图构造如果在一个有序代码中，基本块 B2 跟在 B1 后，那么产生一个由 B1 到 B2 的有向边。a) 有跳转点。这个点从 B1 的结束点跳到 B2 的开始点b) 无跳转点（有序代码中），B2 跟在 B1 后，且 B1 的结束点不是无条件跳转语句 计算支配边界放置 Phi 函数的关键在于了解在每个汇合点处究竟哪个变量需要 Phi 函数。在进一步讲解之前，需要引入支配的概念。 支配集合假设对于任意 CFG 图，Bi 表示第 i 个基本块，那么对于任意的 Dom(Bi) 表示从 CFG 入口开始遍历，到达 Bi 基本块中每条路径都包含的公共基本块。计算算法如下 123456789101112131415Dom(0) = &#123; 0 &#125;for i in range(1, n): Dom(i) = Nchanged = truewhile changed: changed = false for i in range(1, n): for preds j in i: temp = temp ∩ Dom(j) temp = &#123; i &#125; ∪ temp if temp != Dom(i): Dom(i) = temp changed = true 支配者树而对于基本块 Bi 中的定义，当值到达某个节点 m 时，仅在满足下述两个条件的汇合点才需要插入对应的 Phi 函数： Bi 支配 Bm 的一个前驱 Bi 并不严格支配 Bm 这里把相对于 Bi 具有这种性质的结点 Bm 的集合称为 Bi 的支配边界，记作 DF(n)。 而 Bi 严格支配的结点 Dom(Bi)-Bi , 则该集合中与 Bi 最接近的结点称为 Bi 的直接支配结点，记作 IDom(Bi)。 支配边界下面的算法用于计算流图支配边界： 123456789for block in CFG: DF(n) = &#123;&#125;for block in CFG: if block.predecessors.size() &gt; 1: for p in block.predecessors: runner = p while runner != IDom(block): DF(runner) = DF(runner) ∪ &#123; n &#125; runner = IDom(runner) 确定 Phi 函数位置有了支配边界之后，编译器就可以更精确地判断何处可能需要 Phi 函数。其基本思想很简单，在基本块 Bi 中对 x 定义，则要求在 DF(b) 集合包含的每个结点起始处都放置一个对应的 Phi 函数。只在单个基本块中活动的变量，绝对不会出现与之相应的活动 Phi 函数。所以可以计算跨多个程序块的活动变量名的集合，该集合被称为全局名字结合。它可以对该集合中的名字插入 Phi 函数，而忽略不在该集合中的名字。下面的算法用于计算全局名字集合： 12345678910111213Globals = &#123;&#125;Initialize all the blocks sets to &#123;&#125;for each block b in CFG: VarKill = &#123;&#125; for each operation i in b in order assume that opi is &quot;x = y op z&quot; if y not belong VarKill: Globals = Globals ∪ &#123; y &#125; if z not belong VarKill: Globals = Globals ∪ &#123; z &#125; VarKill = VarKill ∪ &#123; x &#125; blocks(x) = blocks(x) ∪ &#123; b &#125; 下面的算法用于重写代码： 123456for each name x in Globals: WorkList = blocks(x) for each block b in WorkList: if d has no phi-function for x: insert a phi-function for x in d WorkList = WorkList ∪ &#123; d &#125; 变量重命名在最终的静态单赋值形式中，每个全局名字都变为一个基本名，而对该基本名的各个定义则通过添加数字下标来区分，该算法如下： 1234567891011121314151617181920212223242526272829for each global name i: counter[i] = 0 stack[i] = 0Rename(block0)NewName(n): i = counter[n] counter[n] = counter[n] + 1 push i onto stack[n] return &quot;ni&quot;Rename(b): for each phi-function in b &quot;x = phi(...)&quot;: rewrite x as NewName(x) for each operation &quot;x = y op z&quot; in b: rewrite y with subscript top(stack[y]) rewrite z with subscript top(stack[z]) rewrite x as NewName(x) for each successor of b in the CFG: fill in phi-function parameters for each successor s of b in the dominator tree: Rename(s) for each operation &quot;x = y op z&quot; in b and each phi-function &quot;x = phi(...)&quot;: pop(stack[x]) Phi function Elimination消除 Phi 函数主要有两步操作。首先编译器可以保持 SSA 名字空间原样不动，将每个 Phi 函数替换为一组复制操作并放入前驱中。比如对于 x = phi(i, j), 编译器应该在传入 i 的基本块末尾加上 x = i, 在传入 j 的基本块末尾加上 x = j： 1234567891011121314151617181920B1: x.1 = a goto B3:B2: x.2 = b goto B3:B3: x.3 = phi(x.1, x.2) c = x.3转换后B1: x.1 = a x.3 = x.1 goto B3B2: x.2 = b x.3 = x.2B3: c = x.3 当当前基本块 B1 某一个前驱结点 B2 有多个后继结点时 (B2, B1)，无法应用上述方法，因为添加的复制操作不仅会流入当前基本块，也会流入其他后继结点。为了弥补这种问题，编译器可以拆分 (B2, B1) 在中间插入一个新的基本块，将所有复制操作放入新的基本块中。这里 (B2, B1) 这样的边称为关键边。 在转换过程中出现的大部分问题都可以通过这种变换解决，但还有两个更为微妙的问题：1、丢失复制，是因为激进的程序变换与不可拆分的关键边共同引起的；2、交换，是因为某些激进的程序变换与静态单赋值形式的详细定义之间的交互所致。这里不做介绍，有兴趣可以参考 reference。 参考[1] Efficiently Computing Static Single Assignment Form and the Control Dependence Graph RON CYTRON, JEANNE FERRANTE, BARRY K. ROSEN, and MARK N. WEGMAN IBM Research Division and F. KENNETH ZADECK Brown University [2] Engineering a Compiler, Second [3] llvm的reg2mem pass做了哪些事情？ [4] Phi node 是如何实现它的功能的？]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clang Source Code Analysis (3)]]></title>
    <url>%2F2016%2F07%2F09%2FClang-Source-Code-Analysis-3%2F</url>
    <content type="text"><![CDATA[在 ParseAST 中，前面通过 P.ParseTopLevelDecl(ADecl) 对源代码进行了分析，紧接着就是调用 HandleTopLevelDecl(ADecl.get()) 进行处理。 代码生成的部分由 HandleTopLevelDecl 负责，而 ASTConsumer 是一个虚基类，所以需要从其他地方入手。这里以 ASTConsumer 为切入点，找到创建位置。 假设我们使用的是 –emit-llvm 模式，而 EmitLLVMAction 继承自 CodeGenAction。在 CodeGenAction 中找到创建 ASTConsumer 的 CreateASTConsumer。 1234567891011std::unique_ptr&lt;ASTConsumer&gt;CodeGenAction::CreateASTConsumer(CompilerInstance &amp;CI, StringRef InFile) &#123; // ... std::unique_ptr&lt;BackendConsumer&gt; Result(new BackendConsumer( BA, CI.getDiagnostics(), CI.getHeaderSearchOpts(), CI.getPreprocessorOpts(), CI.getCodeGenOpts(), CI.getTargetOpts(), CI.getLangOpts(), CI.getFrontendOpts().ShowTimers, InFile, LinkModules, OS, *VMContext, CoverageInfo)); BEConsumer = Result.get(); return std::move(Result);&#125; 实际上是一个 BackendConsumer 实例。另外观察 CodeGenAction::ExecuteAction : 123456789void CodeGenAction::ExecuteAction() &#123; // If this is an IR file, we have to treat it specially. if (getCurrentFileKind() == IK_LLVM_IR) &#123; // ... &#125; // Otherwise follow the normal AST path. this-&gt;ASTFrontendAction::ExecuteAction();&#125; 发现其实际上是执行的 ASTFrontendAction::ExecuteAction，所以原来分析的部分仍然可以使用。现在，找到 BackendConsumer::HandleTopLevelDecl： 1234bool HandleTopLevelDecl(DeclGroupRef D) override &#123; Gen-&gt;HandleTopLevelDecl(D); return true;&#125; 这里进一步调用 CodeGenerator::HandleTopLevelDecl，而 Gen 由 CreateLLVMCodeGen 得到： 12345678CodeGenerator *clang::CreateLLVMCodeGen( DiagnosticsEngine &amp;Diags, const std::string &amp;ModuleName, const HeaderSearchOptions &amp;HeaderSearchOpts, const PreprocessorOptions &amp;PreprocessorOpts, const CodeGenOptions &amp;CGO, llvm::LLVMContext &amp;C, CoverageSourceInfo *CoverageInfo) &#123; return new CodeGeneratorImpl(Diags, ModuleName, HeaderSearchOpts, PreprocessorOpts, CGO, C, CoverageInfo);&#125; 所以，Gen 实际上是一个 CodeGeneratorImpl 实例。 123456789101112bool HandleTopLevelDecl(DeclGroupRef DG) override &#123; if (Diags.hasErrorOccurred()) return true; HandlingTopLevelDeclRAII HandlingDecl(*this); // Make sure to emit all elements of a Decl. for (DeclGroupRef::iterator I = DG.begin(), E = DG.end(); I != E; ++I) Builder-&gt;EmitTopLevelDecl(*I); return true;&#125; 上面是 CodeGeneratorImpl::HandleTopLevelDecl 部分，这里对每个声明部分调用 EmitTopLevelDecl 处理。Builder 是 CodeGenModule 类对象。 12345678910111213141516171819202122232425262728293031323334void CodeGenModule::EmitTopLevelDecl(Decl *D) &#123; // Ignore dependent declarations. if (D-&gt;getDeclContext() &amp;&amp; D-&gt;getDeclContext()-&gt;isDependentContext()) return; switch (D-&gt;getKind()) &#123; case Decl::CXXConversion: case Decl::CXXMethod: case Decl::Function: // Skip function templates if (cast&lt;FunctionDecl&gt;(D)-&gt;getDescribedFunctionTemplate() || cast&lt;FunctionDecl&gt;(D)-&gt;isLateTemplateParsed()) return; EmitGlobal(cast&lt;FunctionDecl&gt;(D)); // Always provide some coverage mapping // even for the functions that aren&apos;t emitted. AddDeferredUnusedCoverageMapping(D); break; case Decl::Var: // Skip variable templates if (cast&lt;VarDecl&gt;(D)-&gt;getDescribedVarTemplate()) return; case Decl::VarTemplateSpecialization: EmitGlobal(cast&lt;VarDecl&gt;(D)); break; // Indirect fields from global anonymous structs and unions can be // ignored; only the actual variable requires IR gen support. case Decl::IndirectField: break; &#125;&#125; 在 CodeGenModule::EmitTopLevelDecl 中，可以发现对函数和变量等而言，调用的其实是 EmitGlobal。跟进 EmitGlobal，发现最终的调用实际上是 EmitGlobalDefinition。 123456789101112void CodeGenModule::EmitGlobalDefinition(GlobalDecl GD, llvm::GlobalValue *GV) &#123; const auto *D = cast&lt;ValueDecl&gt;(GD.getDecl()); if (isa&lt;FunctionDecl&gt;(D)) &#123; return EmitGlobalFunctionDefinition(GD, GV); &#125; if (const auto *VD = dyn_cast&lt;VarDecl&gt;(D)) return EmitGlobalVarDefinition(VD, !VD-&gt;hasDefinition()); llvm_unreachable(&quot;Invalid argument to EmitGlobalDefinition()&quot;);&#125; 可以发现最终的调用分别为 EmitGlobalFunctionDefinition 和 EmitGlobalVarDefinition。这两个函数调用很明显，一个是函数定义，一个是变量定义。 1234567891011121314151617181920212223242526272829303132void CodeGenModule::EmitGlobalFunctionDefinition(GlobalDecl GD, llvm::GlobalValue *GV) &#123; const auto *D = cast&lt;FunctionDecl&gt;(GD.getDecl()); // Compute the function info and LLVM type. const CGFunctionInfo &amp;FI = getTypes().arrangeGlobalDeclaration(GD); llvm::FunctionType *Ty = getTypes().GetFunctionType(FI); // Get or create the prototype for the function. if (!GV || (GV-&gt;getType()-&gt;getElementType() != Ty)) GV = cast&lt;llvm::GlobalValue&gt;(GetAddrOfFunction(GD, Ty, /*ForVTable=*/false, /*DontDefer=*/true, /*IsForDefinition=*/true)); // Already emitted. if (!GV-&gt;isDeclaration()) return; // We need to set linkage and visibility on the function before // generating code for it because various parts of IR generation // want to propagate this information down (e.g. to local static // declarations). auto *Fn = cast&lt;llvm::Function&gt;(GV); setFunctionLinkage(GD, Fn); setFunctionDLLStorageClass(GD, Fn); // FIXME: this is redundant with part of setFunctionDefinitionAttributes setGlobalVisibility(Fn, D); // ... CodeGenFunction(*this).GenerateCode(D, Fn, FI); // ...&#125; 这里先产生函数签名，最后调用 CodeGenFunction::GenerateCode 生成代码。 具体的内容就不继续分析下去了，到这里为止，已经梳理了一边 Clang 执行流程，整理出一个具体框架。还有很多深入的等待继续挖掘。]]></content>
      <categories>
        <category>Clang 源码分析</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clang Source Code Analysis (2)]]></title>
    <url>%2F2016%2F07%2F01%2FClang-Source-Code-Analysis-2%2F</url>
    <content type="text"><![CDATA[前面部分分析了初始化流程，紧接着分析的是 Parse 部分。 所有 Action 的基类是 FrontendAction，在 FrontendAction 的 Execute 中发现： 12345678910111213bool FrontendAction::Execute() &#123; CompilerInstance &amp;CI = getCompilerInstance(); if (CI.hasFrontendTimer()) &#123; llvm::TimeRegion Timer(CI.getFrontendTimer()); ExecuteAction(); &#125; else ExecuteAction(); // .... return true;&#125; 流程转入了 ExecuteAction 中，目前的 Act 是 EmitLLVMAction： 12345class EmitLLVMAction : public CodeGenAction &#123; virtual void anchor();public: EmitLLVMAction(llvm::LLVMContext *_VMContext = nullptr);&#125;; 实际上 EmitLLVMAction 只是 CodeGenAction 的一个子类。所以应该在 CodeGenAction 中找 Execute 的逻辑。 123456789void CodeGenAction::ExecuteAction() &#123; // If this is an IR file, we have to treat it specially. if (getCurrentFileKind() == IK_LLVM_IR) &#123; // other codes. &#125; // Otherwise follow the normal AST path. this-&gt;ASTFrontendAction::ExecuteAction();&#125; 所以在 CodeGenAction::ExecuteAction 中，直接使用了 ASTFrontendAction::ExecuteAction 的实现。找到 ASTFrontendAction 对应的 ExecuteAction： 1234void ASTFrontendAction::ExecuteAction() &#123; ParseAST(CI.getSema(), CI.getFrontendOpts().ShowStats, CI.getFrontendOpts().SkipFunctionBodies);&#125; 这里截取了重要的部分代码。跟踪 ParseAST，截取代码如下： 1234567891011121314151617181920212223242526272829void clang::ParseAST(Sema &amp;S, bool PrintStats, bool SkipFunctionBodies) &#123; ASTConsumer *Consumer = &amp;S.getASTConsumer(); std::unique_ptr&lt;Parser&gt; ParseOP( new Parser(S.getPreprocessor(), S, SkipFunctionBodies)); Parser &amp;P = *ParseOP.get(); S.getPreprocessor().EnterMainSourceFile(); P.Initialize(); if (P.ParseTopLevelDecl(ADecl)) &#123; if (!External &amp;&amp; !S.getLangOpts().CPlusPlus) P.Diag(diag::ext_empty_translation_unit); &#125; else &#123; do &#123; // If we got a null return and something *was* parsed, ignore it. This // is due to a top-level semicolon, an action override, or a parse error // skipping something. if (ADecl &amp;&amp; !Consumer-&gt;HandleTopLevelDecl(ADecl.get())) return; &#125; while (!P.ParseTopLevelDecl(ADecl)); &#125; // Process any TopLevelDecls generated by #pragma weak. for (Decl *D : S.WeakTopLevelDecls()) Consumer-&gt;HandleTopLevelDecl(DeclGroupRef(D)); Consumer-&gt;HandleTranslationUnit(S.getASTContext());&#125; Parse 通过 ParseTopLevelDecl 得到 Decl ，然后通过 ASTConsumer 的 HandleTopLevelDecl 处理。忽略其他现在并不关心的部分，在 ParseTopLevelDecl 内部调用 ParseExternalDeclaration 开始。而 ParseExternalDeclaration 内部，我们只关心下面一行代码： 1return ParseDeclarationOrFunctionDefinition(attrs, DS); 这里处理声明或者函数定义，内部有一个 Internal 包含。这其中分为两部分，一部分是 ParseDeclarationSpecifiers；另一部分是最后的 ParseDeclGroup。 第一部分用于获取类型说明符，第二部分则是具体声明部分，这里重点看第二部分： 1234567891011121314151617181920212223242526272829Parser::DeclGroupPtrTy Parser::ParseDeclGroup(ParsingDeclSpec &amp;DS, unsigned Context, SourceLocation *DeclEnd, ForRangeInit *FRI) &#123; // Parse the first declarator. ParsingDeclarator D(*this, DS, static_cast&lt;Declarator::TheContext&gt;(Context)); ParseDeclarator(D); // Check to see if we have a function *definition* which must have a body. if (D.isFunctionDeclarator() &amp;&amp; !isDeclarationAfterDeclarator()) &#123; Decl *TheDecl = ParseFunctionDefinition(D, ParsedTemplateInfo(), &amp;LateParsedAttrs); return Actions.ConvertDeclToDeclGroup(TheDecl); &#125; SmallVector&lt;Decl *, 8&gt; DeclsInGroup; Decl *FirstDecl = ParseDeclarationAfterDeclaratorAndAttributes( D, ParsedTemplateInfo(), FRI); // If we don&apos;t have a comma, it is either the end of the list (a &apos;;&apos;) or an // error, bail out. SourceLocation CommaLoc; while (TryConsumeToken(tok::comma, CommaLoc)) &#123; ParseDeclarator(D); if (!D.isInvalidType()) &#123; Decl *ThisDecl = ParseDeclarationAfterDeclarator(D); &#125; &#125;&#125; ParseDeclGroup 的结构大致如上，首先使用 ParseDeclarator 获取一个声明，比如 int i; 这里得到的就是 i，然后判断是否紧接 ()，如果是，则调用 ParseFunctionDefinition 分析函数定义，否则循环调用 ParseDeclarator 获取所有声明的变量。 对于声明而言，需要调用 ParseDeclarationAfterDeclarator 将类型与 declarator 结合，形成一个完整的声明。ParseDeclarationAfterDeclarator 中调用了 ParseDeclarationAfterDeclaratorAndAttributes, 而 ParseDeclarationAfterDeclaratorAndAttributes 中实际调用了 Actions.ActOnDeclarator，ActOnDeclarator 实际调用了 HandleDeclarator。 在 HandleDeclarator 中，实际的工作有三个，首先调用 GetTypeForDeclarator; 得到类型信息，因为各个类型实际上只有一个实例，所以这里需要映射过程。其次调用以下几个中的某一个: 123ActOnTypedefDeclaratorActOnFunctionDeclaratorActOnVariableDeclarator 最后，调用 PushOnScopeChains 将声明存起来。保存起来的 declarator 的信息可以用于处理下一次遇到 declarator 判断是否符合语法。 现在回头看 ParseFunctionDefinition 部分。节选代码如下： 12345678910111213141516Decl *Parser::ParseFunctionDefinition(ParsingDeclarator &amp;D, const ParsedTemplateInfo &amp;TemplateInfo, LateParsedAttrList *LateParsedAttrs) &#123; // Enter a scope for the function body. ParseScope BodyScope(this, Scope::FnScope|Scope::DeclScope); // Tell the actions module that we have entered a function definition with the // specified Declarator for the function. Decl *Res = Actions.ActOnStartOfFunctionDef(getCurScope(), D, TemplateInfo.TemplateParams ? *TemplateInfo.TemplateParams : MultiTemplateParamsArg(), &amp;SkipBody); return ParseFunctionStatementBody(Res, BodyScope);&#125; 首先进入函数作用域，执行相应的 Action，最后调用 ParseFunctionStatementBody 开始解析函数部分。 123456789Decl *Parser::ParseFunctionStatementBody(Decl *Decl, ParseScope &amp;BodyScope) &#123; // Do not enter a scope for the brace, as the arguments are in the same scope // (the function body) as the body itself. Instead, just read the statement // list and put it into a CompoundStmt for safe keeping. StmtResult FnBody(ParseCompoundStatementBody()); BodyScope.Exit(); return Actions.ActOnFinishFunctionBody(Decl, FnBody.get());&#125; ParseFunctionStatementBody 中最重要的一句是: 1StmtResult FnBody(ParseCompoundStatementBody()); 然后就是退出作用域，执行相应的 Action。继续跟进 ParseCompoundStatementBody。 在 ParseCompoundStatementBody 中，暂时忽略 kw__extension__ 的情况，于是，实际的调用为 ParseStatementOrDeclaration，其中又调用了 ParseStatementOrDeclarationAfterAttributes，这个函数就是正式进行分析的代码部分： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899StmtResultParser::ParseStatementOrDeclarationAfterAttributes(StmtVector &amp;Stmts, AllowedContsructsKind Allowed, SourceLocation *TrailingElseLoc, ParsedAttributesWithRange &amp;Attrs) &#123; switch (Kind) &#123; case tok::identifier: &#123; Token Next = NextToken(); if (Next.is(tok::colon)) &#123; // C99 6.8.1: labeled-statement // identifier &apos;:&apos; statement return ParseLabeledStatement(Attrs); &#125; // Look up the identifier, and typo-correct it to a keyword if it&apos;s not // found. if (Next.isNot(tok::coloncolon)) &#123; // Try to limit which sets of keywords should be included in typo // correction based on what the next token is. if (TryAnnotateName(/*IsAddressOfOperand*/ false, llvm::make_unique&lt;StatementFilterCCC&gt;(Next)) == ANK_Error) &#123; // Handle errors here by skipping up to the next semicolon or &apos;&#125;&apos;, and // eat the semicolon if that&apos;s what stopped us. SkipUntil(tok::r_brace, StopAtSemi | StopBeforeMatch); if (Tok.is(tok::semi)) ConsumeToken(); return StmtError(); &#125; // If the identifier was typo-corrected, try again. if (Tok.isNot(tok::identifier)) goto Retry; &#125; // Fall through &#125; default: &#123; if ((getLangOpts().CPlusPlus || Allowed == ACK_Any) &amp;&amp; isDeclarationStatement()) &#123; SourceLocation DeclStart = Tok.getLocation(), DeclEnd; DeclGroupPtrTy Decl = ParseDeclaration(Declarator::BlockContext, DeclEnd, Attrs); return Actions.ActOnDeclStmt(Decl, DeclStart, DeclEnd); &#125; if (Tok.is(tok::r_brace)) &#123; Diag(Tok, diag::err_expected_statement); return StmtError(); &#125; return ParseExprStatement(); &#125; case tok::kw_case: // C99 6.8.1: labeled-statement return ParseCaseStatement(); case tok::kw_default: // C99 6.8.1: labeled-statement return ParseDefaultStatement(); case tok::l_brace: // C99 6.8.2: compound-statement return ParseCompoundStatement(); case tok::semi: &#123; // C99 6.8.3p3: expression[opt] &apos;;&apos; bool HasLeadingEmptyMacro = Tok.hasLeadingEmptyMacro(); return Actions.ActOnNullStmt(ConsumeToken(), HasLeadingEmptyMacro); &#125; case tok::kw_if: // C99 6.8.4.1: if-statement return ParseIfStatement(TrailingElseLoc); case tok::kw_switch: // C99 6.8.4.2: switch-statement return ParseSwitchStatement(TrailingElseLoc); case tok::kw_while: // C99 6.8.5.1: while-statement return ParseWhileStatement(TrailingElseLoc); case tok::kw_do: // C99 6.8.5.2: do-statement Res = ParseDoStatement(); SemiError = &quot;do/while&quot;; break; case tok::kw_for: // C99 6.8.5.3: for-statement return ParseForStatement(TrailingElseLoc); case tok::kw_goto: // C99 6.8.6.1: goto-statement Res = ParseGotoStatement(); SemiError = &quot;goto&quot;; break; case tok::kw_continue: // C99 6.8.6.2: continue-statement Res = ParseContinueStatement(); SemiError = &quot;continue&quot;; break; case tok::kw_break: // C99 6.8.6.3: break-statement Res = ParseBreakStatement(); SemiError = &quot;break&quot;; break; case tok::kw_return: // C99 6.8.6.4: return-statement Res = ParseReturnStatement(); SemiError = &quot;return&quot;; break; &#125; return Res;&#125; 关键代码如上，可以看到针对对应的关键字，调用对应的 Parse。这里就不继续跟踪了，有兴趣可以深入了解。 可以发现的是，Action 穿插在代码中，Parse 到指定位置，则调用相应的语义动作进行检查，这样就不需要在 Parse 完成后，遍历一次语法树，且代码简介易于编写。]]></content>
      <categories>
        <category>Clang 源码分析</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clang - Source Code Analysis (1)]]></title>
    <url>%2F2016%2F05%2F13%2FClang-Source-Code-Analysis-1%2F</url>
    <content type="text"><![CDATA[前言读 Clang 源代码是最近一直想做的事情，无奈种种原因一直拖到现在。正好这几天获得了几天喘息时间，便开始了 Clang 源码阅读之旅。 Clang 的源代码可以从 github 上的 Clang 得到。这里我使用的是 Clang 3.9 版本的源代码，如果你使用相近版本，我想问题不会太大。我主要的时间是在 Windows 上工作，所以源代码阅读工作也放到了 Windows 下，毕竟 VS 大法好。具体在 Windows 下如何编译 Clang 请参考 Clang for windows。 想要研究 Clang 源代码，官方文档便是最好的学习资料，除此之外，你还可以订阅 Clang 邮件组(cfe-dev,cfe-commit)。这里首先建议看一看 Clang internals Manual 对基础结构有所把握。 我的着手点是来自知乎上的一篇回答 Clang 真正的前端是什么？。 总体结构Clang 只是一个编译器前端，它获取用户输入，生成语法树，在语义检查和各种诊断后产生 llvm IR。剩下的工作则交给 llvm 完成，而这一切通过 Drive 组织起来。 Clang 默认只进行一遍 parse，你需要通过 Action 来指定完成 parse 后应该干些什么。值得注意的是 Clang 的 Action 穿插在各种 parse 结构中，比如 parse 过程总便对函数声明进行检查。 所以，Clang 的运行流程如下： 解析命令参数，分别为 Analyzer, Migrator, DependencyOutput, Diagnostic, Comment, FileSystem, Frontend, CodeGen, HeaderSearch, LangOpt 等多种类型参数; 根据解析的命令执行相应 Act，进而执行 ParseAST; ParseAST 分为三个部分，前两个部分分别是 ParseTopLevelDecl和 HandleTopLevelDecl; 最后 HandleTranslationUnit 进行检查优化并生成对应的 llvm IR； 下面，我们将通过实际调试来跟踪 Clang 执行流程，首先，写上测试代码： 123456789int function(int x, int y) &#123; return x + y;&#125;int main() &#123; int a = 0; a = function(a, a); return 0;&#125; 保存为 test.cc 然后我们通过如下命令进行编译并调试 Clang : 1clang -cc1 -S -emit-llvm test.cc 然后我们进入调试模式。 首先进入的是位于 driver.cpp 中的 main 函数: 123int main(int argc_, const char **argv_) &#123; llvm::sys::PrintStackTraceOnErrorSignal(); llvm::PrettyStackTraceProgram X(argc_, argv_); 然后进一步跟踪，看到下面部分代码： 123456789101112// Handle -cc1 integrated tools, even if -cc1 was expanded from a response// file.auto FirstArg = std::find_if(argv.begin() + 1, argv.end(), [](const char *A) &#123; return A != nullptr; &#125;);if (FirstArg != argv.end() &amp;&amp; StringRef(*FirstArg).startswith(&quot;-cc1&quot;)) &#123; // If -cc1 came from a response file, remove the EOL sentinels. if (MarkEOLs) &#123; auto newEnd = std::remove(argv.begin(), argv.end(), nullptr); argv.resize(newEnd - argv.begin()); &#125; return ExecuteCC1Tool(argv, argv[1] + 4);&#125; 这里通过判断第一个 argument 是否为以 -cc1 为前缀，是则调用 ExecuteCC1Tool，而我们命令中第一个参数正好为 -cc1，然后跟进 ExecuteCC1Tool 会进入到 cc1_main： 123int cc1_main(ArrayRef&lt;const char *&gt; Argv, const char *Argv0, void *MainAddr) &#123; std::unique_ptr&lt;CompilerInstance&gt; Clang(new CompilerInstance()); IntrusiveRefCntPtr&lt;DiagnosticIDs&gt; DiagID(new DiagnosticIDs()); 这个函数第一行代码便生成了一个 CompilerInstance 对象 Clang，继续跟进会发现下面代码： 12bool Success = CompilerInvocation::CreateFromArgs( Clang-&gt;getInvocation(), Argv.begin(), Argv.end(), Diags); 这里是根据 argument 为 CompilerInstance 创建一个 CompilerInvocation 实例，想来处理 argument 的代码就在里面。所以进入 CreateFromArgs： 123456789101112131415161718192021222324252627282930Success &amp;= ParseAnalyzerArgs(*Res.getAnalyzerOpts(), Args, Diags);Success &amp;= ParseMigratorArgs(Res.getMigratorOpts(), Args);ParseDependencyOutputArgs(Res.getDependencyOutputOpts(), Args);Success &amp;= ParseDiagnosticArgs(Res.getDiagnosticOpts(), Args, &amp;Diags);ParseCommentArgs(LangOpts.CommentOpts, Args);ParseFileSystemArgs(Res.getFileSystemOpts(), Args);// FIXME: We shouldn&apos;t have to pass the DashX option around hereInputKind DashX = ParseFrontendArgs(Res.getFrontendOpts(), Args, Diags);ParseTargetArgs(Res.getTargetOpts(), Args, Diags);Success &amp;= ParseCodeGenArgs(Res.getCodeGenOpts(), Args, DashX, Diags, Res.getTargetOpts());ParseHeaderSearchArgs(Res.getHeaderSearchOpts(), Args);if (DashX == IK_AST || DashX == IK_LLVM_IR) &#123; // ObjCAAutoRefCount and Sanitize LangOpts are used to setup the // PassManager in BackendUtil.cpp. They need to be initializd no matter // what the input type is. if (Args.hasArg(OPT_fobjc_arc)) LangOpts.ObjCAutoRefCount = 1; // PIClevel and PIELevel are needed during code generation and this should be // set regardless of the input type. LangOpts.PICLevel = getLastArgIntValue(Args, OPT_pic_level, 0, Diags); LangOpts.PIELevel = getLastArgIntValue(Args, OPT_pie_level, 0, Diags); parseSanitizerKinds(&quot;-fsanitize=&quot;, Args.getAllArgValues(OPT_fsanitize_EQ), Diags, LangOpts.Sanitize);&#125; else &#123; // Other LangOpts are only initialzed when the input is not AST or LLVM IR. ParseLangArgs(LangOpts, Args, DashX, Res.getTargetOpts(), Diags); if (Res.getFrontendOpts().ProgramAction == frontend::RewriteObjC) LangOpts.ObjCExceptions = 1;&#125; 通过名称就可以猜出每行代码做了些什么功能，所以这里就不一一跟进，只看一下 ParseFrontendArgs： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374static InputKind ParseFrontendArgs(FrontendOptions &amp;Opts, ArgList &amp;Args, DiagnosticsEngine &amp;Diags) &#123; using namespace options; Opts.ProgramAction = frontend::ParseSyntaxOnly; if (const Arg *A = Args.getLastArg(OPT_Action_Group)) &#123; switch (A-&gt;getOption().getID()) &#123; default: llvm_unreachable(&quot;Invalid option in group!&quot;); case OPT_ast_list: Opts.ProgramAction = frontend::ASTDeclList; break; case OPT_ast_dump: case OPT_ast_dump_lookups: Opts.ProgramAction = frontend::ASTDump; break; case OPT_ast_print: Opts.ProgramAction = frontend::ASTPrint; break; case OPT_ast_view: Opts.ProgramAction = frontend::ASTView; break; case OPT_dump_raw_tokens: Opts.ProgramAction = frontend::DumpRawTokens; break; case OPT_dump_tokens: Opts.ProgramAction = frontend::DumpTokens; break; case OPT_S: Opts.ProgramAction = frontend::EmitAssembly; break; case OPT_emit_llvm_bc: Opts.ProgramAction = frontend::EmitBC; break; case OPT_emit_html: Opts.ProgramAction = frontend::EmitHTML; break; case OPT_emit_llvm: Opts.ProgramAction = frontend::EmitLLVM; break; case OPT_emit_llvm_only: Opts.ProgramAction = frontend::EmitLLVMOnly; break; case OPT_emit_codegen_only: Opts.ProgramAction = frontend::EmitCodeGenOnly; break; case OPT_emit_obj: Opts.ProgramAction = frontend::EmitObj; break; case OPT_fixit_EQ: Opts.FixItSuffix = A-&gt;getValue(); // fall-through! case OPT_fixit: Opts.ProgramAction = frontend::FixIt; break; case OPT_emit_module: Opts.ProgramAction = frontend::GenerateModule; break; case OPT_emit_pch: Opts.ProgramAction = frontend::GeneratePCH; break; case OPT_emit_pth: Opts.ProgramAction = frontend::GeneratePTH; break; case OPT_init_only: Opts.ProgramAction = frontend::InitOnly; break; case OPT_fsyntax_only: Opts.ProgramAction = frontend::ParseSyntaxOnly; break; case OPT_module_file_info: Opts.ProgramAction = frontend::ModuleFileInfo; break; case OPT_verify_pch: Opts.ProgramAction = frontend::VerifyPCH; break; case OPT_print_decl_contexts: Opts.ProgramAction = frontend::PrintDeclContext; break; case OPT_print_preamble: Opts.ProgramAction = frontend::PrintPreamble; break; case OPT_E: Opts.ProgramAction = frontend::PrintPreprocessedInput; break; case OPT_rewrite_macros: Opts.ProgramAction = frontend::RewriteMacros; break; case OPT_rewrite_objc: Opts.ProgramAction = frontend::RewriteObjC; break; case OPT_rewrite_test: Opts.ProgramAction = frontend::RewriteTest; break; case OPT_analyze: Opts.ProgramAction = frontend::RunAnalysis; break; case OPT_migrate: Opts.ProgramAction = frontend::MigrateSource; break; case OPT_Eonly: Opts.ProgramAction = frontend::RunPreprocessorOnly; break; &#125; &#125; 这里便是指定 Action 的地方，我们使用的 -emit-llvm ，则 ProgramAction 表示 frontend::EmitLLVM。 现在回到 cc1_main，紧急着便是执行 frontend actions： 12// Execute the frontend actions.Success = ExecuteCompilerInvocation(Clang.get()); 目前为止，初始化编译器部分工作已经完成，下面就是执行部分。跟进 ExecuteCompilerInvocation，注意到下面一段代码： 12345// Create and execute the frontend action.std::unique_ptr&lt;FrontendAction&gt; Act(CreateFrontendAction(*Clang));if (!Act) return false;bool Success = Clang-&gt;ExecuteAction(*Act); 这里就是根据 ParseFrontendArgs 中得到的 ProgramAction 来生成对应的 Act。紧接着，通过该 Act 调用 ExecuteAction 正式开始工作。 CreateFrontendAction 通过进一步调用 CreateFrontendBaseAction 来生成 Act，CreateFrontendBaseAction 中对应部分代码为： 12345678910111213141516171819202122switch (CI.getFrontendOpts().ProgramAction) &#123; case ASTDeclList: return llvm::make_unique&lt;ASTDeclListAction&gt;(); case ASTDump: return llvm::make_unique&lt;ASTDumpAction&gt;(); case ASTPrint: return llvm::make_unique&lt;ASTPrintAction&gt;(); case ASTView: return llvm::make_unique&lt;ASTViewAction&gt;(); case DumpRawTokens: return llvm::make_unique&lt;DumpRawTokensAction&gt;(); case DumpTokens: return llvm::make_unique&lt;DumpTokensAction&gt;(); case EmitAssembly: return llvm::make_unique&lt;EmitAssemblyAction&gt;(); case EmitBC: return llvm::make_unique&lt;EmitBCAction&gt;(); case EmitHTML: return llvm::make_unique&lt;HTMLPrintAction&gt;(); case EmitLLVM: return llvm::make_unique&lt;EmitLLVMAction&gt;(); case EmitLLVMOnly: return llvm::make_unique&lt;EmitLLVMOnlyAction&gt;(); case EmitCodeGenOnly: return llvm::make_unique&lt;EmitCodeGenOnlyAction&gt;(); case EmitObj: return llvm::make_unique&lt;EmitObjAction&gt;(); case FixIt: return llvm::make_unique&lt;FixItAction&gt;(); case GenerateModule: return llvm::make_unique&lt;GenerateModuleAction&gt;(); case GeneratePCH: return llvm::make_unique&lt;GeneratePCHAction&gt;(); case GeneratePTH: return llvm::make_unique&lt;GeneratePTHAction&gt;(); case InitOnly: return llvm::make_unique&lt;InitOnlyAction&gt;(); case ParseSyntaxOnly: return llvm::make_unique&lt;SyntaxOnlyAction&gt;(); case ModuleFileInfo: return llvm::make_unique&lt;DumpModuleInfoAction&gt;(); case VerifyPCH: return llvm::make_unique&lt;VerifyPCHAction&gt;(); 在这里，就可以找到所有的 Action 方便后面使用。 ExecuteAction 中通过对每一个文件执行一次 Execute 来进行编译： 1234567891011for (const FrontendInputFile &amp;FIF : getFrontendOpts().Inputs) &#123; // Reset the ID tables if we are reusing the SourceManager and parsing // regular files. if (hasSourceManager() &amp;&amp; !Act.isModelParsingAction()) getSourceManager().clearIDTables(); if (Act.BeginSourceFile(*this, FIF)) &#123; Act.Execute(); Act.EndSourceFile(); &#125;&#125; Execute 中，通过进一步调用所对应实例的 ExecuteAction 来具体执行，所以这里紧接着关心的便是每个 Action 对应的 ExecuteAction 部分。到此为止，工作流程部分告一段落，接下来具体分析的是对应的 Action。]]></content>
      <categories>
        <category>Clang 源码分析</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel5.2+Dingo/API+JWTauth 的坑]]></title>
    <url>%2F2016%2F04%2F28%2FLaravel5-2-Dingo-API-JWTauth-%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[最近着手做一款应用后端，在否定了 BaaS 后，决定用 Laravel 框架自己做一个 RESTful API。我的环境是 Laravel 5.2 ，另外使用了 Dingo/API 和 JWTAuth。不过在使用的过程中遇到了很多的坑，所以在这里记录一下。 JWTAuth 默认使用 Users 表做为登录认证的表。而我的需求比较奇葩，共有两个不同的表；除此之外，还需要对 JWTAuth 的错误进行自定义。在搜索无果后，只好自己动手实现这两个需求。 首先解决第二个问题，对 JWTAuth 进行错误自定义。这种情况下，我们可以自己去添加一个中间件处理身份认证。 添加中间件处理身份验证1、添加一个 Middleware 可以使用命令行添加： 1php artisan make:middleware GetUserFromToken 此命令将会在 app/Http/Middleware 目录内置立一个名称为 GetUserFromToken 的类。 2、在 GetUserFromToken 中编辑代码，这里仿照 JWTAuth 写了 Middleware 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?phpnamespace App\Http\Middleware;use Closure;use JWTAuth;use Tymon\JWTAuth\Exceptions\JWTException;use Tymon\JWTAuth\Exceptions\TokenExpiredException;use Tymon\JWTAuth\Exceptions\TokenInvalidException;class GetUserFromToken&#123; public function handle($request, Closure $next) &#123; $auth = JWTAuth::parseToken(); if (! $token = $auth-&gt;setRequest($request)-&gt;getToken()) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_not_provided&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]); &#125; try &#123; $user = $auth-&gt;authenticate($token); &#125; catch (TokenExpiredException $e) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_expired&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]); &#125; catch (JWTException $e) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_invalid&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]); &#125; if (! $user) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;user_not_found&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]); &#125; //$this-&gt;events-&gt;fire(&apos;tymon.jwt.valid&apos;, $user); return $next($request); &#125;&#125; 我将每次错误返回数据替换成自己设置的错误信息。 3、在 /app/Http/Kernel.php 中 $routeMiddleware 新增如下内容： 1234protected $routeMiddleware = [ ... &apos;jwt.api.auth&apos; =&gt; \App\Http\Middleware\GetUserFromToken::class, //新增注册的中间件]; 4、在路由中指定使用 jwt.api.auth 1[&apos;middleware&apos; =&gt; &apos;jwt.api.auth&apos;] 完成上面的操作，我们新增处理接口身份认证中间件就完成了。 现在需要处理前一个问题。 多表配置在 JWTAuth 中，可以在配置文件 jwt.php 中设置 User Model namespace，所以可以在 Middleware 中 handle 部分添加如下代码来动态配置 User Model namespace 1config([&apos;jwt.user&apos; =&gt; &apos;App\Models\User&apos;]); 这里，我把 User 表放到了 App\Models\ 中和其他的统一进行管理。不过我在测试中一直出现 App\User 未定义错误。然后就开始了漫长的定位之旅。首先在访问 authenticate 得到 12345678910public function authenticate($token = false)&#123; $id = $this-&gt;getPayload($token)-&gt;get(&apos;sub&apos;); if (! $this-&gt;auth-&gt;byId($id)) &#123; return false; &#125; return $this-&gt;auth-&gt;user();&#125; 然后，在 Tymon\JWTAuth\Providers\Auth\IlluminateAuthAdapter 中找到 byId 和 user 对应代码如下 123456789public function byId($id)&#123; return $this-&gt;auth-&gt;onceUsingId($id);&#125;public function user()&#123; return $this-&gt;auth-&gt;user();&#125; 经过测试发现 auth 实际上是一个 Illuminate\Auth\SessionGuard 实例，然后在其中发现了 onceUsingId 和 user 部分代码 12345678910public function onceUsingId($id)&#123; if (! is_null($user = $this-&gt;provider-&gt;retrieveById($id))) &#123; $this-&gt;setUser($user); return true; &#125; return false;&#125; 在查找 provider 所在位置时定位到文件 Illuminate\Auth\CreatesUserProviders.php 中找到如下代码 123456789101112131415161718public function createUserProvider($provider)&#123; $config = $this-&gt;app[&apos;config&apos;][&apos;auth.providers.&apos;.$provider]; if (isset($this-&gt;customProviderCreators[$config[&apos;driver&apos;]])) &#123; return call_user_func( $this-&gt;customProviderCreators[$config[&apos;driver&apos;]], $this-&gt;app, $config ); &#125; switch ($config[&apos;driver&apos;]) &#123; case &apos;database&apos;: return $this-&gt;createDatabaseProvider($config); case &apos;eloquent&apos;: return $this-&gt;createEloquentProvider($config); default: throw new InvalidArgumentException(&quot;Authentication user provider [&#123;$config[&apos;driver&apos;]&#125;] is not defined.&quot;); &#125;&#125; 这里通过 auth.providers.users 配置设置 $config，而 auth.providers.users 在文件 auth.php 中默认配置如下 123456&apos;providers&apos; =&gt; [ &apos;users&apos; =&gt; [ &apos;driver&apos; =&gt; &apos;eloquent&apos;, &apos;model&apos; =&gt; App\User::class, ],] 所以程序走到了 return $this-&gt;createEloquentProvider($config); 这一步，继续跟踪得到: 1234protected function createEloquentProvider($config)&#123; return new EloquentUserProvider($this-&gt;app[&apos;hash&apos;], $config[&apos;model&apos;]);&#125; 其中 $config[&#39;model&#39;] 则就是原型: 12345public function __construct(HasherContract $hasher, $model)&#123; $this-&gt;model = $model; $this-&gt;hasher = $hasher;&#125; 到此，确定了 model 所在位置，只需要在 Middleware 中添加如下配置 1config([&apos;auth.providers.users.model&apos; =&gt; \App\Models\User::class]); 最终代码如下 1234567891011121314151617181920212223242526272829303132333435363738config([&apos;jwt.user&apos; =&gt; &apos;\App\Models\User&apos;]);config([&apos;auth.providers.users.model&apos; =&gt; \App\Models\User::class]);$auth = JWTAuth::parseToken();if (! $token = $auth-&gt;setRequest($request)-&gt;getToken()) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_not_provided&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]);&#125;try &#123; $user = $auth-&gt;authenticate($token);&#125; catch (TokenExpiredException $e) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_expired&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]);&#125; catch (JWTException $e) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;token_invalid&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]);&#125;if (! $user) &#123; return response()-&gt;json([ &apos;code&apos; =&gt; &apos;&apos;, &apos;message&apos; =&gt; &apos;user_not_found&apos;, &apos;data&apos; =&gt; &apos;&apos;, ]);&#125;//$this-&gt;events-&gt;fire(&apos;tymon.jwt.valid&apos;, $user);return $next($request); 到这里为止，实现了自定义表名功能，在结合自定义 Middleware 部分，就可以实现多表认证。只需要对每一种认证都实现对应的 Middleware ，在接口处分别对不同接口使用不同的 Middleware 进行验证就好。 当然，这样的实现肯定不完美，因为所有的事件部分代码全部删除了。这部分还没有想到什么好的解决办法，自己实现 event 应该是可行的，这里就么有尝试。]]></content>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql 架构学习]]></title>
    <url>%2F2016%2F04%2F22%2FMySql-%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Mysql 支持的数据类型非常之多，如何选择正确的数据类型对于获得高性能至关重要。下面是几个简单原则，用于帮助选择数据类型。 更小的通常更好： 应当尽量使用可以储存数据的最小类型，因为其通常占用资源更少。但是不要低估存储值的范围，因为在 schema 中的多个地方增加数据类型的范围是一个非常耗时和痛苦的操作； 简单就好： 比如应该使用内置类型而不是字符串来存储时间和日期，因为这样操作代价更低。 尽量避免 NULL： 通常情况下最好指定 NOT NULL，除非真的需要 NULL 值。 在架构的时候首先确定大类型，然后具体到基本类型。 数字类型mysql 中有两种不同类型的数字，整数和实数。 整数类型整数类型有：TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT。其分别占用 8, 16, 24, 32, 64 位存储空间，值范围为 [-2^(n-1), 2^(n-1))，其中 N 是储存空间位数。 整数类型有可选的 UNSIGNED 属性，表示没有负数。有符号和无符号使用相同储存空间，并有相同性能。另外，mysql 中可以为整数类型指定宽度（int(10)），但是实际上并不会影响到储存和计算。 实数类型FLOAT 和 DOUBLE 支持使用标准的浮点运算进行近似计算。DECIMAL 类型用于存储精确的小数，其精确计算开销过大，这里不讲。另外，在存储固定位数的小数如金额，可以转换为整数改用 BIGINT 存储，这样可以同时避免浮点数计算不精确和 DECIMAL 精确计算开销大。 字符串类型VARCHAR 和 CHAR 是最主要的两种字符串类型，具体实现方式与储存引擎有关。下面以 InnoDB 为储存引擎。BLOB 和 TEXT 都是为储存很大的数据而设计的字符串数据类型，分别采用二进制和字符方式进行储存。 VARCHARVARCHAR 类型用于储存可变长字符串，是最常见的字符串数据类型，它比定常类型更节省空间。VARCHAR 需要使用1或2个字节用于记录字符串长度，如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用两个字节。需要注意的是由于行是变长的，那么在 UPDATE 或者其他操作过程中使得行变得比原来更长，就会导致额外的工作。所以 VARCHAR 比较实用于字符串列的最大长度比平均长度大得很多；列的更新很少的情况。 CHARCHAR 是定长类型，当储存 CHAR 值时，mysql 会删除所有的末尾空格。CHAR 适合储存很短的字符串，或者所有值都接近同一个长度的值。 日期和时间类型DATETIME 这个类型能保存大范围的值，从 1001 年到 9999 年，精度为秒。它把日期和时间装到格式 YYYYMMDDHHMMSS 的整数中，与时区无关。使用 8 个字节的存储空间。TIMESTAMP 保存了从 1970 年 1 月 1 日午夜以来的描述，它和 UNIX 时间戳相同。TIMESTAMP 只使用4个字节的储存空间。所以其范围比 DATETIME 小得多，只能表示从 1970 年到 2038 年。除特殊行为之外，通常也应该尽量使用 TIMESTAMP ，因为它比 DATETIME 空间效率更高。]]></content>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Y组合子(Y combinator)与匿名Lambda]]></title>
    <url>%2F2016%2F02%2F29%2FY%E7%BB%84%E5%90%88%E5%AD%90-Y-combinator-%E4%B8%8E%E5%8C%BF%E5%90%8DLambda%2F</url>
    <content type="text"><![CDATA[Y组合子(Y combinator)与匿名 LambdaY组合子是函数编程的理论基础，lambda 演算的一部分。它的作用就是把匿名 lambda 函数自身给计算出来。 在介绍组合子之前需要先介绍不动点：不动点（fixed point）是指函数的某种输入和函数本身相等，也就是 f(x) 等于 x 。当然，继续之前你还得了解 first class function 中的高阶函数和柯里化(currying)的概念。 现在，尝试使用前面设计的语言来做一个例子解释 Y 组合子的用途，该语言中名字只有在定义完成后才可见，也就是定义函数时无法知道自己的名字，这样就导致了无法进行递归。那么如何在这门语言中使用递归呢？ 所谓 Y 组合子即一个 Y 函数，它用于计算高阶函数的不动点。假设有函数 f(x) 和高阶函数 g(x)，我们用 t 来表示 g(x) 的不动点。那么就有 g(Y(g)) = Y(g) 等价于 g(t) = t，其中 Y(g) 得到的是 g(x) 的不动点。 下面，我们来计算 Y 的形式，定义斐波拉契函数如下： 123456define f = function(fib) &#123; return function(n) &#123; if (n &lt;= 2) return 1; return fib(n-1) + fib(n-2); &#125;;&#125;; 现在，只需要将 fib 函数传递给 f 就能得到 fib…显然这种办法是行不通的。我们进行如下改写： 12345define fib = function(h, x) &#123; if (x &lt;= 2) return 1; return h(h, x-1) + h(h, x-2);&#125;;fib(fib, 10); 虽然实现了递归，但是这种办法没有那么优美。我希望能够像其他语言一样，使用 fib(10) 进行调用。现在将函数柯里化: 1234567define fib = function(h) &#123; return function(x) &#123; if (x &lt;= 2) return 1; return h(h)(x-1) + h(h)(x-2); &#125;;&#125;;fib(fib)(10); 这样的方式仍然不够好，我们进一步将内部的 h(h) 部分改为 fib(x)： 12345678910define fib = function(h) &#123; return function(x) &#123; let f = function(fib) &#123; if (x &lt;= 2) return 1; return fib(x-1) + fib(x-2); &#125;; return f(h(h)); &#125;;&#125;;fib(fib)(10); 现在发现其中的 f 定义的部分与最开始的代码相似，改写如下： 123456789101112define fib = function(h) &#123; return function(x) &#123; let f = function(fib) &#123; return function(n) &#123; if (n &lt;= 2) return 1; return fib(n-1) + fib(n-2); &#125;; &#125;; return f(h(h))(x); &#125;;&#125;;fib(fib)(10); 然后将 f 部分提取出来： 12345678910111213define f = function(fib) &#123; return function(n) &#123; if (n &lt;= 2) return 1; return fib(n-1) + fib(n-2); &#125;;&#125;;define fib = function(h) &#123; return function(x) &#123; return f(h(h))(x); &#125;;&#125;;fib(fib)(10); 这里发现，利用柯里化，就能得到 Y 组合子，现在对其进行包装： 123456789101112131415161718define f = function(fib) &#123; return function(n) &#123; if (n &lt;= 2) return 1; return fib(n-1) + fib(n-2); &#125;;&#125;;define Y = function(f) &#123; let warp = function(h) &#123; return function(x) &#123; return f(h(h))(x); &#125;; &#125;; return warp(warp);&#125;;define fib = Y(f);fib(10); 现在回头看 Y 组合子的定义，Y(f) 就得到了 f 的不动点。那么现在就可以很友好的得到 fib 函数： 12345678910111213141516define Y = function(f) &#123; let warp = function(h) &#123; return function(x) &#123; return f(h(h))(x); &#125;; &#125;; return warp(warp);&#125;;define fib = Y(function(fib) &#123; return function(n) &#123; if (n &lt;= 2) return 1; return fib(n-1) + fib(n-2); &#125;;&#125;);fib(10); 现在，当然这样的 Y 函数依然有限制，不过已经实现了预期的需求：匿名递归 lambda。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++0x:Copy And Move]]></title>
    <url>%2F2016%2F01%2F07%2FC-Copy-And-Move%2F</url>
    <content type="text"><![CDATA[C++ 提供了5种特殊的成员函数来控制对象的拷贝、移动、赋值和销毁，统称为拷贝控制操作(copy control)。这几个函数分别是拷贝构造函数(copy constructor)、拷贝赋值运算符(copy assignment operator)、移动构造函数(move constructor)、移动复制运算符(move assignment operator)和析构函数(destructor)。 拷贝构造函数如果一个构造函数的第一个参数是自身类型的引用，且任何额外的参数都有默认值，则此函数是拷贝构造函数。 1234class test &#123;public: test(const test&amp;); // copy constructor&#125;; 如果我们没有为一个类定义拷贝构造函数，编译器会为我们定义一个合成拷贝构造函数(synthesized copy constructor)。对于合成拷贝构造函数，在发生拷贝时，每个成员的类型会决定其拷贝方式，类成员使用其拷贝构造函数，内置类型成员直接拷贝，数组会逐个元素地拷贝。 拷贝构造时机对于没有进行函数调用的初始化，如果使用等号(=)初始化一个变量，则实际上执行的是拷贝初始化(copy initialization)，如果不使用等号，则执行直接初始化(direct initialization)。 1234string s1(&quot;direct initialization&quot;);string s2(s1); // direct initializationstring s3 = &quot;copy initialization&quot;; string s4 = s2; // copy initialization 如果初始化中涉及到函数调用，那么在下列情况也会发生拷贝初始化： 将一个对象作为实参传递给一个非引用类型的形参 从一个返回值类型为非引用类型的函数返回一个对象 花括号列表初始化一个数组中的元素或者一个聚合类中的成员 如果一个类满足下列条件，则称为聚合类： 所有成员都是 public的 没有定义任何构造函数 没有类内初始值 没有基类，也没有 virtual 函数 对于聚合类，可以使用花括号括起来的成员初始值列表进行初始化： 123456&gt; struct data &#123;&gt; int ival;&gt; string s;&gt; &#125;;&gt; data val = &#123; 1, &quot;string&quot; &#125;;&gt; 其中初始顺序必须和申明顺序一致，如果初始列表中的元素个数少于类成员的个数，则靠后的成员被值初始化。且初始化列表中的元素个数不能多于成员数量。 需要注意的是，标准允许编译器在初始化过程中跳过拷贝/移动构造函数直接创建对象。 拷贝赋值运算符拷贝赋值运算符接受一个与其所在类型相同的参数。如果没有定义其拷贝赋值运算符，编译器会为它生成一个合成拷贝赋值运算符(synthesized copy assignment operator)。 安全的拷贝赋值运算符编写拷贝赋值运算符时，有两点需要注意：1、自我拷贝 2、异常安全。下面精心构造的例子可以说明这些问题： 12345678910111213class Bitmap &#123; &#125;;class Widget &#123; Bitmap *pb; public: Widget(Bitmap *p) : pb(p) &#123;&#125; Widget &amp;operator = (const Widget &amp;rhs) &#123; delete pb; pb = new Bitmap(*rhs.pb); return *this; &#125;&#125;; 假设有某用户创建一个对象后对自己进行赋值： 123Bitmap *b;Widget w(b);w = w; // error; 或者编写 Bitmap 的设计者在内存不足时抛出异常： 123456class Bitmap &#123;public: Bitmap(const Bitmap&amp; obj) &#123; throw ... &#125;&#125;; 那么在 new Bitmap 操作失败，而原来的备份也被删除。 简单的解决方案是将拷贝复制运算符实现代码进行如下修改： 123456Widget &amp;operator = (const Widget &amp;rhs) &#123; Bitmap *old = pb; pb = new Bitmap(*rhs.pb); delete old; return *this;&#125; 这样的代码首先保证了异常安全，并且顺带解决了自我赋值(拷贝了一份原来的数据)。另一个替代方案是 copy and swap 技术： 1234Widget &amp;operator = (Widget rhs) &#123; this-&gt;swap(rhs); return *this;&#125; 其中假设 swap 函数不会抛出异常。这种方法利用以下依据： 某 class 的 copy assignment 操作可能被申明为 “以 by value 方式接受实参” 以 by value 方式传递东西会造成一件副本 这种方法将 “copying” 动作从函数本体内移到 函数参数构造阶段。 对象移动对于某些场景，比如 vector&lt;string&gt; 增长时，将旧元素拷贝到新内存是不必要的，而某些对象如 IO 类或 unique_ptr 则不能拷贝。为了解决这些问题，新标准引入了移动语义 - 右值引用(rvalue reference)。 右值引用所谓右值引用就是必须绑定到右值的引用，类似于任何引用，一个右值引用也不过是某个对象的另一个名字。左值和右值都是针对表达式而言的，左值是指表达式结束后依然存在的持久对象，右值是指表达式结束时就不再存在的临时对象。一个区分左值与右值的便捷方法是：看能不能对表达式取地址，如果能，则为左值，否则为右值。左值有持久状态，而右值要么是字面常量，要么是表达式求值过程中创建的临时对象，所以使用右值引用可以自由的接管所引用对象的资源。 12int i = 1;int &amp;&amp;rr = i * 2; 基于可以看作是将 i * 2 产生的临时变量绑定到 rr 上。而这里的 rr 是右值引用，但其却是一个变量，对于这种情况，标准中提到： Things that are declared as rvalue reference can be lvalues or rvalues. The distinguishing criterion is: if it has a name, then it is an lvalue. Otherwise, it is an rvalue. 所以， rr 也是一个左值。这里也就是所谓的绑定到右值的引用。理解右值引用是理解移动语义的基础。 移动构造函数和移动赋值操作符类似于拷贝构造函数，移动构造函数第一个参数必须是该类型的一个右值引用，其余参数都必须有默认实参。而移动赋值操作符则是接受本类型的右值。需要注意的是使用移动语义后必须保证源对象处于销毁无害的状态，即该对象拥有的资源转移给了赋值对象。所以一般的移动构造函数都会将原对象的指针等设置为 nullptr。 在移动操作中允许抛出异常，但是通常不会抛出异常。而标准容器库能对异常发生时其自身的行为提供保障，所以如果元素的移动构造函数没有 noexcept 修饰时，容器库在从新分配内存时会选择拷贝构造函数而不是移动构造函数。因此，如无必要，移动构造函数应当加 noexcept 修饰。 需要注意到的是合成版本的移动构造函数和移动赋值操作符合成条件比较多，这里没有涉及。如果一个类定义了右值构造，那么我们可以通过给它传递右值参数调用其移动构造函数。如果想要对左值也进行移动，这需要进行转义。这种转义可以看作 static_cast&lt;T&amp;&amp;&gt;(lvalue);，在标准中由 std::move(lvaule) 提供支持。值得一提的是，被转化的左值，其生命期并没有随着左右值的转化而改变。也就是说，其实仍然是左值，只是变相调用了移动语义。这也是前面之所以强调的必须保证源对象处于销毁无害的状态。所以调用 move 就意味着承诺：*除了对 lvalue 进行赋值或者销毁它以外，我们将不在使用它`。 成员函数与右值与 const 修饰的成员函数一致，我们可以在参数列表后放置一个引用限定符(reference qualifier)来指定调用者是左值还是右值。引用限定符可以是 &amp; 或 &amp;&amp;，分别指出 this 可以指向一个左值或者右值。如果一个函数已经有 const 修饰，那么引用修饰必须出现在其后面的位置。 小结通过以上内容可以看到，C++的许多灵活性来自于其强大的类型系统和精巧的设计理念。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、function as first class]]></title>
    <url>%2F2015%2F12%2F24%2F%E4%B8%83%E3%80%81function-as-first-class%2F</url>
    <content type="text"><![CDATA[当设计一门语言时，函数部分设计五花八门，各种设计所对应的实现方式也各有千秋。 函数式编程函数式编程 是一种编程范式(programming paradigm)，也就是如何写程序的方法论。它将计算机运算看作是数学中函数的计算，并且避免了状态以及变量的概念。在函数式编程语言中，函数跟其他数据类型一样，处于平等地位，可以赋值给其他变量，也可以作为参数，传入另一个函数，或者作为别的函数的返回值。且函数中没有副作用(函数内部与外部互动，如内部修改全局变量值)，因此函数只返回新的值，不修改系统变量。在输入参数相同的情况下，得到的结果总是相同的。 C语言中的函数C语言中的函数并不是严格意义上的函数，它具有副作用。这种函数的实现方式十分简单，对于函数体部分，生成相关代码，保存在静态区域即可。对于函数调用部分，可以将参数压入栈，然后调用。 比如 printf(1, 2, 2); 可以翻译成如下代码： 1234push 2push 2push 1call printf 高阶函数我们把接受一个或多个函数作为参数，或者能返回函数的函数叫做高阶函数。在C语言中可以通过函数指针进行传递函数： 12345typedef void(*func)();void test() &#123;&#125;void call(func f) &#123; f();&#125; 这样是将函数地址传递给调用函数，可以用汇编简要解释： 12345push offset _testcall _call; in callcall [ebp-4] 嵌套函数pascal 之类的语言就支持嵌套函数，所谓嵌套，就是可以在函数内部定义函数。C语言并不支持嵌套函数，我们假设其支持嵌套函数： 12345678910111213141516171819202122void global_func() &#123; int a = 20; void nest_func() &#123; a = 10; &#125; void nest_func1() &#123; int a = 40; void test() &#123; nest_func(); a = 30; &#125; a == 40; test(); a == 30; &#125; nest_func(); a == 10; a = 20; nest_func1(); a == 10;&#125;nest_func(); /* error */ 可以看到的是，嵌套定义函数可以访问外部作用域，并产生副作用。不同作用域相互之间屏蔽。嵌套作用域给函数实现带来了不少麻烦，比如在查找变量所在作用域时，需要沿着栈帧回溯。如上诉例子，test 在查找变量 a 时，应该找到 nest_func1 中的变量 a ，而 test 中调用的 nest_func 所查找的 a 却应该是 global_func 中的 a。(这里假定使用的是 词法作用域， 而不是 动态作用域)这样就不能直接使用原有的向上回溯查找变量的方法，不过这有相应的解决办法。对于每个函数的帧，我们加入一个访问链指针，其指向当前调用栈中，该函数定义所在的外层函数最近一次调用的帧。比如对于上面的例子，在调用 nest_func1() 中的 test() 时，test 中的指针应当指向其直接上层 nest_func1 , 但是对于 test() 调用中的函数 nest_func ，其上层不应当是 test()。 123456top -&gt; nest_func() test() nest_func1() global_func()bottom -&gt;简单的函数调用栈 这里 nest_func 访问链应当指向最上面的 global_func()。这样，函数在查找变量时，就可以通过访问链回溯而不是调用栈回溯。关于访问链的具体实现，可以参考龙紫书。还需要注意的是如果嵌套函数中有引用外层变量，那么是无法将内层函数当作返回值返回，所以这里需要引入闭包的概念。 柯里化函数在闭包之前需要了解柯里化函数(Currying)，简单来说柯里化函数就是函数生成的函数，比如以下C++代码： 12345int func(int a, int b) &#123; return a + b;&#125;auto call = std::bind(func, 1, _1);call(1); 在这里我们传递给函数 func 一个参数，然后生成一个保存了当前状态的函数，然后再后续补完全部参数时调用，这就是一个简单的柯里化函数应用。现在来考虑如何实现柯里化函数，柯里化函数需要保存当前已有的状态，那么我们对每一个函数包括普通函数定义一个 frame ，在每一次调用时，检测参数数目，如果满足所有参数都有对应的实参，那么就调用，否则生成一个新函数，将原有的 frame 拷贝一份，并加入新的参数。 12345if (args.size() == params.size()) call function;else insert new function copy frame to new frame and insert params 闭包闭包是指可以包含自由(未绑定到特定对象)变量的代码块，这些变量不是在这个代码块内或者任何全局上下文中定义的，而是在定义代码块的环境中定义。可以把闭包当作嵌套的高阶柯里化函数，嵌套对应着代码块或全局上下文，柯里化函数则是保存当前上下文状态，高阶使得函数可以通过参数或返回值进行传递。对于闭包有多种实现方式，这里紧紧讨论一种非常 native 的实现方式。首先需要对闭包中访问的自由变量进行捕获，然后隐式地作用参数传递给闭包体，生成新函数返回。这样变换以后，新生成的函数并不依赖于其父作用域，使得函数可以在任意地方调用。 12345678(define (func x) (lambda (a) （+ a x)) 可以改为(define (func x) ((define (nest_func x a) (+ a x)) x))]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clang for windows]]></title>
    <url>%2F2015%2F12%2F23%2FClang-for-windows%2F</url>
    <content type="text"><![CDATA[G++ 编译产生的错误信息非常不人性化，所以准备转到 Clang，在这中途折腾了许久，仅仅是为了将 Clang 安装在 windows 上。所以在这里记录下该过程，以后再遇到相关问题可以快速解决。 ClangClang 是一个 C 语言、C++、Objective-C、Objective-C++ 语言的轻量级编译器，相对于 GCC ，其编译速度更快，编译产出错误提示更友好。 安装这里介绍的安装方法需要下面的工具，CMake、GIT、VisualStudio。有关于 CMake 的介绍，可以看CMake入门。git 是一个免费的、分布式的版本控制工具，或是一个强调了速度快的源代码管理工具。Git最初被Linus Torvalds开发出来用于管理Linux内核的开发。关于 git 入门教程可以参考git快速入门。 首先是下载 Clang 的源代码，Clang 编译需要依赖 llvm。 123456mkdir llvmcd llvmgit clone http://llvm.org/git/llvm.gitmv llvm sourcecd source/toolsgit clone http://llvm.org/git/clang.git 现在使用CMake将其转换为VS工程。 1234cd ../../mkdir debug+assertscd debug+assertscmake -G &quot;Visual Studio 14&quot; ../source -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DLLVM_ENABLE_ASSERTIONS=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo 这样，等待相关信息准备完毕后，就会在当前目录下就会生成 VS 工程。这里我使用的是 VS2015 ，你在自己使用的时候，需要针对性的修改一下。 现在可以打开进行编译，普通的机器编译过程比较长.]]></content>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SFINAE、std::declval杂谈]]></title>
    <url>%2F2015%2F12%2F21%2FSFINAE%E3%80%81std-declval%E6%9D%82%E8%B0%88%2F</url>
    <content type="text"><![CDATA[前言在知行一社区上看到一篇文章介绍设计 UnitTest 的文章。在看其源代码时，发现有处代码并不是很懂。通过查找相关资料，解决了该问题，记录在此。 问题作者在谈到其设计目标时，提供了一些用例，其中： 123TEST_REQUIRE(condition, &quot;这样&quot;, &quot;可以&quot;, &quot;打印&quot;, &quot;很多&quot;， &quot;行&quot;); TEST_CHECK(condigion, []&#123; /** 这里可以做些事 */ &#125;);TEST_REQUIRE(condition, logger, args_to_logger); /**&lt; logger can be any callable object */ 这样的用法让我或多或少有些疑惑。于是看了其实现，其中关键问题部分代码如下： 1234567891011template &lt;typename F, typename... Args, typename = decltype(std::declval&lt;F&gt;()(std::declval&lt;Args&gt;()...))&gt;void do_check_failed(F&amp;&amp; f, Args&amp;&amp;... args)&#123; f(std::forward&lt;Args&gt;(args)...); &#125;template &lt;typename... Msgs&gt;void do_check_failed(Msgs&amp;&amp;... msgs)&#123; std::initializer_list&lt;int&gt;&#123;(std::cout &lt;&lt; msgs &lt;&lt; std::endl, 0)...&#125;;&#125; 这两个函数实现了传递多种参数的方式。其中令我疑惑的部分在于typename = decltype(std::declval&lt;F&gt;()(std::declval&lt;Args&gt;()...))部分的实现。现在让我一步一步展开。 declvaldeclval主要用于配合decltype在模板形参构造函数不明确的情况下（也就是不需要通过构造函数构造变量）来使用模板形参的成员。在进一步探索前，先看一下declval的定义： 12template&lt;class T&gt;typename add_rvalue_reference&lt;T&gt;::type declval() noexcept; // as unevaluated operand 该函数并没有完整定义，所以只能在未发生函数调用(unevaluated)的上下文环境中使用。这正好就是用于配合decltype(decltype不求值)。假设有这么一个场景，你需要得到某类型中某函数返回值的类型，然而该函数并没有构造函数: 123456789struct Default &#123; Default(const Default &amp;d) &#123;&#125; int foo() const &#123; return 1; &#125;&#125;;int main() &#123; decltype(Default.foo()) n1 = 1; return 0;&#125; 这样的代码无法通过编译。如果加上declval： 1234int main() &#123; decltype(std::declval&lt;Default&gt;().foo()) n1 = 1; return 0;&#125; 这样就能顺利通过编译。当然，更多的使用场景是出现在模板的使用中。 SFINAESFINAE(Subsitiution Failure Is Not an Error!)可以理解为匹配失败不是错误，更严格的说是参数匹配失败不是一个编译时错误。考虑下面的应用场景，我们定义一个模板函数add，它只为数值类型提供服务： 1234567template&lt;typename T&gt;T add(T &amp;t1, T &amp;t2) &#123; if (T is arithmetic) return t1 + t2; else // error&#125; C++并没有提供反射机制，想实现这样的操作需要开动我们的脑筋。让我们看一下下面的代码： 1234567891011121314151617181920212223242526272829303132template&lt;typename T, bool B&gt; struct enable_if_;template&lt;typename T&gt; struct is_arithmetic_;template&lt;typename T, bool B&gt;struct enable_if_ &#123; typedef T type;&#125;;template&lt;typename T&gt;struct enable_if_&lt;T, false&gt; &#123;&#125;;template&lt;typename T&gt;struct is_arithmetic_ &#123; enum &#123; value = false &#125;; &#125;;template&lt;&gt;struct is_arithmetic_&lt;int&gt; &#123; enum &#123; value = true &#125;; &#125;;template&lt;typename T&gt;typename enable_if_&lt;T, is_arithmetic_&lt;T&gt;::value&gt;::type add(T &amp;t1, T &amp;t2) &#123; return t1 + t2;&#125;int main() &#123; int a = 1, b = 2; cout &lt;&lt; &quot;add(a, b) = &quot; &lt;&lt; add(a, b) &lt;&lt; endl; // add(&quot;string&quot;, &quot;string&quot;); error: no matching function for call to &apos;add(const char [7], const char [7])&apos; return 0;&#125; 在实现add函数时，通过is_arithmetic_判断是否可以计算，如果可以，则允许该次类型推导，否则拒绝并报错。enable_if_和is_arithmetic_的实现都使用了模板特例化，对于is_arithmetic，我们认为的将所有可以计算的实例化，将value的值改为true（这里仅作演示，只对int进行实例化）。对于enable_if_，能够成功推导的，则保存其原始类型，否则不保存。这样，对于add(&quot;string&quot;, &quot;string&quot;);在编译时，编译器通过推导出is_arithmetic_::value == false，那么就选择特例化版本，而特例化版本的enable_if_中并没有type类型，所以该次推导失败。而add(a, b);部分正好相反，成功推导。 原始问题现在回到最初的问题当中，当定义一个模板参数时，可以为之匿名： 12template&lt;typename T, typename = void&gt;void foo(...) &#123;&#125; 这样，对于typename = decltype(std::declval&lt;F&gt;()(std::declval&lt;Args&gt;()...))的作用就非常清楚了。如果传入参数为函数，那么就会选择该实例，否则选择另一实例。如果不太明白还可以看看下面的例子： 123456789101112131415161718192021222324252627//// 让*.equal_range支持range-based循环//#include &lt;iostream&gt;#include &lt;map&gt;namespace std&#123; template&lt;typename Iter, typename = typename iterator_traits&lt;Iter&gt;::iterator_category&gt; Iter begin(pair&lt;Iter, Iter&gt; const &amp;p) &#123; return p.first; &#125; template&lt;typename Iter, typename = typename iterator_traits&lt;Iter&gt;::iterator_category&gt; Iter end(pair&lt;Iter, Iter&gt; const &amp;p) &#123; return p.second; &#125;&#125;int main()&#123; std::multimap&lt;int, int&gt; mm &#123; &#123;1, 1&#125;, &#123;1, 2&#125;, &#123;2, 1&#125;, &#123;2, 2&#125; &#125;; for(auto &amp;v : mm.equal_range(1)) &#123; std::cout &lt;&lt; v.first &lt;&lt; &quot; -&gt; &quot; &lt;&lt; v.second &lt;&lt; std::endl; &#125;&#125; 该代码摘抄自stackoverflow。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++:构造函数异常]]></title>
    <url>%2F2015%2F12%2F12%2FCPlusPlus%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[C++语言认为：一个对象在出生的过程中发生异常问题，那这个对象就是一个没有生命的怪胎。既然它不是一个完整的对象，就根本不存在析构或释放的说法。因此，C++在执行构造函数过程中产生异常时，是不会调用对象的析构函数的，而仅仅清理和释放产生异常前的那些C++管理的变量空间等，之后就把异常抛给程序员处理。所以构造函数失败时，说明构造出的对象不是一个完整的对象，如果严重，可能要直接终止程序，或通过修正改参数等重新构造，总而言之，要在构造函数内部把问题解决。 对于C++语言来说，由于构造函数产生异常时不会调用对应的析构函数，那么在构造函数里发生异常前的代码所创建的其他东西就不能被析构函数内的相关释放代码所释放。例如： class throw_ { public: throw_() { ... } }; class Object { public: Object() data(new int[100]) { throw_ t = throw_(); } ~Object() { delete []data; } private: int *data; }; throw_类的构造函数没有承若不抛出异常，所以这段代码中data指向的内存空间不能得到释放。除此之外，还有下面这种情况也会抛出异常: class Object { public: Object() { for (size_t i = 0; i &lt; 100; ++i) { data[i] = nullptr; } //... for (size_t i = 0; i &lt; 100; ++i) { data[i] = new int[1024 * 1024 * 1024]; } } ~Object() { for (size_t i = 0; i &lt; 100; ++i) { delete []data[i]; } } private: int *data[100]; }; 如果在申请空间的时候抛出：bad_alloc 异常，那么前面申请的内存将得不到释放，造成内存泄漏。这样可以改写如下： try { throw_ t = throw_(); } catch (Exception &amp;e) { delete []data; throw e; } 但是这么做只会使你的代码看上去混乱,而且会降低效率,这也是一直以来异常名声不大好的原因之一. 请借助于RAII技术来完成这样的工作: class throw_ { public: throw_() { ... } }; class Object { public: Object() data(make_shared(new int[100])) { throw_ t = throw_(); } ~Object() { } private: shared_ptr&lt;int&gt; data; }; 能这样做的原因是构造函数抛出异常时，已经构造的成员会逆序析构。 最后，其他人总结： C++中通知对象构造失败的唯一方法那就是在构造函数中抛出异常； 构造函数中抛出异常将导致对象的析构函数不被执行； 当对象发生部分构造时，已经构造完毕的子对象将会逆序地被析构；]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、中间代码(IR)]]></title>
    <url>%2F2015%2F12%2F10%2F%E5%85%AD%E3%80%81%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%A0%81-IR%2F</url>
    <content type="text"><![CDATA[中间代码中间代码的地位和作用中间代码的作用是可使程序的结构在逻辑上更为简单明确，特别是可使目标代码的优化比较容易实现中间代码，即为中间语言程序，中间语言的复杂性介于源程序语言和机器语言之间。 中间代码形式1、树和有向无环图(DAG) 其优点是高层表示，使用与源程序代码。2、三地址码 底层表示，接近于目标机器。3、控制流图(CFG) 更精细的三地址码，程序的图状表示，适合做程序分析、程序优化。4、静态单赋值形式(SSA) 更佳精细的控制流图，同时编码控制流信息和数据流信息。5、连续传递风格(CPS) 多用于函数式编程中，更一般的SSA。可以表达跨模块、函数的控制流。 程序优化和代码优化正是基于中间代码进行的。不同的中间代码在不同优化方面各有优劣，所以在做优化时常常需要在多种IR中进行转换。 DAGDAG和抽象语法树的不同之处在于，如果DAG中的一个节点N表示一个公共表达式，则N可能有多个父节点。因此DAG不仅更简洁的表示了表达式，而且可以为最终生成的表达式的高效代码提供重要的信息。 DAG构造在处理表达式部分抽象语法树时，我们把所有节点放入一个数组中，父节点通过数组索引找到其子节点。这种就称为该表达式的值编码。这个时候，就可以改变语法制导翻译时的代码，使得在为表达式创建节点时，先在数组中寻找是否有指定的&lt;op, l, r&gt;节点，然后决定是否创建。需要注意到是，每次定位一个节点都需要搜索整个数组，这个开销是非常大的，当一个数组中存放了整个程序所用的表达式时更是如此。更高效的办法是使用散列表，将节点放入若干桶中，每个桶通常只包含少量的节点。要给DAG中的节点构造散列表，首先需要建立散列函数(hash function)h。这个函数为形如&lt;op, l, r&gt;的三元组计算桶的索引。 三地址码三地址码拆分了多运算符算数表达式以及控制流语句嵌套的结构，所以适用于目标代码的生成和优化。其基于两个基本概念：地址和指令。地址描述了指令所在的位置信息，指令描述了该表达式进行的运算。 下面是常见的三地址指令形式： 形如x = y op z的赋值指令； 单目运算x = op y； 赋值指令x = y； 无条件转移指令goto L, 其中L表示下一部将要执行的指令是带有标号L的三地址指令； 条件转移指令if x goto L和iffalse x goto L； 形如if x relop y goto L的条件转移指令。它对x和y应用于一个关系运算符(&lt;,&lt;=,&gt;,&gt;=,!=,==)，然后根据结果跳转； 过程调用和返回系列指令，param x进行参数传递，call p, n和y = call p, n表示进行过程调用(其中n表示参数数目)，return x表示返回操作y是返回值； 带下标的复制指令x = y[i]和y[i] = x； 形如x = &amp;y、x = *y和*x = y的指令及指针赋值指令； 表示三地址码的表示方式有多种，如果需要有变量这个概念，则可以用四元组表示。 四元组表示一个四元式(quadruple)有四个字段，分别称为：op、arg1、arg2、result。这种方式表示的三地址码再做寄存器分配时会更优一点。该方法在描述三地址码是存在一些特例： 形如x = -y的单目运算指令和复制指令都不使用arg2； param x这类指令既不是用arg2，也不使用result； 条件转移指令将目标标号放入result中； 如果不需要变量概念，直接使用运算结果隐式地表示临时变量，则可以使用三元组表示。 三元组表示三元式(triple)只有三个字段，即没有result，而使用其位置来表示它的结果。也就是： 对于 1 x = y op z 2 a = x op 1 可以写成 1 y op z 2 (1) op 1 其中(1)表示该位置的值为位于地址1的指令的结果 在高层优化时，使用这种方式会比较简单。需要注意的是，在优化编译器时，由于指令的位置常常会发生变化，四元式相对于三元式的优势就体现出来了。使用四元式时，可以不需要修改。使用三元式时需要修改所有引用其位置的指令。当然可以使用 间接三元式 来解决这个问题。间接三元式包含了一个指向三元式的指针列表，而不是三元式序列本身。这样，在修改时，只需要修改指针指向位置即可。 控制流图三地址码结构并不明显，在控制流优化、数据流分析中并不方便。而控制流图则利于做控制流优化和数据流分析。在控制流图中，一个语句序列，能够从头执行到尾（即跳转指令只能出现在末尾）被称为基本块。而控制流图就是以基本块为节点，跳转信息为边的图。 控制流图构造方法首先找出基本块，然后建立连接。基本块算法如下： 找基本块入口源代码的首行或者转移代码（有条件和无条件）或者转移代码的下一行 基本块构造：通过入口点开始，将其组成各自的基本块。基本块语句序列的特征：从不包含它本身的进入点到其他进入点或者到某条转移语句或者到某条停止语句 如果有语句不在任一基本块中，那么它为”死代码“，删除 然后就是控制流图构造。如果在一个有序代码中，基本块B2跟在B1后，那么产生一个由B1到B2的有向边。 有跳转点。这个点从B1的结束点跳到B2的开始点 无跳转点（有序代码中），B2跟在B1后，且B1的结束点不是无条件跳转语句 静态单赋值形式在数据流分析中需要寻找表达式中每个定值的使用点。定值-使用链(def-use chain)是一种能够高效获取这些信息的数据结构：对流图中的每条语句，编译器能够保存两个由指针组成的列表，其中一个列表中的指针指向在该语句中定值的变量的所有使用点，另一个列表中的指针指向该语句中使用的变量的所有定值点。而静态单赋值形式(static single assignment from)是对def-use chain的一种改进思想。SSA形式是这样一种中间表示：在程序正文中，每个变量只有一个定值，而这个定值可能位于一个可动态执行多次的循环中，因此称为静态单赋值形式，而不是单赋值。在用SSA形式表示的过程中，def-use chain是显示的：变量的使用可能用到一个特定定值产生的值，当且仅当在该过程的SSA形式中此变量的定值和使用具有完全相同的名字。 将普通代码转换为SSA形式代码标准方法是每一个赋值的变量带上一个下标，并在流图中的汇合点使用Ø函数（即形式为Ø（x,x,x…,x）的函数），以区分对一个变量的多种赋值。每一个函数具有的参数个数同汇合到那一点的该变量的不同版本个数一样多，并且每一个参数与该点的一个特定控制流前驱相对应。 抽象语法书到三地址码首先是设计三地址码，这里采用的三地址码和龙书提到的并不完全一样，为了简化工作，将Relop部分和数组相关部分也译成运算，即没有IfRelop运算。三地址部分结构如下： public class IR { public static abstract class Quad implements Acceptable { public Quad prev = null; public Quad next = null; public Quad() { prev = this; next = this; } } public static class Var { } public static class FVar extends Var { public Float fnum; public FVar(float f) { this.fnum = f; } public String toString() { return &quot;&quot; + this.fnum; } } public static class IVar extends Var { public Integer num; public IVar(int num) { this.num = num; } public String toString() { return &quot;&quot; + this.num; } } public static class CVar extends Var { public char c; public CVar(char c) { this.c = c; } public String toString() { return &quot;&quot; + c; } } public static class ID extends Var { public String name; public ID(String name) { this.name = name; } public String toString() { return name; } } public static class Str extends Var { public String str; public Str(String str) { this.str = str; } public String toString() { return &quot;\&quot;&quot; + str + &quot;\&quot;&quot;; } } public static class Temp extends Var { public String name; public Temp() { name = &quot;t&quot; + getIndex(); } public static int index = 0; public static int getIndex() { return index++; } public String toString() { return name; } } public static class Array extends Var { public Var exp; public Var index; public Array(Var e, Var i) { this.exp = e; this.index = i; } public String toString() { return exp.toString() + &quot;[&quot; + index.toString() + &quot;]&quot;; } } public static class Label extends Quad { public String address; public Label() { address = &quot;L&quot; + getIndex(); } public void accept(Visitor v) { v.visit(this); } public static int index = 0; public static int getIndex() { return index++; } } public static class Assign extends Quad { public Op op; public Var arg1; public Var arg2; public Var result; public Assign(Op o, Var a1, Var a2, Var res) { this.op = o; this.arg1 = a1; this.arg2 = a2; this.result = res; } public void accept(Visitor v) { v.visit(this); } enum Op { Add, Sub, Mul, Div } } public static class SingleAssign extends Quad { public Var arg; public Var result; public SingleAssign(Var arg, Var res) { this.arg = arg; this.result = res; } public void accept(Visitor v) { v.visit(this); } } public static class Copy extends Quad { public Var arg; public Var result; public Copy(Var arg, Var res) { this.arg = arg; this.result = res; } public void accept(Visitor v) { v.visit(this); } } public static class Goto extends Quad { public Label label; public Goto(Label label) { this.label = label; } public void accept(Visitor v) { v.visit(this); } } public static class If extends Quad { public Var condition; public Label label; public If(Var con, Label label) { this.condition = con; this.label = label; } public void accept(Visitor v) { v.visit(this); } } public static class IfFalse extends If { public IfFalse(Var con, Label label) { super(con, label); } public void accept(Visitor v) { v.visit(this); } } public static class RelopCopy extends Quad { public Var arg1; public Var arg2; public Relop relop; public Var result; public RelopCopy(Var a1, Var a2, Relop relop, Var result) { this.arg1 = a1; this.arg2 = a2; this.relop = relop; this.result = result; } public void accept(Visitor v) { v.visit(this); } enum Relop { GT, GEQT, LT, LEQT, EQ, } } public static class Param extends Quad { public Var val; public Param(Var v) { val = v; } public void accept(Visitor v) { v.accept(this); } } public static class Call extends Quad { public Var name; public int num; public Var result; public Call(Var name, int num, Var res) { this.name = name; this.result = res; this.num = num; } public Call(Var name, int num) { this(name, num, null); } public void accept(Visitor v) { v.visit(this); } } public static class Return extends Quad { public Var arg; public Return(Var a) { this.arg = a; } public void accept(Visitor v) { v.visit(this); } } } 其中关于值的部分设计是以Var作为父类，派生出不同的类型。其中Temp表示在翻译过程中产生的临时变量。所有的指令都继承自Quad，整体采用双向链表实现。需要注意的是为了方便起见，我将Label也加入Quad中。 再翻译过程中，使用this.var保存该语法树节点返回值。对于一般的运算，直接翻译并存储到临时变量中： public void visit(AddSubExp exp) { exp.left.accept(this); Var l = this.var; exp.right.accept(this); Var r = this.var; this.var = new IR.Temp(); IR.Assign.Op op = exp.isAdd ? IR.Assign.Op.Add : IR.Assign.Op.Sub; quad.add(new IR.Assign(op, l, r, this.var)); } 对于if需要记录条件成功和失败时跳转的标签位置(如果有else，还需要结束位置，而没有else时，结束位置就是失败时跳转位置)。为了处理嵌套结构，我是用栈来记录当前活跃的跳转地址： public void visit(IfStatement s) { Label true_ = new Label(); Label false_ = new Label(); Label next = new Label(); stack.push(true_); stack.push(false_); s.condition.accept(this); if (this.var != null) { quad.add(new IR.If(this.var, true_)); quad.add(new IR.Goto(false_)); } stack.pop(); stack.pop(); quad.add(true_); s.ifStatements.accept(this); if (s.hasElse) { quad.add(new IR.Goto(next)); quad.add(false_); s.elseStatements.accept(this); quad.add(next); } else { quad.add(false_); } } 当我们后续处理完condition部分时，this.var为空，表示并没有返回值，而此处if (this.var != null)是为了处理if (1)这样的没有生成condition的节点。如果有else，需要在else所属语句块前加上跳转指令，以跳转到if结束。 while部分结构和if类似，不过还需要记录整个语句开头位置，并在语句执行完下一句添加无条件转移，从而形成循环。当while中出现break和continue指令时，需要分别跳转到末尾和开头。 在处理与和或指令时，分别对前面记录的栈顶位置进行跳转即可： public void visit(AndOrExp exp) { if (exp.isAnd) { for (Exp.T t : exp.exps) { t.accept(this); if (this.var == null) continue; quad.add(new IR.IfFalse(this.var, stack.peek())); } if (this.var == null) return; quad.add(new IR.Goto(stack.elementAt(stack.size()-2))); } else { for (Exp.T t : exp.exps) { t.accept(this); if (this.var == null) continue; quad.add(new IR.If(this.var, stack.elementAt(stack.size()-2))); } if (this.var == null) return; quad.add(new IR.Goto(stack.peek())); } this.var = null; } 其中如果出现嵌套结构，那么返回值可能为空，此时不需要生成相关指令，忽略。 最后需要注意到的是我对每一个作用于进行了命名，并且对在作用于声明的变量统一添加上该作用于名称的，这样做是为了防止名称冲突： var a = 0; if (a) { var a = &quot;asdf&quot;; } 上面部分展示了名称冲突。 当这里为止，前端部分基本上完成，关于后续部分，交给另外两个阶段完成。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、语义分析]]></title>
    <url>%2F2015%2F12%2F10%2F%E4%BA%94%E3%80%81%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[语义分析语义分析是编译过程的一个逻辑阶段，语义分析的任务是对结构上正确的源程序进行上下文有关性质的审查，进行类型审查。语义分析是审查源程序有无语义错误，为代码生成阶段收集类型信息。比如语义分析的一个工作是进行类型审查，审查每个算符是否具有语言规范允许的运算对象，当不符合语言规范时，编译程序应报告错误。如有的编译程序要对实数用作数组下标的情况报告错误。又比如某些某些程序规定运算对象可被强制，那么当二目运算施于一整型和一实型对象时，编译程序应将整型转换为实型而不能认为是源程序的错误。 符号表符号表是用来存放源程序中出现的有关名字的属性信息，这些信息集中反映了名字的语义特征属性。符号表在编译全过程的地位和作用非常重要，是进行上下文合法性检查和语义处理及代码生成的依据。符号表总体结构的设计和实现是与源语言的复杂性（包括词法结构、语法结构的复杂性）有关，还与对于编译系统在时间效率和空间效率方面的要求有关。 符号表有多种表示方式，而该程序需要用到嵌套作用于，所以符号表应该如下： public class Scope { public Scope parent; private HashMap&lt;String, Type&gt; map; public Scope(Scope parent) { this.parent = parent; this.map = new HashMap&lt;String, Type&gt;(); } public void put(String name, Type type) { this.map.put(name, type); } public Type findInCurrent(String name) { if (!this.map.containsKey(name)) { return Type.NOT_FOUND; } else { return this.map.get(name); } } public Type find(String name) { Type type = this.findInCurrent(name); if (type == Type.NOT_FOUND) { if (this.parent != null) { return parent.find(name); } } return type; } public enum Type { ID, INT, CHAR, FLOAT, STRING, ARRAY, FUNCTION, NOT_FOUND } } 整个符号表呈现树形状，不过其中通过 parent 与父节点建立连接，这也方便遍时后回溯。这样，在每次定义变量、函数时将其名称及相关数据记录进符号表： public void visit(VarDecl s) { s.exp.accept(this); scope.put(s.id, Type.ID); } 其中如果当前scope中s.id的值已经定义则报错。每次使用时查找是否进行定义： public void visit(Id id) { Type type = scope.find(id.id); if (type == Type.NOT_FOUND) { Error.instance().PrintMsg(&quot;var &quot; + id.id + &quot; not defined!&quot;); } this.type = type; } 作用域按照上面的符号表构建，当查找变量时，首先在当前作用于中遍历一次，没有找到则遍历父节点。通过这种方式，可以实现作用域屏蔽： var x = 1; function func() { var x = 1.0f; } x == 1; 在内层作用域中，并不会对外部数据进行覆盖。 类型检查类型检查主要在两个部分：语义分析、运行时类型检查。语义分析部分主要针对的是常量部分的类型检查如&quot;string&quot; + 1这样的用法错误。而变量等存在如下情况： var x = 1; if (condition) { x = &quot;string&quot;; } func(x); 在调用func(x)时，无法得知当前的x的具体类型，所以这部分需要交给运行时类型检查完成。而对于如下的运算，需要进行类型转换： var x = 1 + 0.5; var y = &apos;c&apos; + 1; 因为只有数值类型可以进行类型相互转换，所以在判断时： private boolean numberic(Type type) { return (type == Type.CHAR || type == Type.INT || type == Type.FLOAT); } private void needType(Type type) { if (this.type != type &amp;&amp; this.type != Type.ID) { if (!numberic(type) || !numberic(this.type)) { Error.instance().PrintMsg(&quot;need &quot; + type.toString() + &quot; but get &quot; + this.type.toString()); } } } private Type maxType(Type left, Type right) { if (left == right) { return left; } else if (left == Type.FLOAT || right == Type.FLOAT) { return Type.FLOAT; } else if (left == Type.INT || right == Type.INT) { return Type.INT; } else { return Type.CHAR; } } 在判断是否指定类型(needType)时，如果不是相同类型、并且当前类型并不是ID(即不能判断)，且双方都不是数值类型，那么肯定错误。当双方都是数值类型时，可以通过maxType计算返回值类型(其中有类型提升)。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、语法制导翻译]]></title>
    <url>%2F2015%2F12%2F07%2F%E5%9B%9B%E3%80%81%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[语法制导翻译分析树在语法知道翻译之前，先来了解程序代码在内存中的表示方法。大部分程序员对于树形结构肯定是并不陌生，而树形结构也正好适合程序结构的表达。 比如if语句的树形表示如下： root + ---- condtion ---- if_statement ---- else_statement 分析树表示方法有多种，而这里选择使用异形树来表示，因为它更加直观。下面就是异形树表示if的例子： public static class IfStatement extends T { public Exp.T condition; public Stm.T ifStatements; public boolean hasElse; public Stm.T elseStatements; public IfStatement(Exp.T condition, Stm.T ifStatement, Stm.T elseStatement) { this.condition = condition; this.ifStatements = ifStatement; this.hasElse = elseStatement != null; this.elseStatements = elseStatement; } public IfStatement(Exp.T condition, Stm.T ifStatement) { this(condition, ifStatement, null); } @Override public void accept(Visitor v) { v.visit(this); } } 其中的T是所有Statement的基类。异形树的代码非常直观，能够一眼就明白具体是做什么！然而，异形树充斥着大量冗余操作。你必须为每一个产生式都写出相应的生成代码以及访问代码。 其中的accept(Visitor v)方法属于 Visitor 模式的应用，Visitor 属于 interface ，这样不仅解决了向下转型的问题，还使得对于多种生成树遍历方法，不需要修改原有的代码。如果使用解释器模式，就无法实现解耦。 制导动作在语法分析的部分，关于if分析部分的代码如下： // &quot;if&quot; &quot;(&quot; assign_exp &quot;)&quot; statement [&quot;else&quot; statement] // case KEYWORD_IF: { advance(); eatToken(Kind.TOKEN_LPAREN); parseAssignExp(); eatToken(Kind.TOKEN_RPAREN); parseStatement(); if (current.kind == Kind.TOKEN_KEYWORD &amp;&amp; current.keyword == Keyword.KEYWORD_ELSE) { advance(); parseStatement(); } return; } 可以看到的是，在分析语法时，直接抛弃了源代码中的信息而不是储存下来。那么只需要在该部分添加相应的语法分析动作，来生成分析树即可。修改后代码如下： case KEYWORD_IF: { advance(); eatToken(Kind.TOKEN_LPAREN); Exp.T exp = parseAssignExp(); eatToken(Kind.TOKEN_RPAREN); Stm.T if_ = parseStatement(); Stm.T else_ = null; if (current.kind == Kind.TOKEN_KEYWORD &amp;&amp; current.keyword == Keyword.KEYWORD_ELSE) { advance(); else_ = parseStatement(); } return new Stm.IfStatement(exp, if_, else_); } 也就是我们在分析阶段，将所有的非终结符信息记录下来，并填入相应的生成树节点中。 抽象语法树生成树极大的保留了程序源代码的结构，使得我们可以轻松的恢复其原先的代码。不过，多数时候，我们所做的工作并不关心其中的大部分数据，这就造成了大量冗余代码的产生。 举个例子，假设有调用函数：id(exp);语句，其产生分析树应该如下： exp + and or exp + condition exp + add sub exp + mul div exp + ... 其中有很大一部分属于冗余信息，即我们并不关心这部分数据。下面是我们希望见到的语法树： call + ---- id ---- exp 这就是抽象语法树。相比语法树，抽象语法树在时间和空间方面都有极大的优化。关于抽象语法树的建立，只需要在 parse 部分稍稍修改，就能极大地化简分析树： private Exp.T parseConditionExp() { Exp.T exp = parseAddSubExp(); while (current.kind == Kind.TOKEN_ADD || current.kind == Kind.TOKEN_SUB) { Kind kind = current.kind; advance(); exp = new Exp.AddSubExp(kind == Kind.TOKEN_ADD, exp, parseAddSubExp()); } return exp; } 这段代码用于分析 + - 法。可以看到如果当前节点并不关加减法什么卵事，就会跳过AddSubExp的构造。按照这个步骤，最终程序返回的就是一棵非常精简的树。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、语法分析]]></title>
    <url>%2F2015%2F12%2F04%2F%E4%B8%89%E3%80%81%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[自顶向下的语法分析自顶向下语法分析器从语法分析树的根开始，系统化地向下扩展树，直至树的叶节点与词法分析器返回的以归类单词相匹配。该过程在树的下边缘选择一个非终结符，选定某个适用于该非终结符的产生式，用与该产生式右侧相对应的子树扩展结点。 自顶向下语法分析器的优化而自顶向下语法分析器的效率极其依赖于其在扩展非终结符时选择正确产生式的能力。如果语法分析其总是做出正确的选择，那么其效率是非常高的；如果与之相反，那么分析代价将直线上升。在编程语言实现模式一书中，提到通过记忆化，可以使得回溯变代价变小。 递归下降分析算法语法分析器可以利用一个简单的修改来避免回溯。在语法分析器去选择下一条规则时，他可以同时考虑当前关注的符号以及下一个输入符号，称为前瞻符号。通过前瞻一个符号，可以消除在解析右递归表达式语法时多种选择造成的不确定性。 // 递归下降语法框架 假设有如下文法产生式： A -&gt; B11 ... B1i | B21 ... B2j | B31 ... B3k | ... 那么就可以为 A 写出如下分析代码： parse_A() token = nextToken() switch (token) case ...: // B11 ... B1i case ...: // B21 ... B2j case ...: // B31 ... B3k ... default: error(...); 为了描述这个前瞻符号，需要引入 FIRST 集合和 FOLLOW 集合。对于每个语法符号 a, 集合 FIRST(A) 为：从 A 推导出的每个符号串的第一个单词所对应的终结符的集合；而对于 FOLLOW(A) 表示紧跟在 A 导出的符号串之后的所有可能单词。使用 FIRST 和 FOLLOW 集合，可以准确的使得某个语法对自顶向下语法分析器无回溯的条件。对于产生式 A -&gt; B ，定义其增强 FIRST 集合 FIRST+ 如下： FIRST+(A-&gt;B) = FIRST(B) 如果 FIRST(B) 不包含空产生式 FIRST(B) U FOLLOW(A) 否则 在介绍 FIRST 集构造方法之前，需要引入 NULLABLE 集合的概念。如果一个非终结符X属于集合 NULLABLE ，当且仅当： 基本情况：X -&gt; 归纳情况：X -&gt; Y1 …. Yn 中， Y1, ….Yn 是 n 个非终结符，且都属于 NULLABLE 集 下面看到的是 NULLABLE 集合算法： NULLABLE = {} while (nullable is still changing) foreach (production p : x -&gt; B) if (B == null) NULABLE U= {X} if (B == Y1 ... Yn) if (Y1 belong NULLABLE &amp;&amp; .... &amp;&amp; Yn belong NULLABLE) NULLABLE U= {X} 下面，展示 First 集的不动点算法： foreach (nonterminal N) FIRST(N) = {} while (some set is changing) foreach (production p : N-&gt;B1 ... Bn) foreach (Bi form B1 upto Bn) if (B1 == a) FIRST(N) U= {a} break; if (Bi == M) FIRST(N) U= FIRST(M) if (M is not in NULLABLE) break; 刚开始的时候每个非终结符都为空集。如果每次遍历完成，仍然有集合被改变时，可能会影响到其他的非终结符的集合，所以仍然需要遍历。对于每一个产生式，第一个元素如果是终结符，把该终结符加入 FIRST 集合；如果第一个是非终结符，那么把该非终结符加入 FIRST 集合，如果该非终结符属于 NULLABLE ，那么还需要再次判断紧接着的符号。 现在来看 FOLLOW 集的不动点算法： foreach (nonterminal N) FOLLOW(N) = {} while (some set is changing) foreach (production p : N -&gt; B1 ... Bn) temp = FOLLOW(N) foreach (B1 form Bn downto B1) if (Bi == a) temp = {a} if (Bi == M) FOLLOW(M) U= temp; if (M is not NULLABLE) temp = FIRST(M) else temp U= FIRST(M) 其中 temp 表示的是当前位置的 FOLLOW 集，初始时为当前产生式的 FOLLOW 集。现在计算该产生式关联到的非终结符的 FOLLOW 集。因此从产生式后往前看，如果是终结符，则把 temp 更新为当前终结符。如果当前为非终结符 M ，由于 temp 是当前位置的 FOLLOW 集，所以将其加入 M 的 FOLLOW 集中。现在考虑 temp 位置移动，如果当前 M 不属于 NULLABLE ，那么表示不会穿过 M ，所以 temp = FIRST(M) ，否则应该 temp U= FIRST(M) 。 通过 FIRST 和 FOLLOW 集合，可以得到 FIRST+ 集合，这样就可以编写程序实现了。当然，并不是所有的语法都是无回溯的。这个时候需要重写产生式，将公共左因子提取出来，从而消除回溯。 左递归在自顶向下分析中，如果产生式中有做递归的情况，分析器将出现无限循环的现象。这个时候，需要将左递归转换为右递归。对于直接做递归，引入一个新的非终结符即可解决，对于间接左递归，需要先重写为直接左递归，然后再修改右递归。 程序实现这里给出描述的这门语言的文法产生式，可以看到该语言文法产生式十分简单，对于手写来说，并不算复杂。 atom_exp: ID | FLOAT_LITERAL | INTEGER_LITERAL | CHAR | STRING | &quot;(&quot; exp &quot;)&quot; | ID &quot;(&quot; exp_list &quot;)&quot; | &quot;[&quot; exp_list &quot;]&quot; exp_list: exp { &quot;,&quot; exp } not_exp: atom_exp [ &quot;[&quot; exp &quot;]&quot; ] mul_div_exp: &quot;!&quot; mul_div_exp | not_exp add_sub_exp: mul_div_exp (&quot;*&quot; | &quot;/&quot; | &quot;%&quot;) mul_div_exp | mul_div_exp conditon_exp: add_sub_exp (&quot;+&quot; | &quot;-&quot;) add_sub_exp | add_sub_exp and_exp: condition_exp (&quot;&lt;&quot; | &quot;&gt;&quot; | &quot;&gt;=&quot; | &quot;&lt;=&quot; | &quot;==&quot;) condition_exp | conditoin_exp or_exp: and_exp &quot;&amp;&amp;&quot; and_exp | and_exp exp: or_exp &quot;||&quot; or_exp | or_exp assign_exp: exp &quot;=&quot; exp | exp var_decl: &quot;var&quot; ID &quot;=&quot; assign_exp &quot;;&quot; statement: block | &quot;if&quot; &quot;(&quot; assign_exp &quot;)&quot; statement [&quot;else&quot; statement] | &quot;while&quot; &quot;(&quot; assign_exp &quot;)&quot; statement | &quot;return&quot; assign_exp &quot;;&quot; | &quot;break&quot; &quot;;&quot; | &quot;continue&quot; &quot;;&quot; | assign_exp &quot;;&quot; | var_decl block: &quot;{&quot; { statement} &quot;}&quot; formal_list: ID { &quot;,&quot; ID } function_decl: &quot;function&quot; ID &quot;(&quot; formal_list &quot;)&quot; block program: { function_decl } 这里使用 EBNF 进行描述。在写代码时，对于每一个非终结符，都有与之对应的 parseXXX 函数对它进行解析。这里使用 if 语句的文法产生式，能够很清楚的看到编码方式： //statement: // block // | &quot;if&quot; &quot;(&quot; assign_exp &quot;)&quot; statement [&quot;else&quot; statement] // | &quot;while&quot; &quot;(&quot; assign_exp &quot;)&quot; statement // | &quot;return&quot; assign_exp &quot;;&quot; // | &quot;break&quot; &quot;;&quot; // | &quot;continue&quot; &quot;;&quot; // | assign_exp &quot;;&quot; // | var_decl // private void parseStatement() { //System.out.println(current.toString()); if (current.kind == Kind.TOKEN_LBRACE) { parseBlock(); return; } else if (current.kind == Kind.TOKEN_KEYWORD) { switch (current.keyword) { case KEYWORD_IF: { advance(); eatToken(Kind.TOKEN_LPAREN); parseAssignExp(); eatToken(Kind.TOKEN_RPAREN); parseStatement(); if (current.kind == Kind.TOKEN_KEYWORD &amp;&amp; current.keyword == Keyword.KEYWORD_ELSE) { advance(); parseStatement(); } return; } case KEYWORD_WHILE: { advance(); eatToken(Kind.TOKEN_LPAREN); parseAssignExp(); eatToken(Kind.TOKEN_RPAREN); parseStatement(); return; } case KEYWORD_RETURN: { advance(); if (current.kind != Kind.TOKEN_SEMI) { parseAssignExp(); } eatToken(Kind.TOKEN_SEMI); return; } case KEYWORD_CONTINUE: { advance(); eatToken(Kind.TOKEN_SEMI); return; } case KEYWORD_BREAK: { advance(); eatToken(Kind.TOKEN_SEMI); return; } case KEYWORD_VAR: parseVarDecl(); return; default: error(); break; } } else { parseAssignExp(); eatToken(Kind.TOKEN_SEMI); return; } } 代码中的 advance() 部分如下： private void advance() { current = lexer.nextToken(); } eatToken() 一部分如下： private void eatToken(Kind kind) { if (kind == current.kind) advance(); else { // 错误处理 } } 那么可以清晰的看到，我们每次都通过当前读入的 Token ，选择相应的文法树。一直重复这个过程，就可以实现语法分析。需要注意的是，这里面关于表达式的匹配的部分也是使用文法定义，导致这部分代码占据了大部分的内容。且还要注意各个符号的结合性（将在下一部分看到）。关于表达式中代码是隐含了运算符的优先级，所以不需要单独判断。不过有部分 parse 在实现表达式解析的时候，单独采用了表达式解析法，而不是递归下降分析法。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、词法分析]]></title>
    <url>%2F2015%2F12%2F03%2F%E4%BA%8C%E3%80%81%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[词法分析词法分析是编译器前段的第一个阶段，它将源代码按照一定的规则分割为记号流，然后传递给语法分析器进行下一步处理。在词法分析中，需要记录下源代码的信息，以供后续阶段使用。 词法分析有ad-hoc和自动机识别两种方式。自动机识别时，需要手工构造正则表达式并输入自动机，然后自动机根据正则表达式生成NFA。直接解析NFA开销过大，所以需要把NFA转化成为DFA。这时候得到的DFA有许多可以精简的状态，所以可以做DFA最小化，然后得到最小的DFA。这样自动机就可以自动识别并返回记号。 正则表达式到 NFA正则表达式到 NFA 有 McMaughton-Yamada-Thompson 算法，涉及到贴图原因，这里就不讲了。 从 NFA 到 DFA 的转换由于 NFA 对于一个输入符号可以选择不同的转换，它还可以执行输入上的 ε 转换，所以直接对 NFA 进行模拟不方便，需要转换成 DFA。NFA 到 DFA 可以由子集构造法（subset construction）构造。 输入：一个 NFA N;输出：一个 DFA D;方法：该算法为 D 构造一个转换表 Dtran。D 的每一个状态是 NFA 中状态的集合。在该算法之前需要引入如下几个操作： ε-closure(s) 能够从 NFA 的 s 状态只通过 ε 转换到达的状态集合； ε-closure(T) 能够从 T 中某个 NFA 状态 s 开始，只通过 ε 转换达到的状态集合； move(T, a) 能够从 T 中某个状态 s 出发通过标号为 a 的转换到达的 NFA 状态的集合； 该算法有一个记录新产生的 D 的状态的表：Dstates，在算法开始时，为 ε-closure(s) 产生一个状态做为起始状态。将起始状态放入工作列表。对于工作列表中的状态 T ，找出任意输入 a 能到达的集合 C = move(T, a) ，求得 C 对应的状态 ε-closure(C)， 如果 ε-closure(T) 状态没有包含在 Dstates 中，则创建一个新状态并加入工作列表。最后将 Dtran[T, a] = C。 该算法伪代码如下： A = ε-closure(s0); Dstate.insert(A); queue.push(A); while (!queue.empty()) { T = queue.front(); queue.pop(); for (auto i : input) { C = ε-closure(move(T, i)); if (Dstate.count(C) == 0) { Dstate.insert(C); } Dtran[T][i] = C; } } return Dtran; 其中的 ε-closure(T) 可以通过下面的代码得到 ε-closure(T) { stack.push(T.states); res = null; while (!stack.empty()) { s = stack.pop(); for (auto i : 所有NFA状态) { if (s 有一条 ε 转换到 i &amp;&amp; res.count(i) == 0) { res.insert(i); stack.push(i); } } } return res; } DFA 状态最小化对于一个NFA，当把它确定化之后，得到的DFA所具有的状态数可能并不是最小的。其原因之一，就在于上面所给出的确定化算法没有考虑到DFA中具有某种“同一性“的一些状态可加以合并的问题。所谓一个DFA M状态数的最小化，是指构造一个等价的DFA M′，而后者有最小的状态数。所谓状态数最小，指的是对于原来状态中任意两个状态，能被划分到一组当且仅当对于所有输入，这两个状态都到达同一个组，这样所得到的分组组成的状态，即状态数最小化。 现在，让我们来看一下简单的 Hopcroft 算法： // 基于等价类的思想 split(S) foreach (character c) if (c can split S) split S into T1, ..., TK hopcroft() split all nodes into N, A while (set is still changes) split(all S) c can split S 的意思是如果 S 集合中存在两个状态可以通过 c 转移到不同的目标状态，那么就是可以切分（split）的。而一开始的 split 的目的是将一般状态和接受状态，这样做的目的是为了保证最后切分完成后，不存在任意一个由接受状态和一般状态组成的状态（因为这样就不知道这里是不是该接受）。 DFA 模拟输入：一个以eof结尾的字符串x，DFA 的开始状态为 s0 ，接受状态为 F ，转换函数为 move;输出：如果 D 接受 x ，返回 yes，否则返回 No；方法：对于每一个输入字符 c ，当前状态的值 s 由状态 move 函数得到，直到文件尾。如果 s 在 F 中，则返回 yes，否则返回 no ； 算法伪代码如下： s = s0; c = nextChar(); while (c != eof) { s = move(s, c); c = nextChar(); } if (F.contain(s)) return &quot;yes&quot;; else return &quot;no&quot;; 因为这里得到的 DFA 其实就是一个有向图，所以程序可以使用有向图表示方式来表示 move 。 实践在实践中，需要处理标识符、关键字、字符串常量等进行特殊处理。关键字有多种表示方法，可以硬编码到 TOKEN 中，如 TOKEN_IF ，也可以当作标识符处理，也就是说，当词法分析器分析出标识符后，与已知的关键字进行比较，从而区分关键字和标识符。 在这里我采用单独编码关键字部分，那么Token部分设计就分为Kind、Keyword: public enum Keyword { KEYWORD_ELSE, // &quot;else&quot; KEYWORD_IF, // &quot;if&quot; KEYWORD_RETURN, // &quot;return&quot; KEYWORD_WHILE, // &quot;while&quot; KEYWORD_BREAK, // &quot;break&quot; KEYWORD_CONTINUE, // &quot;continue&quot; KEYWORD_FUNCTION, KEYWORD_VAR, // var } public enum Kind { TOKEN_ADD, // &quot;+&quot; TOKEN_DIV, // / TOKEN_MOD, // % TOKEN_AND, // &quot;&amp;&amp;&quot; TOKEN_OR, // || TOKEN_ASSIGN, // &quot;=&quot; TOKEN_EQ, // &quot;eq&quot; TOKEN_COMMER, // &quot;,&quot; TOKEN_DOT, // &quot;.&quot; TOKEN_EOF, // EOF TOKEN_ID, // Identifier TOKEN_LBRACE, // &quot;{&quot; TOKEN_LBRACK, // &quot;[&quot; TOKEN_LPAREN, // &quot;(&quot; TOKEN_LT, // &quot;&lt;&quot; TOKEN_GT, // &quot;&gt;&quot; TOKEN_LEQT, // &quot;&lt;=&quot; TOKEN_GEQT, // &quot;&gt;=&quot; TOKEN_NOT, // &quot;!&quot; TOKEN_NUM, // IntegerLiteral TOKEN_FLOAT, // float literal TOKEN_RBRACE, // &quot;}&quot; TOKEN_RBRACK, // &quot;]&quot; TOKEN_RPAREN, // &quot;)&quot; TOKEN_SEMI, // &quot;;&quot; TOKEN_SUB, // &quot;-&quot; TOKEN_TIMES, // &quot;*&quot; TOKEN_KEYWORD, // TOKEN_CHAR, TOKEN_STRING, } Token部分需要记录相关信息： public class Token { public Kind kind; public Keyword keyword; public char c; public Integer num; public Float fnum; public String lexeme; public Integer lineNum; public Integer col; } 当然，这样设计肯定不合理的，考虑到这部分内容更多是为了完成，就采取这种编码方式更少的了。 在lexer中，主要采用ad-hoc，即手工编写： switch (c) { case &apos;%&apos;: kind = Kind.TOKEN_MOD; break; case &apos;+&apos;: kind = Kind.TOKEN_ADD; break; case &apos;-&apos;: kind = Kind.TOKEN_SUB; break; ... } 这里对数据的处理方式肯定是不对的，要使用String table才是好办法。 string table字符串比较耗时比较大，并且代码中标识符重用率也比较多，所以可以使用 string table 来记录出现过的标识符，这样不仅省了空间，在判断是否相等时的时间开销也降低了。 比较简单的实现方式是对每个标识符进行 hash ，然后将每个 hash 值放入一个桶中进行分类。每次插入的时候就在桶中进行匹配，没有找到则插入，否则返回原来实例的索引即可。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、语言基本要素]]></title>
    <url>%2F2015%2F12%2F02%2F%E4%B8%80%E3%80%81%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E8%A6%81%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[来源学习编译原理之后，想尝试着用学习的知识写一个简单的编译器，并把它放在 github 上，当作对自己学习成果的检验和练习。而写博客，则是一种鞭策，驱动我坚持不懈地写下去。所以准备从无到有写一个系列，希望能对后来的学习者有所帮助。 准备首先写前端，然后翻译成字节码，构建运行时程序，并在这个基础上，进行代码优化相关内容。其中涉及到的知识有词法分析、语法分析、语义分析、类型检查、全文CPS变换、字节码解释器、垃圾回收、控制流程图、数据流分析。鉴于能力有限，不可能面面聚到，有的只能做一个简单介绍。 目标这个目标分为三个阶段，第一个阶段是自己动手写一个编译器，将源代码翻译成中间代码。第二个阶段是设计一个Scheme解释器。第三个阶段是研究现有的编译器中间代码及优化等部分。 编译器实现的是一种简单的编程语言，在设计的时候尽可能的精简、方便实现。这个语言设计来源于虎书的 MiniJava , 代码则是采用的 http://staff.ustc.edu.cn/~bjhua/courses/compiler/2014/ 中提供的代码基础上进行了一定的修改，使用 java 实现。首先看一个简单的例子： function f(arg1, arg2) { var condition = arg1; if (condition) { // todo } else { // todo } while (condition) { // todo } } function main() { f(1, 2); } 这是一门脚本语言，这样设计的目的是使得 parse 部分能够轻松的写出来。关于其他细节，在后续过程中进行阐述。 作为PLT领域的初学者，没有系统全面的掌握相关知识，那么设计的语言肯定是不合理、存在缺陷的。所以第二个阶段采用现有的语言为实现模板，而Scheme精简美丽，再加上能够应用到一些PLT中的理论，所以成为了不二之选。至于第三个阶段，通过现有的、已经比较成熟源码学习应该是比自己手写收获更大，所以选择使用现有源代码。]]></content>
      <categories>
        <category>编译器实现</category>
      </categories>
      <tags>
        <tag>Compile</tag>
      </tags>
  </entry>
</search>
